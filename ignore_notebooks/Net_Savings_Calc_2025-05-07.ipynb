{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f88039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81418fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9813c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import (\n",
    "        classification_report, confusion_matrix, r2_score, mean_squared_error, root_mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, accuracy_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve\n",
    ") \n",
    "\n",
    "from sklearn.inspection import PartialDependenceDisplay, permutation_importance, partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f20eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier, XGBRegressor, plot_importance\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53490c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder \n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817e1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b36d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edc5bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d876e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.imputation import CategoricalImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c86864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgbimputer import XGBImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c87fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "537a0d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7468642",
   "metadata": {},
   "outputs": [],
   "source": [
    "In2019_withFresh_Y_Pred = pd.read_csv('../data/In2019_withFresh_Y_Pred_DistanceClass.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c0802ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112019 entries, 0 to 112018\n",
      "Data columns (total 55 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   Unnamed: 0.2                    112019 non-null  int64  \n",
      " 1   Unnamed: 0.1                    112019 non-null  int64  \n",
      " 2   Unnamed: 0                      112019 non-null  int64  \n",
      " 3   RecordID                        112019 non-null  int64  \n",
      " 4   ESS_Id                          112019 non-null  int64  \n",
      " 5   EventTimeStamp                  112019 non-null  object \n",
      " 6   eventDescription                108067 non-null  object \n",
      " 7   actionDescription               0 non-null       float64\n",
      " 8   ecuSoftwareVersion              49117 non-null   object \n",
      " 9   ecuSerialNumber                 46794 non-null   object \n",
      " 10  ecuModel                        104416 non-null  object \n",
      " 11  ecuMake                         104416 non-null  object \n",
      " 12  ecuSource                       112019 non-null  int64  \n",
      " 13  spn                             112019 non-null  float64\n",
      " 14  fmi                             112019 non-null  float64\n",
      " 15  active                          112019 non-null  bool   \n",
      " 16  activeTransitionCount           112019 non-null  int64  \n",
      " 17  faultValue                      0 non-null       float64\n",
      " 18  EquipmentID                     112019 non-null  int64  \n",
      " 19  MCTNumber                       112019 non-null  int64  \n",
      " 20  Latitude                        112019 non-null  float64\n",
      " 21  Longitude                       112019 non-null  float64\n",
      " 22  LocationTimeStamp               112019 non-null  object \n",
      " 23  FaultId                         112019 non-null  int64  \n",
      " 24  AcceleratorPedal                56551 non-null   float64\n",
      " 25  BarometricPressure              56615 non-null   float64\n",
      " 26  CruiseControlActive             56589 non-null   object \n",
      " 27  CruiseControlSetSpeed           56698 non-null   float64\n",
      " 28  DistanceLtd                     56567 non-null   float64\n",
      " 29  EngineCoolantTemperature        56643 non-null   float64\n",
      " 30  EngineLoad                      56648 non-null   float64\n",
      " 31  EngineOilPressure               56645 non-null   float64\n",
      " 32  EngineOilTemperature            56506 non-null   float64\n",
      " 33  EngineRpm                       56752 non-null   float64\n",
      " 34  EngineTimeLtd                   56598 non-null   float64\n",
      " 35  FuelLevel                       55129 non-null   float64\n",
      " 36  FuelLtd                         56712 non-null   float64\n",
      " 37  FuelRate                        56597 non-null   float64\n",
      " 38  FuelTemperature                 23808 non-null   float64\n",
      " 39  IgnStatus                       56881 non-null   object \n",
      " 40  IntakeManifoldTemperature       56645 non-null   float64\n",
      " 41  LampStatus                      112019 non-null  float64\n",
      " 42  ParkingBrake                    51876 non-null   object \n",
      " 43  ServiceDistance                 0 non-null       float64\n",
      " 44  Speed                           56518 non-null   float64\n",
      " 45  SwitchedBatteryVoltage          4151 non-null    float64\n",
      " 46  Throttle                        56452 non-null   float64\n",
      " 47  TurboBoostPressure              56525 non-null   float64\n",
      " 48  spn_fmi                         112019 non-null  object \n",
      " 49  is_fullderate                   112019 non-null  int64  \n",
      " 50  is_fullderate_group             112019 non-null  int64  \n",
      " 51  EquipID_Index                   112019 non-null  object \n",
      " 52  time_to_next_SPN5246            112019 non-null  float64\n",
      " 53  time_interval_to_SPN5246_class  112019 non-null  int64  \n",
      " 54  Predicted_Time_Interval_Class   112019 non-null  int64  \n",
      "dtypes: bool(1), float64(28), int64(14), object(12)\n",
      "memory usage: 46.3+ MB\n"
     ]
    }
   ],
   "source": [
    "In2019_withFresh_Y_Pred.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e1e9f5",
   "metadata": {},
   "source": [
    "**Goal:** Predict the rank based on the total shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dea232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In2019_withFresh_Y_Pred['spn_fmi'] = In2019_withFresh_Y_Pred['spn_fmi'].str.replace('.0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_equipment_savings(data_path):\n",
    "    \"\"\"\n",
    "    Calculate potential savings or losses based on equipment data analysis.\n",
    "    \n",
    "    Conditions:\n",
    "    1. If SPN 5246 exists in an EquipmentID group AND Predicted_Distance_Class contains 1: $4000 saved\n",
    "    2. If SPN 5246 doesn't exist in an EquipmentID group AND Predicted_Distance_Class contains 1: $500 lost\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to the data file (CSV expected)\n",
    "        \n",
    "    Returns:\n",
    "        float: Net savings (positive) or losses (negative) across all equipment\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    print(f\"Loading data from {data_path}...\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Display data info for verification\n",
    "    print(f\"Data loaded. Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(f\"Number of unique EquipmentID: {df['EquipmentID'].nunique()}\")\n",
    "    \n",
    "    # Initialize variables to track total savings/losses\n",
    "    total_savings = 0\n",
    "    total_losses = 0\n",
    "    \n",
    "    # Create a results dataframe to store savings/losses by equipment\n",
    "    results = []\n",
    "    \n",
    "    # Group by EquipmentID\n",
    "    equipment_groups = df.groupby('EquipmentID')\n",
    "    \n",
    "    # Process each equipment group\n",
    "    for equipment_id, group in equipment_groups:\n",
    "        # Check if SPN 5246 exists in this group\n",
    "        has_spn_5246 = (group['spn'] == 5246).any()\n",
    "        \n",
    "        # Check if Predicted_Distance_Class contains 1  \n",
    "        has_time_interval_1 = (group['Predicted_Distance_Class'] == 1).any()\n",
    "       # has_time_interval_2 = (group['Predicted_Distance_Class'] == 2).any()\n",
    "                               \n",
    "        savings = 0\n",
    "        losses = 0\n",
    "        \n",
    "        # Apply the business rules\n",
    "        if has_spn_5246 and has_time_interval_1: # or has_time_interval_2):\n",
    "            # Condition 1: SPN 5246 exists and Predicted_Distance_Class contains 1  \n",
    "            savings = 4000\n",
    "            total_savings += savings\n",
    "        elif not has_spn_5246 and has_time_interval_1: # or has_time_interval_2):\n",
    "            # Condition 2: SPN 5246 doesn't exist and Predicted_Distance_Class contains 1  \n",
    "            losses = 500\n",
    "            total_losses += losses\n",
    "        \n",
    "        # Store the results for this equipment\n",
    "        results.append({\n",
    "            'EquipmentID': equipment_id,\n",
    "            'Has_SPN_5246': has_spn_5246,\n",
    "            'Has_Time_Interval_1': has_time_interval_1,\n",
    "        #    'Has_Time_Interval_2': has_time_interval_2,\n",
    "            'Savings': savings,\n",
    "            'Losses': losses,\n",
    "            'Net': savings - losses\n",
    "        })\n",
    "    \n",
    "    # Create a results dataframe\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Calculate net savings across all equipment\n",
    "    net_savings = total_savings - total_losses\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(f\"Total equipment count: {len(results)}\")\n",
    "    print(f\"Equipment with savings: {(results_df['Savings'] > 0).sum()}\")\n",
    "    print(f\"Equipment with losses: {(results_df['Losses'] > 0).sum()}\")\n",
    "    print(f\"Total savings: ${total_savings:,.2f}\")\n",
    "    print(f\"Total losses: ${total_losses:,.2f}\")\n",
    "    print(f\"Net savings: ${net_savings:,.2f}\")\n",
    "    \n",
    "    # Display a few sample results\n",
    "    print(\"\\nSample equipment results:\")\n",
    "    print(results_df.head(10))\n",
    "    \n",
    "    # Save the detailed results to CSV\n",
    "    results_df.to_csv('equipment_savings_analysis_byDistanceClass.csv', index=False)\n",
    "    print(\"Detailed results saved to 'equipment_savings_analysis_byDistanceClass.csv'\")\n",
    "    \n",
    "    return net_savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc3da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/In2019_withFresh_Y_Pred.csv...\n",
      "Data loaded. Shape: (112019, 55)\n",
      "Columns: ['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'RecordID', 'ESS_Id', 'EventTimeStamp', 'eventDescription', 'actionDescription', 'ecuSoftwareVersion', 'ecuSerialNumber', 'ecuModel', 'ecuMake', 'ecuSource', 'spn', 'fmi', 'active', 'activeTransitionCount', 'faultValue', 'EquipmentID', 'MCTNumber', 'Latitude', 'Longitude', 'LocationTimeStamp', 'FaultId', 'AcceleratorPedal', 'BarometricPressure', 'CruiseControlActive', 'CruiseControlSetSpeed', 'DistanceLtd', 'EngineCoolantTemperature', 'EngineLoad', 'EngineOilPressure', 'EngineOilTemperature', 'EngineRpm', 'EngineTimeLtd', 'FuelLevel', 'FuelLtd', 'FuelRate', 'FuelTemperature', 'IgnStatus', 'IntakeManifoldTemperature', 'LampStatus', 'ParkingBrake', 'ServiceDistance', 'Speed', 'SwitchedBatteryVoltage', 'Throttle', 'TurboBoostPressure', 'spn_fmi', 'is_fullderate', 'is_fullderate_group', 'EquipID_Index', 'time_to_next_SPN5246', 'time_interval_to_SPN5246_class', 'Predicted_Time_Interval_Class']\n",
      "Number of unique EquipmentID: 686\n",
      "\n",
      "Summary of Results:\n",
      "Total equipment count: 686\n",
      "Equipment with savings: 34\n",
      "Equipment with losses: 446\n",
      "Total savings: $136,000.00\n",
      "Total losses: $223,000.00\n",
      "Net savings: $-87,000.00\n",
      "\n",
      "Sample equipment results:\n",
      "   EquipmentID  Has_SPN_5246  Has_Time_Interval_1  Has_Time_Interval_2  \\\n",
      "0          301         False                 True                 True   \n",
      "1          302          True                 True                 True   \n",
      "2          303         False                 True                 True   \n",
      "3          304         False                 True                 True   \n",
      "4          305         False                 True                 True   \n",
      "5          306         False                False                False   \n",
      "6          307         False                False                False   \n",
      "7          308         False                False                 True   \n",
      "8          309         False                 True                False   \n",
      "9          310         False                False                False   \n",
      "\n",
      "   Savings  Losses   Net  \n",
      "0        0     500  -500  \n",
      "1     4000       0  4000  \n",
      "2        0     500  -500  \n",
      "3        0     500  -500  \n",
      "4        0     500  -500  \n",
      "5        0       0     0  \n",
      "6        0       0     0  \n",
      "7        0     500  -500  \n",
      "8        0     500  -500  \n",
      "9        0       0     0  \n",
      "Detailed results saved to 'equipment_savings_analysis.csv'\n",
      "\n",
      "Overall result: Net loss of $87,000.00\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Replace with the actual path to your data file\n",
    "    data_file = \"../data/In2019_withFresh_Y_Pred_DistanceClass.csv\"\n",
    "    \n",
    "    try:\n",
    "        net_result = calculate_equipment_savings(data_file)\n",
    "        \n",
    "        if net_result > 0:\n",
    "            print(f\"\\nOverall result: Net savings of ${net_result:,.2f}\")\n",
    "        else:\n",
    "            print(f\"\\nOverall result: Net loss of ${-net_result:,.2f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d06fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea0db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbbcf21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c2fcfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_here' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mstop_here\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'stop_here' is not defined"
     ]
    }
   ],
   "source": [
    "stop_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5cf626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b043b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9980446-eb0f-4df1-b880-785e75ce68df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_interval_to_SPN5246_class\n",
       "9999999    715686\n",
       "0          229509\n",
       "1            2233\n",
       "2            1263\n",
       "3             837\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainPre2019['time_interval_to_SPN5246_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f8d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RecordID</th>\n",
       "      <th>ESS_Id</th>\n",
       "      <th>EventTimeStamp</th>\n",
       "      <th>eventDescription</th>\n",
       "      <th>actionDescription</th>\n",
       "      <th>ecuSoftwareVersion</th>\n",
       "      <th>ecuSerialNumber</th>\n",
       "      <th>ecuModel</th>\n",
       "      <th>...</th>\n",
       "      <th>Speed</th>\n",
       "      <th>SwitchedBatteryVoltage</th>\n",
       "      <th>Throttle</th>\n",
       "      <th>TurboBoostPressure</th>\n",
       "      <th>spn_fmi</th>\n",
       "      <th>is_fullderate</th>\n",
       "      <th>is_fullderate_group</th>\n",
       "      <th>EquipID_Index</th>\n",
       "      <th>time_to_next_SPN5246</th>\n",
       "      <th>time_interval_to_SPN5246_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43931</td>\n",
       "      <td>48303</td>\n",
       "      <td>49415</td>\n",
       "      <td>2363162</td>\n",
       "      <td>2015-05-11 13:11:20</td>\n",
       "      <td>Incorrect Data J1939 Network #1 Primary Vehicl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>4.475814</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.58</td>\n",
       "      <td>639.0_2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301_0</td>\n",
       "      <td>1.027800e+04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45693</td>\n",
       "      <td>50251</td>\n",
       "      <td>51363</td>\n",
       "      <td>2400445</td>\n",
       "      <td>2015-05-13 08:22:32</td>\n",
       "      <td>Condition Exists Cruise Control Enable Switch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>64.637170</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>89.6</td>\n",
       "      <td>4.64</td>\n",
       "      <td>596.0_31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301_0</td>\n",
       "      <td>1.023481e+04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50271</td>\n",
       "      <td>55260</td>\n",
       "      <td>57330</td>\n",
       "      <td>2482983</td>\n",
       "      <td>2015-05-18 09:34:05</td>\n",
       "      <td>Abnormal Rate of Change Aftertreatment 1 Outle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC4__1284P4C_2*</td>\n",
       "      <td>6U13D13</td>\n",
       "      <td>MX</td>\n",
       "      <td>...</td>\n",
       "      <td>63.525490</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.30</td>\n",
       "      <td>3226.0_10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301_0</td>\n",
       "      <td>1.011362e+04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54326</td>\n",
       "      <td>59636</td>\n",
       "      <td>61706</td>\n",
       "      <td>2554027</td>\n",
       "      <td>2015-05-21 13:57:35</td>\n",
       "      <td>Incorrect Data J1939 Network #1 Primary Vehicl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>4.364162</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>639.0_2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301_0</td>\n",
       "      <td>1.003723e+04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54418</td>\n",
       "      <td>59731</td>\n",
       "      <td>61801</td>\n",
       "      <td>2555325</td>\n",
       "      <td>2015-05-21 14:54:32</td>\n",
       "      <td>Incorrect Data J1939 Network #1 Primary Vehicl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639.0_2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301_0</td>\n",
       "      <td>1.003628e+04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949523</th>\n",
       "      <td>4036</td>\n",
       "      <td>4494</td>\n",
       "      <td>4495</td>\n",
       "      <td>1052146</td>\n",
       "      <td>2015-02-24 16:24:05</td>\n",
       "      <td>Low (Severity Medium) Catalyst Tank Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05317106*04119044*051914190353*09400015*G1*BDR*</td>\n",
       "      <td>79751302</td>\n",
       "      <td>6X1u13D1500000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1761.0_18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R1762_0</td>\n",
       "      <td>2.400000e+08</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949524</th>\n",
       "      <td>5907</td>\n",
       "      <td>6438</td>\n",
       "      <td>6439</td>\n",
       "      <td>1089561</td>\n",
       "      <td>2015-02-26 13:12:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05317106*04119044*051914190353*09400015*G1*BDR*</td>\n",
       "      <td>79751302</td>\n",
       "      <td>6X1u13D1500000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.058292</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>5848.0_9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R1762_0</td>\n",
       "      <td>2.400000e+08</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949525</th>\n",
       "      <td>5915</td>\n",
       "      <td>6446</td>\n",
       "      <td>6447</td>\n",
       "      <td>1090499</td>\n",
       "      <td>2015-02-26 13:50:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05317106*04119044*051914190353*09400015*G1*BDR*</td>\n",
       "      <td>79751302</td>\n",
       "      <td>6X1u13D1500000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5848.0_9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R1762_0</td>\n",
       "      <td>2.400000e+08</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949526</th>\n",
       "      <td>4472</td>\n",
       "      <td>4952</td>\n",
       "      <td>4953</td>\n",
       "      <td>1059704</td>\n",
       "      <td>2015-02-25 06:08:43</td>\n",
       "      <td>Incorrect Data J1939 Network #1 Primary Vehicl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>4.378725</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>639.0_2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R1764_0</td>\n",
       "      <td>2.400000e+08</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949527</th>\n",
       "      <td>4512</td>\n",
       "      <td>4999</td>\n",
       "      <td>5000</td>\n",
       "      <td>1060204</td>\n",
       "      <td>2015-02-25 06:38:40</td>\n",
       "      <td>Incorrect Data J1939 Network #1 Primary Vehicl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639.0_2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R1764_0</td>\n",
       "      <td>2.400000e+08</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949528 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.1  Unnamed: 0  RecordID   ESS_Id       EventTimeStamp  \\\n",
       "0              43931       48303     49415  2363162  2015-05-11 13:11:20   \n",
       "1              45693       50251     51363  2400445  2015-05-13 08:22:32   \n",
       "2              50271       55260     57330  2482983  2015-05-18 09:34:05   \n",
       "3              54326       59636     61706  2554027  2015-05-21 13:57:35   \n",
       "4              54418       59731     61801  2555325  2015-05-21 14:54:32   \n",
       "...              ...         ...       ...      ...                  ...   \n",
       "949523          4036        4494      4495  1052146  2015-02-24 16:24:05   \n",
       "949524          5907        6438      6439  1089561  2015-02-26 13:12:11   \n",
       "949525          5915        6446      6447  1090499  2015-02-26 13:50:59   \n",
       "949526          4472        4952      4953  1059704  2015-02-25 06:08:43   \n",
       "949527          4512        4999      5000  1060204  2015-02-25 06:38:40   \n",
       "\n",
       "                                         eventDescription  actionDescription  \\\n",
       "0       Incorrect Data J1939 Network #1 Primary Vehicl...                NaN   \n",
       "1           Condition Exists Cruise Control Enable Switch                NaN   \n",
       "2       Abnormal Rate of Change Aftertreatment 1 Outle...                NaN   \n",
       "3       Incorrect Data J1939 Network #1 Primary Vehicl...                NaN   \n",
       "4       Incorrect Data J1939 Network #1 Primary Vehicl...                NaN   \n",
       "...                                                   ...                ...   \n",
       "949523          Low (Severity Medium) Catalyst Tank Level                NaN   \n",
       "949524                                                NaN                NaN   \n",
       "949525                                                NaN                NaN   \n",
       "949526  Incorrect Data J1939 Network #1 Primary Vehicl...                NaN   \n",
       "949527  Incorrect Data J1939 Network #1 Primary Vehicl...                NaN   \n",
       "\n",
       "                                     ecuSoftwareVersion ecuSerialNumber  \\\n",
       "0                                               unknown         unknown   \n",
       "1                                               unknown         unknown   \n",
       "2                                       PC4__1284P4C_2*         6U13D13   \n",
       "3                                               unknown         unknown   \n",
       "4                                               unknown         unknown   \n",
       "...                                                 ...             ...   \n",
       "949523  05317106*04119044*051914190353*09400015*G1*BDR*        79751302   \n",
       "949524  05317106*04119044*051914190353*09400015*G1*BDR*        79751302   \n",
       "949525  05317106*04119044*051914190353*09400015*G1*BDR*        79751302   \n",
       "949526                                          unknown         unknown   \n",
       "949527                                          unknown         unknown   \n",
       "\n",
       "                 ecuModel  ...      Speed  SwitchedBatteryVoltage  Throttle  \\\n",
       "0                 unknown  ...   4.475814                 3276.75      14.4   \n",
       "1                 unknown  ...  64.637170                 3276.75      89.6   \n",
       "2                      MX  ...  63.525490                 3276.75       0.0   \n",
       "3                 unknown  ...   4.364162                 3276.75      12.0   \n",
       "4                 unknown  ...        NaN                     NaN       NaN   \n",
       "...                   ...  ...        ...                     ...       ...   \n",
       "949523  6X1u13D1500000000  ...        NaN                     NaN       NaN   \n",
       "949524  6X1u13D1500000000  ...   2.058292                 3276.75       0.0   \n",
       "949525  6X1u13D1500000000  ...        NaN                     NaN       NaN   \n",
       "949526            unknown  ...   4.378725                 3276.75       0.0   \n",
       "949527            unknown  ...        NaN                     NaN       NaN   \n",
       "\n",
       "        TurboBoostPressure      spn_fmi  is_fullderate  is_fullderate_group  \\\n",
       "0                     0.58    639.0_2.0              0                    0   \n",
       "1                     4.64   596.0_31.0              0                    0   \n",
       "2                    20.30  3226.0_10.0              0                    0   \n",
       "3                     1.45    639.0_2.0              0                    0   \n",
       "4                      NaN    639.0_2.0              0                    0   \n",
       "...                    ...          ...            ...                  ...   \n",
       "949523                 NaN  1761.0_18.0              0                    0   \n",
       "949524                0.29   5848.0_9.0              0                    0   \n",
       "949525                 NaN   5848.0_9.0              0                    0   \n",
       "949526                1.74    639.0_2.0              0                    0   \n",
       "949527                 NaN    639.0_2.0              0                    0   \n",
       "\n",
       "       EquipID_Index  time_to_next_SPN5246  time_interval_to_SPN5246_class  \n",
       "0              301_0          1.027800e+04                               0  \n",
       "1              301_0          1.023481e+04                               0  \n",
       "2              301_0          1.011362e+04                               0  \n",
       "3              301_0          1.003723e+04                               0  \n",
       "4              301_0          1.003628e+04                               0  \n",
       "...              ...                   ...                             ...  \n",
       "949523       R1762_0          2.400000e+08                         9999999  \n",
       "949524       R1762_0          2.400000e+08                         9999999  \n",
       "949525       R1762_0          2.400000e+08                         9999999  \n",
       "949526       R1764_0          2.400000e+08                         9999999  \n",
       "949527       R1764_0          2.400000e+08                         9999999  \n",
       "\n",
       "[949528 rows x 53 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainPre2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ea6fb",
   "metadata": {},
   "source": [
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = OneHotEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = OneHotEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ada74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainPre2019[['ecuSource', 'LampStatus', 'time_interval_to_SPN5246_class', 'ecuSerialNumber', 'ecuModel', 'ecuMake']] = TrainPre2019[['ecuSource', 'LampStatus', 'time_interval_to_SPN5246_class', 'ecuSerialNumber', 'ecuModel', 'ecuMake']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainPre2019[['activeTransitionCount']] = TrainPre2019[['activeTransitionCount']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b2c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainPre2019.replace(to_replace='3276,75', value='3278.75', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b311add",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainPre2019[[  'AcceleratorPedal',\n",
    "                    'BarometricPressure',\n",
    "                    'CruiseControlSetSpeed',\n",
    "                    'DistanceLtd',\n",
    "                    'EngineCoolantTemperature',\n",
    "                    'EngineLoad',\n",
    "                    'EngineOilPressure',\n",
    "                    'EngineOilTemperature',\n",
    "                    'EngineRpm',\n",
    "                    'EngineTimeLtd',\n",
    "                    'FuelLevel',\n",
    "                    'FuelLtd',\n",
    "                    'FuelRate',\n",
    "                    'FuelTemperature',\n",
    "                    'IntakeManifoldTemperature',\n",
    "                    'Speed',\n",
    "                    'Throttle',\n",
    "                    'active',\n",
    "                    'TurboBoostPressure',\n",
    "                    'CruiseControlActive',\n",
    "                    'IgnStatus',\n",
    "                    'ParkingBrake',\n",
    "                    'SwitchedBatteryVoltage'\n",
    "]] = TrainPre2019[[                         'AcceleratorPedal',\n",
    "                                            'BarometricPressure',\n",
    "                                            'CruiseControlSetSpeed',\n",
    "                                            'DistanceLtd',\n",
    "                                            'EngineCoolantTemperature',\n",
    "                                            'EngineLoad',\n",
    "                                            'EngineOilPressure',\n",
    "                                            'EngineOilTemperature',\n",
    "                                            'EngineRpm',\n",
    "                                            'EngineTimeLtd',\n",
    "                                            'FuelLevel',\n",
    "                                            'FuelLtd',\n",
    "                                            'FuelRate',\n",
    "                                            'FuelTemperature',\n",
    "                                            'IntakeManifoldTemperature',\n",
    "                                            'Speed',\n",
    "                                            'Throttle',\n",
    "                                            'active',\n",
    "                                            'TurboBoostPressure',\n",
    "                                            'CruiseControlActive',\n",
    "                                            'IgnStatus',\n",
    "                                            'ParkingBrake',\n",
    "                                            'SwitchedBatteryVoltage'\n",
    "                     ]].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e176034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'RecordID',\n",
       " 'ESS_Id',\n",
       " 'actionDescription',\n",
       " 'spn',\n",
       " 'fmi',\n",
       " 'active',\n",
       " 'faultValue',\n",
       " 'MCTNumber',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'FaultId',\n",
       " 'AcceleratorPedal',\n",
       " 'BarometricPressure',\n",
       " 'CruiseControlActive',\n",
       " 'CruiseControlSetSpeed',\n",
       " 'DistanceLtd',\n",
       " 'EngineCoolantTemperature',\n",
       " 'EngineLoad',\n",
       " 'EngineOilPressure',\n",
       " 'EngineOilTemperature',\n",
       " 'EngineRpm',\n",
       " 'EngineTimeLtd',\n",
       " 'FuelLevel',\n",
       " 'FuelLtd',\n",
       " 'FuelRate',\n",
       " 'FuelTemperature',\n",
       " 'IgnStatus',\n",
       " 'IntakeManifoldTemperature',\n",
       " 'ParkingBrake',\n",
       " 'ServiceDistance',\n",
       " 'Speed',\n",
       " 'SwitchedBatteryVoltage',\n",
       " 'Throttle',\n",
       " 'TurboBoostPressure',\n",
       " 'is_fullderate',\n",
       " 'is_fullderate_group',\n",
       " 'time_to_next_SPN5246']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumericColumns = TrainPre2019.select_dtypes(include=[np.number]).columns.tolist()\n",
    "NumericColumns_Without_MatchID = NumericColumns.pop(0)\n",
    "NumericColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4918675",
   "metadata": {},
   "source": [
    "Among numeric columns, will keep:\n",
    "\n",
    "\n",
    "['AcceleratorPedal',\n",
    "'BarometricPressure',\n",
    "'CruiseControlSetSpeed',\n",
    "'DistanceLtd',\n",
    "'EngineCoolantTemperature',\n",
    "'EngineLoad',\n",
    "'EngineOilPressure',\n",
    "'EngineOilTemperature',\n",
    "'EngineRpm',\n",
    "'EngineTimeLtd',\n",
    "'FuelLevel',\n",
    "'FuelLtd',\n",
    "'FuelRate',\n",
    "'FuelTemperature',\n",
    "'IntakeManifoldTemperature',\n",
    "'Speed',\n",
    "'Throttle',\n",
    "'active',\n",
    "'TurboBoostPressure',\n",
    "'activeTransitionCount',\n",
    "'CruiseControlActive',\n",
    "'IgnStatus',\n",
    "'ParkingBrake',\n",
    "'SwitchedBatteryVoltage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9ffe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EventTimeStamp',\n",
       " 'eventDescription',\n",
       " 'ecuSoftwareVersion',\n",
       " 'ecuSerialNumber',\n",
       " 'ecuModel',\n",
       " 'ecuMake',\n",
       " 'ecuSource',\n",
       " 'activeTransitionCount',\n",
       " 'EquipmentID',\n",
       " 'LocationTimeStamp',\n",
       " 'LampStatus',\n",
       " 'spn_fmi',\n",
       " 'EquipID_Index',\n",
       " 'time_interval_to_SPN5246_class']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NonNumericColumns = TrainPre2019.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "NonNumericColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c08de",
   "metadata": {},
   "source": [
    "Among, non-numeric columns, will keep:\n",
    "\n",
    "        ('target_encoder', TargetEncoder(handle_unknown='ignore'), [   'ecuSoftwareVersion',\n",
    "                                                                        'ecuSerialNumber',\n",
    "                                                                        'ecuModel',\n",
    "                                                                        'ecuMake',\n",
    "                                                                        'spn_fmi'\n",
    "                                                                    ]),\n",
    "        ('ordinal_encoder', OrdinalEncoder(handle_unknown='ignore'), [   'ecuSource',\n",
    "                                                                                'LampStatus'\n",
    "                                                                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb4efd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15484cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TrainPre2019.drop(columns = [   'Unnamed: 0',\n",
    "                                    'Unnamed: 0.1',\n",
    "                                    'RecordID',\n",
    "                                    'ESS_Id',\n",
    "                                    'actionDescription',\n",
    "                                    'spn',\n",
    "                                    'fmi',\n",
    "                                    'faultValue',\n",
    "                                    'MCTNumber',\n",
    "                                    'Latitude',\n",
    "                                    'Longitude',\n",
    "                                    'is_fullderate',\n",
    "                                    'is_fullderate_group',\n",
    "                                    'time_to_next_SPN5246',\n",
    "                                    'ServiceDistance',\n",
    "                                    'EventTimeStamp',\n",
    "                                    'eventDescription',\n",
    "                                    'EquipmentID',\n",
    "                                    'LocationTimeStamp',\n",
    "                                    'EquipID_Index',\n",
    "                                    'time_interval_to_SPN5246_class',\n",
    "                                    'MCTNumber',                                  \n",
    "                                    'FaultId',\n",
    "                                    'ecuSoftwareVersion',\n",
    "                                    'ecuSerialNumber',\n",
    "                                    'ecuModel',\n",
    "                                    'ecuMake'                                                                                      \n",
    "                                ]\n",
    "                      )\n",
    "y = TrainPre2019['time_interval_to_SPN5246_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['spn_fmi'] = X['spn_fmi'].str.replace('.0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b0229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecuSource</th>\n",
       "      <th>active</th>\n",
       "      <th>activeTransitionCount</th>\n",
       "      <th>AcceleratorPedal</th>\n",
       "      <th>BarometricPressure</th>\n",
       "      <th>CruiseControlActive</th>\n",
       "      <th>CruiseControlSetSpeed</th>\n",
       "      <th>DistanceLtd</th>\n",
       "      <th>EngineCoolantTemperature</th>\n",
       "      <th>EngineLoad</th>\n",
       "      <th>...</th>\n",
       "      <th>FuelTemperature</th>\n",
       "      <th>IgnStatus</th>\n",
       "      <th>IntakeManifoldTemperature</th>\n",
       "      <th>LampStatus</th>\n",
       "      <th>ParkingBrake</th>\n",
       "      <th>Speed</th>\n",
       "      <th>SwitchedBatteryVoltage</th>\n",
       "      <th>Throttle</th>\n",
       "      <th>TurboBoostPressure</th>\n",
       "      <th>spn_fmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127</td>\n",
       "      <td>14.4</td>\n",
       "      <td>13.9200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>120841.70</td>\n",
       "      <td>185.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>134.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.4</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.475814</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.58</td>\n",
       "      <td>639_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>89.6</td>\n",
       "      <td>14.4275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>121687.10</td>\n",
       "      <td>186.8</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.2</td>\n",
       "      <td>4351.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.637170</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>89.6</td>\n",
       "      <td>4.64</td>\n",
       "      <td>596_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>123057.10</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.4</td>\n",
       "      <td>17407.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.525490</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.30</td>\n",
       "      <td>3226_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.5725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>124496.50</td>\n",
       "      <td>183.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.6</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.364162</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>639_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949523</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1761_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949524</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.2100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.48672</td>\n",
       "      <td>80838.70</td>\n",
       "      <td>134.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.2</td>\n",
       "      <td>17407.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.058292</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>5848_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949525</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5848_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949526</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127</td>\n",
       "      <td>21.6</td>\n",
       "      <td>14.4275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.48672</td>\n",
       "      <td>83681.85</td>\n",
       "      <td>154.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.378725</td>\n",
       "      <td>3276.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>639_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949527</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949528 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ecuSource  active activeTransitionCount  AcceleratorPedal  \\\n",
       "0             11     1.0                   127              14.4   \n",
       "1             49     1.0                     3              89.6   \n",
       "2              0     1.0                     6               0.0   \n",
       "3             11     1.0                   127              12.0   \n",
       "4             11     0.0                   127               NaN   \n",
       "...          ...     ...                   ...               ...   \n",
       "949523         0     0.0                    11               NaN   \n",
       "949524         0     1.0                     1               0.0   \n",
       "949525         0     0.0                     1               NaN   \n",
       "949526        11     1.0                   127              21.6   \n",
       "949527        11     0.0                   127               NaN   \n",
       "\n",
       "        BarometricPressure  CruiseControlActive  CruiseControlSetSpeed  \\\n",
       "0                  13.9200                  0.0                0.00000   \n",
       "1                  14.4275                  0.0                0.00000   \n",
       "2                  14.3550                  0.0                0.00000   \n",
       "3                  14.5725                  0.0                0.00000   \n",
       "4                      NaN                  NaN                    NaN   \n",
       "...                    ...                  ...                    ...   \n",
       "949523                 NaN                  NaN                    NaN   \n",
       "949524             14.2100                  0.0               66.48672   \n",
       "949525                 NaN                  NaN                    NaN   \n",
       "949526             14.4275                  0.0               66.48672   \n",
       "949527                 NaN                  NaN                    NaN   \n",
       "\n",
       "        DistanceLtd  EngineCoolantTemperature  EngineLoad  ...  \\\n",
       "0         120841.70                     185.0        18.0  ...   \n",
       "1         121687.10                     186.8        38.0  ...   \n",
       "2         123057.10                     185.0         0.0  ...   \n",
       "3         124496.50                     183.2        14.0  ...   \n",
       "4               NaN                       NaN         NaN  ...   \n",
       "...             ...                       ...         ...  ...   \n",
       "949523          NaN                       NaN         NaN  ...   \n",
       "949524     80838.70                     134.6        11.0  ...   \n",
       "949525          NaN                       NaN         NaN  ...   \n",
       "949526     83681.85                     154.4        12.0  ...   \n",
       "949527          NaN                       NaN         NaN  ...   \n",
       "\n",
       "        FuelTemperature  IgnStatus  IntakeManifoldTemperature  LampStatus  \\\n",
       "0                 134.6        1.0                      154.4      1279.0   \n",
       "1                 100.4        1.0                      120.2      4351.0   \n",
       "2                 120.2        1.0                      118.4     17407.0   \n",
       "3                 109.4        1.0                      107.6      1279.0   \n",
       "4                   NaN        NaN                        NaN      1279.0   \n",
       "...                 ...        ...                        ...         ...   \n",
       "949523              NaN        NaN                        NaN      1023.0   \n",
       "949524             32.0        1.0                       84.2     17407.0   \n",
       "949525              NaN        NaN                        NaN      1023.0   \n",
       "949526             32.0        1.0                       93.2      1279.0   \n",
       "949527              NaN        NaN                        NaN      1279.0   \n",
       "\n",
       "        ParkingBrake      Speed  SwitchedBatteryVoltage  Throttle  \\\n",
       "0                0.0   4.475814                 3276.75      14.4   \n",
       "1                0.0  64.637170                 3276.75      89.6   \n",
       "2                0.0  63.525490                 3276.75       0.0   \n",
       "3                0.0   4.364162                 3276.75      12.0   \n",
       "4                NaN        NaN                     NaN       NaN   \n",
       "...              ...        ...                     ...       ...   \n",
       "949523           NaN        NaN                     NaN       NaN   \n",
       "949524           0.0   2.058292                 3276.75       0.0   \n",
       "949525           NaN        NaN                     NaN       NaN   \n",
       "949526           0.0   4.378725                 3276.75       0.0   \n",
       "949527           NaN        NaN                     NaN       NaN   \n",
       "\n",
       "        TurboBoostPressure  spn_fmi  \n",
       "0                     0.58    639_2  \n",
       "1                     4.64   596_31  \n",
       "2                    20.30  3226_10  \n",
       "3                     1.45    639_2  \n",
       "4                      NaN    639_2  \n",
       "...                    ...      ...  \n",
       "949523                 NaN  1761_18  \n",
       "949524                0.29   5848_9  \n",
       "949525                 NaN   5848_9  \n",
       "949526                1.74    639_2  \n",
       "949527                 NaN    639_2  \n",
       "\n",
       "[949528 rows x 27 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc487125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9ceb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               0\n",
       "1               0\n",
       "2               0\n",
       "3               0\n",
       "4               0\n",
       "           ...   \n",
       "949523    9999999\n",
       "949524    9999999\n",
       "949525    9999999\n",
       "949526    9999999\n",
       "949527    9999999\n",
       "Name: time_interval_to_SPN5246_class, Length: 949528, dtype: category\n",
       "Categories (5, int64): [0, 1, 2, 3, 9999999]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e716c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active</th>\n",
       "      <th>AcceleratorPedal</th>\n",
       "      <th>BarometricPressure</th>\n",
       "      <th>CruiseControlActive</th>\n",
       "      <th>CruiseControlSetSpeed</th>\n",
       "      <th>DistanceLtd</th>\n",
       "      <th>EngineCoolantTemperature</th>\n",
       "      <th>EngineLoad</th>\n",
       "      <th>EngineOilPressure</th>\n",
       "      <th>EngineOilTemperature</th>\n",
       "      <th>...</th>\n",
       "      <th>FuelLtd</th>\n",
       "      <th>FuelRate</th>\n",
       "      <th>FuelTemperature</th>\n",
       "      <th>IgnStatus</th>\n",
       "      <th>IntakeManifoldTemperature</th>\n",
       "      <th>ParkingBrake</th>\n",
       "      <th>Speed</th>\n",
       "      <th>SwitchedBatteryVoltage</th>\n",
       "      <th>Throttle</th>\n",
       "      <th>TurboBoostPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>949528.000000</td>\n",
       "      <td>426247.000000</td>\n",
       "      <td>476659.000000</td>\n",
       "      <td>466508.000000</td>\n",
       "      <td>467458.000000</td>\n",
       "      <td>476568.000000</td>\n",
       "      <td>476625.000000</td>\n",
       "      <td>476168.000000</td>\n",
       "      <td>476735.000000</td>\n",
       "      <td>475236.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476017.000000</td>\n",
       "      <td>475932.000000</td>\n",
       "      <td>248414.000000</td>\n",
       "      <td>494185.000000</td>\n",
       "      <td>476730.000000</td>\n",
       "      <td>303591.000000</td>\n",
       "      <td>475134.000000</td>\n",
       "      <td>102624.000000</td>\n",
       "      <td>320557.000000</td>\n",
       "      <td>474652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.520453</td>\n",
       "      <td>28.544902</td>\n",
       "      <td>14.191954</td>\n",
       "      <td>0.096682</td>\n",
       "      <td>62.174458</td>\n",
       "      <td>364626.882789</td>\n",
       "      <td>169.566761</td>\n",
       "      <td>31.959878</td>\n",
       "      <td>33.453187</td>\n",
       "      <td>187.261404</td>\n",
       "      <td>...</td>\n",
       "      <td>50560.896556</td>\n",
       "      <td>4.627839</td>\n",
       "      <td>37.043151</td>\n",
       "      <td>0.995724</td>\n",
       "      <td>106.750817</td>\n",
       "      <td>0.283948</td>\n",
       "      <td>26.293766</td>\n",
       "      <td>3104.761359</td>\n",
       "      <td>66.074916</td>\n",
       "      <td>6.286150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499582</td>\n",
       "      <td>36.550423</td>\n",
       "      <td>1.195484</td>\n",
       "      <td>0.295525</td>\n",
       "      <td>12.239142</td>\n",
       "      <td>142701.441105</td>\n",
       "      <td>32.811442</td>\n",
       "      <td>30.635726</td>\n",
       "      <td>11.282650</td>\n",
       "      <td>61.171250</td>\n",
       "      <td>...</td>\n",
       "      <td>24171.307050</td>\n",
       "      <td>5.783522</td>\n",
       "      <td>23.152840</td>\n",
       "      <td>0.065249</td>\n",
       "      <td>25.476308</td>\n",
       "      <td>0.450913</td>\n",
       "      <td>28.208800</td>\n",
       "      <td>729.139651</td>\n",
       "      <td>46.345526</td>\n",
       "      <td>8.557188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.045000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-39.156250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.210000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.622600</td>\n",
       "      <td>267338.900000</td>\n",
       "      <td>170.600000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>28.420000</td>\n",
       "      <td>179.937500</td>\n",
       "      <td>...</td>\n",
       "      <td>33494.638645</td>\n",
       "      <td>0.647223</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3276.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.355000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.486720</td>\n",
       "      <td>379825.250000</td>\n",
       "      <td>183.200000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>36.540000</td>\n",
       "      <td>202.775000</td>\n",
       "      <td>...</td>\n",
       "      <td>51938.602972</td>\n",
       "      <td>1.690706</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>109.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.699216</td>\n",
       "      <td>3276.750000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.486720</td>\n",
       "      <td>481544.650000</td>\n",
       "      <td>186.800000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>39.440000</td>\n",
       "      <td>214.531300</td>\n",
       "      <td>...</td>\n",
       "      <td>68751.040705</td>\n",
       "      <td>7.211920</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>125.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.933190</td>\n",
       "      <td>3276.750000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>8.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>15.225000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.593570</td>\n",
       "      <td>649549.000000</td>\n",
       "      <td>406.400000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>3212.544000</td>\n",
       "      <td>...</td>\n",
       "      <td>312737.574126</td>\n",
       "      <td>25.611560</td>\n",
       "      <td>231.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>264.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>158.447200</td>\n",
       "      <td>3278.750000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>63.220000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              active  AcceleratorPedal  BarometricPressure  \\\n",
       "count  949528.000000     426247.000000       476659.000000   \n",
       "mean        0.520453         28.544902           14.191954   \n",
       "std         0.499582         36.550423            1.195484   \n",
       "min         0.000000          0.000000            3.045000   \n",
       "25%         0.000000          0.000000           14.210000   \n",
       "50%         1.000000          4.000000           14.355000   \n",
       "75%         1.000000         48.800000           14.500000   \n",
       "max         1.000000        100.000000           15.225000   \n",
       "\n",
       "       CruiseControlActive  CruiseControlSetSpeed    DistanceLtd  \\\n",
       "count        466508.000000          467458.000000  476568.000000   \n",
       "mean              0.096682              62.174458  364626.882789   \n",
       "std               0.295525              12.239142  142701.441105   \n",
       "min               0.000000               0.000000       0.000000   \n",
       "25%               0.000000              64.622600  267338.900000   \n",
       "50%               0.000000              66.486720  379825.250000   \n",
       "75%               0.000000              66.486720  481544.650000   \n",
       "max               1.000000              69.593570  649549.000000   \n",
       "\n",
       "       EngineCoolantTemperature     EngineLoad  EngineOilPressure  \\\n",
       "count             476625.000000  476168.000000      476735.000000   \n",
       "mean                 169.566761      31.959878          33.453187   \n",
       "std                   32.811442      30.635726          11.282650   \n",
       "min                   -7.600000       0.000000           0.000000   \n",
       "25%                  170.600000      11.000000          28.420000   \n",
       "50%                  183.200000      19.000000          36.540000   \n",
       "75%                  186.800000      48.000000          39.440000   \n",
       "max                  406.400000     101.000000         145.000000   \n",
       "\n",
       "       EngineOilTemperature  ...        FuelLtd       FuelRate  \\\n",
       "count         475236.000000  ...  476017.000000  475932.000000   \n",
       "mean             187.261404  ...   50560.896556       4.627839   \n",
       "std               61.171250  ...   24171.307050       5.783522   \n",
       "min              -39.156250  ...       0.000000       0.000000   \n",
       "25%              179.937500  ...   33494.638645       0.647223   \n",
       "50%              202.775000  ...   51938.602972       1.690706   \n",
       "75%              214.531300  ...   68751.040705       7.211920   \n",
       "max             3212.544000  ...  312737.574126      25.611560   \n",
       "\n",
       "       FuelTemperature      IgnStatus  IntakeManifoldTemperature  \\\n",
       "count    248414.000000  494185.000000              476730.000000   \n",
       "mean         37.043151       0.995724                 106.750817   \n",
       "std          23.152840       0.065249                  25.476308   \n",
       "min          17.600000       0.000000                 -40.000000   \n",
       "25%          32.000000       1.000000                  89.600000   \n",
       "50%          32.000000       1.000000                 109.400000   \n",
       "75%          32.000000       1.000000                 125.600000   \n",
       "max         231.800000       1.000000                 264.200000   \n",
       "\n",
       "        ParkingBrake          Speed  SwitchedBatteryVoltage       Throttle  \\\n",
       "count  303591.000000  475134.000000           102624.000000  320557.000000   \n",
       "mean        0.283948      26.293766             3104.761359      66.074916   \n",
       "std         0.450913      28.208800              729.139651      46.345526   \n",
       "min         0.000000       0.000000                7.650000       0.000000   \n",
       "25%         0.000000       0.000000             3276.750000       0.000000   \n",
       "50%         0.000000       9.699216             3276.750000     100.000000   \n",
       "75%         1.000000      59.933190             3276.750000     100.000000   \n",
       "max         1.000000     158.447200             3278.750000     100.000000   \n",
       "\n",
       "       TurboBoostPressure  \n",
       "count       474652.000000  \n",
       "mean             6.286150  \n",
       "std              8.557188  \n",
       "min              0.000000  \n",
       "25%              0.580000  \n",
       "50%              2.030000  \n",
       "75%              8.700000  \n",
       "max             63.220000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33ae6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3de2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X\n",
    "\n",
    "le_y = LabelEncoder()\n",
    "\n",
    "y_fitted = le_y.fit(y)\n",
    "y_encoded = le_y.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size = 0.001, random_state = 321, shuffle=True, stratify = y_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08207f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "666d5f0a",
   "metadata": {},
   "source": [
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=3434)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)    # might need another set of pipeline; alternatively, we can go with the following approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c1b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b2bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.178 GB of training data: 2.295 s\n",
      "Binning 0.020 GB of validation data: 0.069 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.44751, val loss: 0.45152, in 0.694s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.40532, val loss: 0.40912, in 1.171s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.37105, val loss: 0.37480, in 0.120s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.34294, val loss: 0.34649, in 0.195s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.31993, val loss: 0.32333, in 0.473s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.30118, val loss: 0.30444, in 0.064s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.28546, val loss: 0.28862, in 0.092s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.27192, val loss: 0.27499, in 0.060s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.26090, val loss: 0.26386, in 0.055s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.25144, val loss: 0.25432, in 0.063s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.24377, val loss: 0.24662, in 0.060s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.23757, val loss: 0.24038, in 0.067s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.23233, val loss: 0.23514, in 0.054s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.22762, val loss: 0.23038, in 0.056s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.22403, val loss: 0.22680, in 0.054s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.22063, val loss: 0.22336, in 0.045s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.21704, val loss: 0.21980, in 0.066s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.21409, val loss: 0.21681, in 0.059s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.21200, val loss: 0.21466, in 0.054s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.21006, val loss: 0.21270, in 0.070s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.20834, val loss: 0.21092, in 0.078s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.20688, val loss: 0.20942, in 0.050s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.20555, val loss: 0.20805, in 0.057s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.20418, val loss: 0.20664, in 0.069s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.20312, val loss: 0.20554, in 0.048s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.20163, val loss: 0.20398, in 0.049s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.20071, val loss: 0.20306, in 0.072s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.19979, val loss: 0.20211, in 0.079s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.19899, val loss: 0.20130, in 0.789s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.19822, val loss: 0.20060, in 0.212s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.19755, val loss: 0.19990, in 0.239s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.19698, val loss: 0.19936, in 0.075s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.19638, val loss: 0.19875, in 0.082s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.19547, val loss: 0.19778, in 0.058s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.19492, val loss: 0.19729, in 0.071s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.19433, val loss: 0.19670, in 0.066s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.19352, val loss: 0.19592, in 0.050s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.19287, val loss: 0.19528, in 0.082s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.19235, val loss: 0.19486, in 0.057s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.19167, val loss: 0.19420, in 0.056s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.19116, val loss: 0.19370, in 0.061s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.19079, val loss: 0.19335, in 0.059s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.19036, val loss: 0.19294, in 0.064s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18998, val loss: 0.19259, in 0.046s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18966, val loss: 0.19228, in 0.042s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18939, val loss: 0.19201, in 0.044s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18915, val loss: 0.19180, in 0.049s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.18897, val loss: 0.19163, in 0.061s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18859, val loss: 0.19133, in 0.059s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18837, val loss: 0.19112, in 0.048s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18814, val loss: 0.19089, in 0.052s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18794, val loss: 0.19073, in 0.065s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18769, val loss: 0.19045, in 0.058s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18739, val loss: 0.19013, in 0.044s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18726, val loss: 0.19003, in 0.049s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18705, val loss: 0.18982, in 0.044s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18672, val loss: 0.18947, in 0.057s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18655, val loss: 0.18928, in 0.079s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18635, val loss: 0.18908, in 0.055s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18600, val loss: 0.18876, in 0.052s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18577, val loss: 0.18854, in 0.045s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18557, val loss: 0.18835, in 0.057s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18543, val loss: 0.18819, in 0.042s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18532, val loss: 0.18810, in 0.041s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18515, val loss: 0.18793, in 0.049s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18504, val loss: 0.18783, in 0.052s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18487, val loss: 0.18766, in 1.107s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.18476, val loss: 0.18756, in 0.368s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18460, val loss: 0.18740, in 0.054s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18449, val loss: 0.18732, in 0.045s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18438, val loss: 0.18721, in 0.047s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18425, val loss: 0.18710, in 0.042s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18416, val loss: 0.18703, in 0.046s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.18401, val loss: 0.18686, in 0.043s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18384, val loss: 0.18673, in 0.042s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.18374, val loss: 0.18666, in 0.032s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18365, val loss: 0.18660, in 0.030s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18353, val loss: 0.18650, in 0.045s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18337, val loss: 0.18636, in 0.043s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18325, val loss: 0.18626, in 0.046s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18312, val loss: 0.18615, in 0.038s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.18303, val loss: 0.18605, in 0.046s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18296, val loss: 0.18599, in 0.042s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.18275, val loss: 0.18574, in 0.059s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18268, val loss: 0.18571, in 0.041s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18252, val loss: 0.18554, in 0.041s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18242, val loss: 0.18545, in 0.045s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18230, val loss: 0.18532, in 0.056s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.18219, val loss: 0.18521, in 0.045s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18210, val loss: 0.18514, in 0.042s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18203, val loss: 0.18510, in 0.042s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18196, val loss: 0.18505, in 0.039s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18183, val loss: 0.18494, in 0.054s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18177, val loss: 0.18490, in 0.047s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18168, val loss: 0.18482, in 0.052s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18158, val loss: 0.18474, in 0.046s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.18150, val loss: 0.18467, in 0.034s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18144, val loss: 0.18461, in 0.033s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18137, val loss: 0.18455, in 0.032s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18124, val loss: 0.18442, in 0.055s\n",
      "Fit 100 trees in 13.013 s, (3100 total leaves)\n",
      "Time spent computing histograms: 5.304s\n",
      "Time spent finding best splits:  1.463s\n",
      "Time spent applying splits:      2.297s\n",
      "Time spent predicting:           0.143s\n",
      "Binning 0.178 GB of training data: 1.367 s\n",
      "Binning 0.020 GB of validation data: 0.040 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.40654, val loss: 0.40671, in 0.057s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.33082, val loss: 0.33102, in 0.047s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.26947, val loss: 0.26970, in 0.048s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.21977, val loss: 0.22002, in 0.049s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.17952, val loss: 0.17978, in 0.058s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.14683, val loss: 0.14710, in 0.050s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.12034, val loss: 0.12062, in 0.050s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09884, val loss: 0.09912, in 0.065s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08146, val loss: 0.08174, in 0.052s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06719, val loss: 0.06747, in 0.047s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05557, val loss: 0.05584, in 0.050s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04631, val loss: 0.04659, in 0.049s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03850, val loss: 0.03881, in 0.045s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03211, val loss: 0.03243, in 0.059s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02708, val loss: 0.02743, in 0.060s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02287, val loss: 0.02321, in 0.061s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01947, val loss: 0.01979, in 0.053s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01677, val loss: 0.01712, in 0.073s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01448, val loss: 0.01482, in 0.140s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01258, val loss: 0.01292, in 0.101s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01113, val loss: 0.01150, in 0.049s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00989, val loss: 0.01024, in 0.050s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00889, val loss: 0.00923, in 0.058s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00809, val loss: 0.00845, in 0.056s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00738, val loss: 0.00775, in 0.051s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00681, val loss: 0.00718, in 0.077s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00636, val loss: 0.00672, in 0.106s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00594, val loss: 0.00632, in 0.053s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00563, val loss: 0.00602, in 0.050s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00534, val loss: 0.00575, in 0.043s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00508, val loss: 0.00549, in 0.055s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00528, in 0.052s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00470, val loss: 0.00511, in 0.042s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00458, val loss: 0.00499, in 0.052s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00445, val loss: 0.00485, in 0.141s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00435, val loss: 0.00474, in 0.879s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00424, val loss: 0.00464, in 0.291s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00416, val loss: 0.00457, in 0.544s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00410, val loss: 0.00450, in 0.178s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00403, val loss: 0.00444, in 0.138s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00399, val loss: 0.00439, in 0.086s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.00395, val loss: 0.00435, in 0.063s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00392, val loss: 0.00431, in 0.065s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00388, val loss: 0.00428, in 0.045s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00385, val loss: 0.00425, in 0.064s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00383, val loss: 0.00423, in 0.073s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00378, val loss: 0.00419, in 0.128s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00370, val loss: 0.00412, in 0.049s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00368, val loss: 0.00410, in 0.043s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00366, val loss: 0.00408, in 0.035s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00364, val loss: 0.00407, in 0.038s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00358, val loss: 0.00401, in 0.046s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00356, val loss: 0.00399, in 0.050s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00397, in 0.049s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00353, val loss: 0.00396, in 0.039s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00351, val loss: 0.00395, in 0.046s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00350, val loss: 0.00395, in 0.039s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00345, val loss: 0.00390, in 0.046s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00344, val loss: 0.00387, in 0.059s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00342, val loss: 0.00385, in 0.054s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00337, val loss: 0.00380, in 0.049s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00335, val loss: 0.00380, in 0.044s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00330, val loss: 0.00375, in 0.051s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00329, val loss: 0.00375, in 0.045s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00326, val loss: 0.00372, in 0.045s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.00325, val loss: 0.00371, in 0.045s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00324, val loss: 0.00369, in 0.048s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00321, val loss: 0.00367, in 0.055s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00321, val loss: 0.00367, in 0.116s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00319, val loss: 0.00366, in 0.053s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00364, in 0.040s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00315, val loss: 0.00362, in 0.047s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00315, val loss: 0.00362, in 0.041s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.00314, val loss: 0.00361, in 0.060s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00313, val loss: 0.00361, in 0.034s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00359, in 0.030s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00310, val loss: 0.00358, in 0.034s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00310, val loss: 0.00358, in 0.030s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00309, val loss: 0.00357, in 0.044s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00308, val loss: 0.00356, in 0.052s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00307, val loss: 0.00355, in 0.047s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00306, val loss: 0.00355, in 0.049s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00305, val loss: 0.00354, in 0.054s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00305, val loss: 0.00354, in 0.032s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00304, val loss: 0.00353, in 0.040s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00302, val loss: 0.00352, in 0.065s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00300, val loss: 0.00351, in 1.014s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00300, val loss: 0.00351, in 0.159s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00299, val loss: 0.00350, in 0.228s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00299, val loss: 0.00349, in 0.336s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00295, val loss: 0.00345, in 0.049s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00294, val loss: 0.00344, in 0.043s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00293, val loss: 0.00344, in 0.036s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00293, val loss: 0.00343, in 0.042s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00292, val loss: 0.00343, in 0.037s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00291, val loss: 0.00342, in 0.037s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00290, val loss: 0.00342, in 0.040s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00289, val loss: 0.00341, in 0.042s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00288, val loss: 0.00340, in 0.029s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00340, in 0.037s\n",
      "Fit 100 trees in 10.270 s, (3100 total leaves)\n",
      "Time spent computing histograms: 4.363s\n",
      "Time spent finding best splits:  1.210s\n",
      "Time spent applying splits:      1.844s\n",
      "Time spent predicting:           0.127s\n",
      "Binning 0.178 GB of training data: 0.306 s\n",
      "Binning 0.020 GB of validation data: 0.038 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41319, val loss: 0.41485, in 0.066s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.34298, val loss: 0.34430, in 0.068s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.28603, val loss: 0.28701, in 0.065s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.23997, val loss: 0.24107, in 0.054s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.20222, val loss: 0.20335, in 0.054s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.17171, val loss: 0.17282, in 0.052s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14655, val loss: 0.14735, in 0.059s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.12614, val loss: 0.12695, in 0.063s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.10947, val loss: 0.11001, in 0.064s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09611, val loss: 0.09665, in 0.070s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08512, val loss: 0.08546, in 0.061s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.07602, val loss: 0.07621, in 0.063s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06814, val loss: 0.06820, in 0.068s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06173, val loss: 0.06170, in 0.061s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05646, val loss: 0.05638, in 0.059s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05214, val loss: 0.05201, in 0.070s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04859, val loss: 0.04842, in 0.053s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04565, val loss: 0.04543, in 0.052s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04345, val loss: 0.04324, in 0.058s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04138, val loss: 0.04118, in 0.061s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03966, val loss: 0.03946, in 0.049s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03820, val loss: 0.03795, in 0.052s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03705, val loss: 0.03680, in 0.097s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03598, val loss: 0.03572, in 0.055s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03513, val loss: 0.03486, in 0.047s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03446, val loss: 0.03421, in 0.042s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03386, val loss: 0.03361, in 0.045s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03333, val loss: 0.03308, in 0.046s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03289, val loss: 0.03265, in 0.052s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03251, val loss: 0.03226, in 0.049s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03204, val loss: 0.03177, in 0.047s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03174, val loss: 0.03144, in 0.052s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03139, val loss: 0.03110, in 0.048s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03115, val loss: 0.03087, in 0.046s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.03094, val loss: 0.03065, in 0.055s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03066, val loss: 0.03039, in 0.048s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03043, val loss: 0.03017, in 0.056s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03026, val loss: 0.03000, in 0.047s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.03011, val loss: 0.02986, in 0.046s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02997, val loss: 0.02971, in 0.046s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02966, val loss: 0.02942, in 0.058s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02941, val loss: 0.02919, in 0.041s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02922, val loss: 0.02900, in 0.058s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02911, val loss: 0.02889, in 0.046s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02898, val loss: 0.02876, in 0.058s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.02885, val loss: 0.02863, in 0.045s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02867, val loss: 0.02847, in 0.041s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02860, val loss: 0.02840, in 0.045s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02842, val loss: 0.02823, in 0.042s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02836, val loss: 0.02818, in 0.054s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02822, val loss: 0.02803, in 0.039s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02816, val loss: 0.02798, in 0.044s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02805, val loss: 0.02788, in 0.046s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.02794, val loss: 0.02778, in 0.055s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02782, val loss: 0.02767, in 0.086s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02774, val loss: 0.02758, in 0.079s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02766, val loss: 0.02752, in 0.039s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.02760, val loss: 0.02746, in 0.052s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02750, val loss: 0.02737, in 0.028s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02745, val loss: 0.02732, in 0.059s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02738, val loss: 0.02726, in 0.071s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02729, val loss: 0.02720, in 0.048s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02724, val loss: 0.02717, in 0.037s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02719, val loss: 0.02712, in 0.035s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02714, val loss: 0.02705, in 0.051s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02705, val loss: 0.02697, in 0.053s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.02698, val loss: 0.02692, in 0.059s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02692, val loss: 0.02686, in 0.047s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02684, val loss: 0.02679, in 0.058s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02679, val loss: 0.02674, in 0.055s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02677, val loss: 0.02672, in 0.059s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02674, val loss: 0.02670, in 0.054s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02667, val loss: 0.02664, in 0.089s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02662, val loss: 0.02659, in 0.903s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02658, val loss: 0.02655, in 0.080s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02653, val loss: 0.02651, in 0.205s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02649, val loss: 0.02647, in 0.049s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02645, val loss: 0.02643, in 0.067s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02643, val loss: 0.02641, in 0.042s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02631, val loss: 0.02629, in 0.063s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02629, val loss: 0.02628, in 0.040s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02627, val loss: 0.02626, in 0.040s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02625, val loss: 0.02624, in 0.041s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02621, val loss: 0.02620, in 0.043s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02619, val loss: 0.02619, in 0.041s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02616, val loss: 0.02616, in 0.043s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02611, val loss: 0.02610, in 0.035s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02608, val loss: 0.02608, in 0.040s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02601, val loss: 0.02600, in 0.044s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02595, val loss: 0.02594, in 0.039s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02592, val loss: 0.02590, in 0.039s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02589, val loss: 0.02588, in 0.043s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02586, val loss: 0.02585, in 0.042s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02582, val loss: 0.02582, in 0.036s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02581, val loss: 0.02582, in 0.036s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02579, val loss: 0.02580, in 0.040s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.02577, val loss: 0.02578, in 0.037s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02573, val loss: 0.02575, in 0.047s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02569, val loss: 0.02570, in 0.040s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02567, val loss: 0.02569, in 0.042s\n",
      "Fit 100 trees in 6.701 s, (3100 total leaves)\n",
      "Time spent computing histograms: 3.412s\n",
      "Time spent finding best splits:  0.788s\n",
      "Time spent applying splits:      1.287s\n",
      "Time spent predicting:           0.087s\n",
      "Binning 0.178 GB of training data: 0.246 s\n",
      "Binning 0.020 GB of validation data: 0.027 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.43795, val loss: 0.43837, in 0.064s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.38769, val loss: 0.38813, in 0.066s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.34693, val loss: 0.34740, in 0.063s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.31386, val loss: 0.31435, in 0.056s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.28694, val loss: 0.28747, in 0.060s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.26506, val loss: 0.26559, in 0.143s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.24737, val loss: 0.24794, in 0.114s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.23280, val loss: 0.23344, in 0.097s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.22106, val loss: 0.22171, in 0.051s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.21146, val loss: 0.21211, in 0.077s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.20355, val loss: 0.20423, in 0.071s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.19701, val loss: 0.19767, in 0.052s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.19172, val loss: 0.19240, in 0.065s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18715, val loss: 0.18784, in 0.073s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18345, val loss: 0.18411, in 0.063s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18024, val loss: 0.18095, in 0.068s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.17771, val loss: 0.17841, in 0.056s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.17541, val loss: 0.17615, in 0.061s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.17346, val loss: 0.17424, in 0.066s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.17185, val loss: 0.17269, in 0.064s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.17054, val loss: 0.17142, in 0.054s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.16941, val loss: 0.17030, in 0.050s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.16845, val loss: 0.16936, in 0.057s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16756, val loss: 0.16846, in 0.052s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16678, val loss: 0.16768, in 0.056s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16616, val loss: 0.16710, in 0.050s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.16555, val loss: 0.16649, in 0.056s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16508, val loss: 0.16604, in 0.088s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16456, val loss: 0.16552, in 0.053s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16412, val loss: 0.16508, in 0.060s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16363, val loss: 0.16459, in 0.056s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16319, val loss: 0.16417, in 0.059s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.16281, val loss: 0.16379, in 0.051s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.16236, val loss: 0.16331, in 0.047s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16207, val loss: 0.16299, in 0.052s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16178, val loss: 0.16269, in 0.048s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.16132, val loss: 0.16226, in 0.044s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.16099, val loss: 0.16196, in 0.052s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.16066, val loss: 0.16163, in 0.044s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.16034, val loss: 0.16133, in 0.045s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16011, val loss: 0.16110, in 0.050s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15989, val loss: 0.16090, in 0.049s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15968, val loss: 0.16066, in 0.050s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15947, val loss: 0.16045, in 0.057s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15925, val loss: 0.16021, in 0.052s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15908, val loss: 0.16005, in 0.061s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15893, val loss: 0.15990, in 0.069s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15877, val loss: 0.15979, in 0.053s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15857, val loss: 0.15959, in 0.063s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15844, val loss: 0.15948, in 0.044s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15829, val loss: 0.15933, in 0.048s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15815, val loss: 0.15918, in 0.048s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15802, val loss: 0.15908, in 0.043s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15790, val loss: 0.15897, in 0.045s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15782, val loss: 0.15889, in 0.042s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15769, val loss: 0.15878, in 0.047s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15759, val loss: 0.15867, in 0.053s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15750, val loss: 0.15860, in 0.040s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15743, val loss: 0.15853, in 0.048s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15731, val loss: 0.15842, in 0.048s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15719, val loss: 0.15831, in 0.041s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15698, val loss: 0.15811, in 0.052s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15689, val loss: 0.15804, in 0.049s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15680, val loss: 0.15796, in 0.045s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15672, val loss: 0.15789, in 0.042s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15665, val loss: 0.15783, in 0.043s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15655, val loss: 0.15772, in 0.052s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15648, val loss: 0.15766, in 0.036s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15642, val loss: 0.15761, in 0.038s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15636, val loss: 0.15756, in 0.053s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15628, val loss: 0.15747, in 0.051s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15623, val loss: 0.15743, in 0.038s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15615, val loss: 0.15737, in 0.038s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15611, val loss: 0.15734, in 0.037s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15606, val loss: 0.15729, in 0.040s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15599, val loss: 0.15721, in 0.042s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.15592, val loss: 0.15716, in 0.050s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15586, val loss: 0.15711, in 0.041s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15578, val loss: 0.15703, in 0.049s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15573, val loss: 0.15699, in 0.066s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15570, val loss: 0.15696, in 0.314s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15563, val loss: 0.15690, in 0.077s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.15555, val loss: 0.15683, in 0.403s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15548, val loss: 0.15676, in 0.632s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15533, val loss: 0.15664, in 0.232s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15531, val loss: 0.15663, in 0.684s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15523, val loss: 0.15656, in 0.172s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15517, val loss: 0.15651, in 0.101s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15509, val loss: 0.15642, in 0.082s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15501, val loss: 0.15635, in 0.106s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15496, val loss: 0.15632, in 0.120s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15492, val loss: 0.15629, in 0.139s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.15487, val loss: 0.15624, in 0.190s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15484, val loss: 0.15622, in 0.100s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15479, val loss: 0.15618, in 0.078s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15476, val loss: 0.15616, in 0.093s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15469, val loss: 0.15606, in 0.076s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.15452, val loss: 0.15588, in 0.081s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15446, val loss: 0.15584, in 0.127s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15441, val loss: 0.15578, in 0.085s\n",
      "Fit 100 trees in 8.734 s, (3100 total leaves)\n",
      "Time spent computing histograms: 4.376s\n",
      "Time spent finding best splits:  1.194s\n",
      "Time spent applying splits:      1.679s\n",
      "Time spent predicting:           0.143s\n",
      "Binning 0.178 GB of training data: 0.419 s\n",
      "Binning 0.020 GB of validation data: 0.052 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 11 leaves, max depth = 5, train loss: 0.40501, val loss: 0.40491, in 0.043s\n",
      "[2/100] 1 tree, 13 leaves, max depth = 6, train loss: 0.32806, val loss: 0.32798, in 0.081s\n",
      "[3/100] 1 tree, 17 leaves, max depth = 6, train loss: 0.26573, val loss: 0.26566, in 0.101s\n",
      "[4/100] 1 tree, 28 leaves, max depth = 7, train loss: 0.21524, val loss: 0.21518, in 0.127s\n",
      "[5/100] 1 tree, 8 leaves, max depth = 4, train loss: 0.17434, val loss: 0.17430, in 0.072s\n",
      "[6/100] 1 tree, 19 leaves, max depth = 6, train loss: 0.14122, val loss: 0.14118, in 0.076s\n",
      "[7/100] 1 tree, 10 leaves, max depth = 4, train loss: 0.11439, val loss: 0.11436, in 0.108s\n",
      "[8/100] 1 tree, 7 leaves, max depth = 5, train loss: 0.09265, val loss: 0.09263, in 0.048s\n",
      "[9/100] 1 tree, 9 leaves, max depth = 5, train loss: 0.07505, val loss: 0.07503, in 0.075s\n",
      "[10/100] 1 tree, 19 leaves, max depth = 5, train loss: 0.06079, val loss: 0.06077, in 0.074s\n",
      "[11/100] 1 tree, 24 leaves, max depth = 7, train loss: 0.04924, val loss: 0.04923, in 0.085s\n",
      "[12/100] 1 tree, 19 leaves, max depth = 6, train loss: 0.03988, val loss: 0.03987, in 0.096s\n",
      "[13/100] 1 tree, 17 leaves, max depth = 6, train loss: 0.03231, val loss: 0.03230, in 0.053s\n",
      "[14/100] 1 tree, 17 leaves, max depth = 6, train loss: 0.02617, val loss: 0.02616, in 0.059s\n",
      "[15/100] 1 tree, 18 leaves, max depth = 7, train loss: 0.02120, val loss: 0.02119, in 0.080s\n",
      "[16/100] 1 tree, 15 leaves, max depth = 7, train loss: 0.01717, val loss: 0.01716, in 0.127s\n",
      "[17/100] 1 tree, 15 leaves, max depth = 5, train loss: 0.01391, val loss: 0.01390, in 0.083s\n",
      "[18/100] 1 tree, 15 leaves, max depth = 6, train loss: 0.01126, val loss: 0.01126, in 0.104s\n",
      "[19/100] 1 tree, 12 leaves, max depth = 6, train loss: 0.00912, val loss: 0.00912, in 0.064s\n",
      "[20/100] 1 tree, 18 leaves, max depth = 6, train loss: 0.00739, val loss: 0.00739, in 0.090s\n",
      "[21/100] 1 tree, 11 leaves, max depth = 5, train loss: 0.00599, val loss: 0.00598, in 0.083s\n",
      "[22/100] 1 tree, 18 leaves, max depth = 8, train loss: 0.00485, val loss: 0.00485, in 0.061s\n",
      "[23/100] 1 tree, 16 leaves, max depth = 7, train loss: 0.00393, val loss: 0.00393, in 0.058s\n",
      "[24/100] 1 tree, 12 leaves, max depth = 6, train loss: 0.00318, val loss: 0.00318, in 0.061s\n",
      "[25/100] 1 tree, 8 leaves, max depth = 5, train loss: 0.00258, val loss: 0.00258, in 0.047s\n",
      "[26/100] 1 tree, 17 leaves, max depth = 5, train loss: 0.00209, val loss: 0.00209, in 0.058s\n",
      "[27/100] 1 tree, 29 leaves, max depth = 9, train loss: 0.00169, val loss: 0.00169, in 0.074s\n",
      "[28/100] 1 tree, 13 leaves, max depth = 5, train loss: 0.00137, val loss: 0.00137, in 0.053s\n",
      "[29/100] 1 tree, 11 leaves, max depth = 5, train loss: 0.00111, val loss: 0.00111, in 0.048s\n",
      "[30/100] 1 tree, 24 leaves, max depth = 7, train loss: 0.00090, val loss: 0.00090, in 0.091s\n",
      "[31/100] 1 tree, 16 leaves, max depth = 6, train loss: 0.00073, val loss: 0.00073, in 0.064s\n",
      "[32/100] 1 tree, 17 leaves, max depth = 7, train loss: 0.00059, val loss: 0.00059, in 0.058s\n",
      "[33/100] 1 tree, 14 leaves, max depth = 6, train loss: 0.00048, val loss: 0.00048, in 0.065s\n",
      "[34/100] 1 tree, 15 leaves, max depth = 6, train loss: 0.00039, val loss: 0.00039, in 0.056s\n",
      "[35/100] 1 tree, 11 leaves, max depth = 5, train loss: 0.00031, val loss: 0.00031, in 0.058s\n",
      "[36/100] 1 tree, 15 leaves, max depth = 5, train loss: 0.00025, val loss: 0.00025, in 0.050s\n",
      "[37/100] 1 tree, 17 leaves, max depth = 6, train loss: 0.00021, val loss: 0.00021, in 0.051s\n",
      "[38/100] 1 tree, 12 leaves, max depth = 5, train loss: 0.00017, val loss: 0.00017, in 0.050s\n",
      "[39/100] 1 tree, 16 leaves, max depth = 6, train loss: 0.00013, val loss: 0.00013, in 0.051s\n",
      "[40/100] 1 tree, 9 leaves, max depth = 4, train loss: 0.00011, val loss: 0.00011, in 0.039s\n",
      "[41/100] 1 tree, 15 leaves, max depth = 6, train loss: 0.00009, val loss: 0.00009, in 0.047s\n",
      "[42/100] 1 tree, 18 leaves, max depth = 6, train loss: 0.00007, val loss: 0.00007, in 0.047s\n",
      "[43/100] 1 tree, 16 leaves, max depth = 5, train loss: 0.00006, val loss: 0.00006, in 0.051s\n",
      "[44/100] 1 tree, 8 leaves, max depth = 4, train loss: 0.00005, val loss: 0.00005, in 0.041s\n",
      "[45/100] 1 tree, 11 leaves, max depth = 4, train loss: 0.00004, val loss: 0.00004, in 0.050s\n",
      "[46/100] 1 tree, 13 leaves, max depth = 5, train loss: 0.00003, val loss: 0.00003, in 0.052s\n",
      "[47/100] 1 tree, 10 leaves, max depth = 4, train loss: 0.00002, val loss: 0.00002, in 0.042s\n",
      "[48/100] 1 tree, 10 leaves, max depth = 7, train loss: 0.00002, val loss: 0.00002, in 0.052s\n",
      "[49/100] 1 tree, 7 leaves, max depth = 3, train loss: 0.00002, val loss: 0.00002, in 0.040s\n",
      "[50/100] 1 tree, 19 leaves, max depth = 7, train loss: 0.00001, val loss: 0.00001, in 0.054s\n",
      "[51/100] 1 tree, 8 leaves, max depth = 5, train loss: 0.00001, val loss: 0.00001, in 0.040s\n",
      "[52/100] 1 tree, 9 leaves, max depth = 4, train loss: 0.00001, val loss: 0.00001, in 0.044s\n",
      "[53/100] 1 tree, 12 leaves, max depth = 4, train loss: 0.00001, val loss: 0.00001, in 0.068s\n",
      "[54/100] 1 tree, 18 leaves, max depth = 6, train loss: 0.00001, val loss: 0.00001, in 0.063s\n",
      "[55/100] 1 tree, 13 leaves, max depth = 5, train loss: 0.00000, val loss: 0.00000, in 0.078s\n",
      "[56/100] 1 tree, 12 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.059s\n",
      "[57/100] 1 tree, 21 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.072s\n",
      "[58/100] 1 tree, 18 leaves, max depth = 7, train loss: 0.00000, val loss: 0.00000, in 0.059s\n",
      "[59/100] 1 tree, 9 leaves, max depth = 5, train loss: 0.00000, val loss: 0.00000, in 0.048s\n",
      "[60/100] 1 tree, 11 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.078s\n",
      "[61/100] 1 tree, 27 leaves, max depth = 8, train loss: 0.00000, val loss: 0.00000, in 0.096s\n",
      "[62/100] 1 tree, 14 leaves, max depth = 5, train loss: 0.00000, val loss: 0.00000, in 0.064s\n",
      "[63/100] 1 tree, 11 leaves, max depth = 5, train loss: 0.00000, val loss: 0.00000, in 0.065s\n",
      "[64/100] 1 tree, 10 leaves, max depth = 4, train loss: 0.00000, val loss: 0.00000, in 0.054s\n",
      "[65/100] 1 tree, 19 leaves, max depth = 5, train loss: 0.00000, val loss: 0.00000, in 0.076s\n",
      "[66/100] 1 tree, 16 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.054s\n",
      "[67/100] 1 tree, 18 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.056s\n",
      "[68/100] 1 tree, 16 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.095s\n",
      "[69/100] 1 tree, 11 leaves, max depth = 5, train loss: 0.00000, val loss: 0.00000, in 0.050s\n",
      "[70/100] 1 tree, 8 leaves, max depth = 4, train loss: 0.00000, val loss: 0.00000, in 0.055s\n",
      "[71/100] 1 tree, 16 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.055s\n",
      "[72/100] 1 tree, 8 leaves, max depth = 4, train loss: 0.00000, val loss: 0.00000, in 0.084s\n",
      "[73/100] 1 tree, 7 leaves, max depth = 5, train loss: 0.00000, val loss: 0.00000, in 0.049s\n",
      "[74/100] 1 tree, 21 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.087s\n",
      "[75/100] 1 tree, 13 leaves, max depth = 5, train loss: 0.00000, val loss: 0.00000, in 0.053s\n",
      "[76/100] 1 tree, 13 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.062s\n",
      "[77/100] 1 tree, 8 leaves, max depth = 4, train loss: 0.00000, val loss: 0.00000, in 0.059s\n",
      "[78/100] 1 tree, 17 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.078s\n",
      "[79/100] 1 tree, 13 leaves, max depth = 6, train loss: 0.00000, val loss: 0.00000, in 0.055s\n",
      "[80/100] 1 tree, 21 leaves, max depth = 7, train loss: 0.00000, val loss: 0.00000, in 0.088s\n",
      "[81/100] 1 tree, 10 leaves, max depth = 5, train loss: 0.00000, val loss: 0.00000, in 0.083s\n",
      "[82/100] 1 tree, 8 leaves, max depth = 4, train loss: 0.00000, val loss: 0.00000, in 0.050s\n",
      "[83/100] 1 tree, 30 leaves, max depth = 7, train loss: 0.00000, val loss: 0.00000, in 0.058s\n",
      "Fit 83 trees in 6.062 s, (1205 total leaves)\n",
      "Time spent computing histograms: 3.429s\n",
      "Time spent finding best splits:  0.496s\n",
      "Time spent applying splits:      0.949s\n",
      "Time spent predicting:           0.055s\n",
      "Binning 0.092 GB of training data: 0.173 s\n",
      "Binning 0.010 GB of validation data: 0.017 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.46925, val loss: 0.44711, in 0.052s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.43983, val loss: 0.42005, in 0.047s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41587, val loss: 0.39794, in 0.045s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.39806, val loss: 0.38044, in 0.410s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.37834, val loss: 0.36141, in 0.819s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.36474, val loss: 0.34951, in 0.101s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.35337, val loss: 0.33864, in 0.175s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.34500, val loss: 0.33182, in 0.079s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.33698, val loss: 0.32412, in 0.039s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.33032, val loss: 0.31782, in 0.033s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.32406, val loss: 0.31266, in 0.055s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.31835, val loss: 0.30815, in 0.032s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.31410, val loss: 0.30410, in 0.042s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.31011, val loss: 0.30200, in 0.062s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.30464, val loss: 0.29626, in 0.032s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.30116, val loss: 0.29411, in 0.028s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.29483, val loss: 0.28763, in 0.034s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.28923, val loss: 0.28219, in 0.043s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.28651, val loss: 0.27999, in 0.057s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.28474, val loss: 0.27901, in 0.052s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.28181, val loss: 0.27651, in 0.040s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.27930, val loss: 0.27498, in 0.036s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.27682, val loss: 0.27414, in 0.063s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.27406, val loss: 0.27214, in 0.040s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.27150, val loss: 0.26999, in 0.046s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.26973, val loss: 0.26899, in 0.027s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.26825, val loss: 0.26825, in 0.029s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.26539, val loss: 0.26574, in 0.113s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.26389, val loss: 0.26468, in 0.124s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.26241, val loss: 0.26413, in 0.034s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.26099, val loss: 0.26382, in 0.035s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.25973, val loss: 0.26368, in 0.030s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.25820, val loss: 0.26265, in 0.036s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.25612, val loss: 0.26131, in 0.037s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.25501, val loss: 0.26087, in 0.069s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.25310, val loss: 0.25909, in 0.062s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.25209, val loss: 0.25895, in 0.033s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.25078, val loss: 0.25813, in 0.042s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.25011, val loss: 0.25784, in 0.031s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.24864, val loss: 0.25657, in 0.044s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.24717, val loss: 0.25548, in 0.038s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.24632, val loss: 0.25524, in 0.037s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.24540, val loss: 0.25462, in 0.037s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.24417, val loss: 0.25368, in 0.028s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.24320, val loss: 0.25286, in 0.024s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.24293, val loss: 0.25287, in 0.023s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.24244, val loss: 0.25282, in 0.024s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.24180, val loss: 0.25268, in 0.028s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.24112, val loss: 0.25270, in 0.033s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.24075, val loss: 0.25257, in 0.021s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.24006, val loss: 0.25172, in 0.026s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.23976, val loss: 0.25173, in 0.025s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.23879, val loss: 0.25075, in 0.030s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.23826, val loss: 0.25024, in 0.025s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.23758, val loss: 0.24988, in 0.023s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.23734, val loss: 0.24987, in 0.026s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.23684, val loss: 0.24948, in 0.027s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.23658, val loss: 0.24936, in 0.027s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.23630, val loss: 0.24944, in 0.032s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.23578, val loss: 0.24905, in 0.025s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.23536, val loss: 0.24908, in 0.027s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.23511, val loss: 0.24917, in 0.023s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.23469, val loss: 0.24905, in 0.024s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.23438, val loss: 0.24888, in 0.025s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.23387, val loss: 0.24871, in 0.027s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.23364, val loss: 0.24870, in 0.026s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.23313, val loss: 0.24853, in 0.025s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.23277, val loss: 0.24822, in 0.026s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.23241, val loss: 0.24812, in 0.026s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.23216, val loss: 0.24791, in 0.028s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.23202, val loss: 0.24788, in 0.060s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.23165, val loss: 0.24777, in 0.025s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.23149, val loss: 0.24770, in 0.026s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.23118, val loss: 0.24745, in 0.025s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.23092, val loss: 0.24749, in 0.025s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.23080, val loss: 0.24738, in 0.025s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.23067, val loss: 0.24735, in 0.025s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.23058, val loss: 0.24733, in 0.034s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.23028, val loss: 0.24713, in 0.033s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.23011, val loss: 0.24704, in 0.029s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.22994, val loss: 0.24704, in 0.029s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.22978, val loss: 0.24707, in 0.029s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.22943, val loss: 0.24676, in 0.030s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.22911, val loss: 0.24681, in 0.033s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.22900, val loss: 0.24679, in 0.027s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.22860, val loss: 0.24662, in 0.035s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.22808, val loss: 0.24618, in 0.027s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.22783, val loss: 0.24600, in 0.031s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.22759, val loss: 0.24595, in 0.037s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.22736, val loss: 0.24584, in 0.029s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.22712, val loss: 0.24572, in 0.031s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.22703, val loss: 0.24571, in 0.027s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.22692, val loss: 0.24573, in 0.025s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.22665, val loss: 0.24558, in 0.030s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.22639, val loss: 0.24567, in 0.044s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.22622, val loss: 0.24569, in 0.037s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.22606, val loss: 0.24554, in 0.030s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.22591, val loss: 0.24549, in 0.032s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.22581, val loss: 0.24549, in 0.027s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.22538, val loss: 0.24510, in 0.026s\n",
      "Fit 100 trees in 5.199 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.373s\n",
      "Time spent finding best splits:  0.769s\n",
      "Time spent applying splits:      1.167s\n",
      "Time spent predicting:           0.050s\n",
      "Binning 0.089 GB of training data: 0.160 s\n",
      "Binning 0.010 GB of validation data: 0.020 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41272, val loss: 0.40977, in 0.047s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.34159, val loss: 0.33900, in 0.048s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.28381, val loss: 0.28153, in 0.041s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.23667, val loss: 0.23461, in 0.035s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.19845, val loss: 0.19670, in 0.033s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16719, val loss: 0.16561, in 0.032s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14180, val loss: 0.14033, in 0.034s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.12084, val loss: 0.11949, in 0.033s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10376, val loss: 0.10257, in 0.035s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08962, val loss: 0.08856, in 0.033s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07803, val loss: 0.07705, in 0.035s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06841, val loss: 0.06752, in 0.033s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06052, val loss: 0.05968, in 0.034s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05387, val loss: 0.05312, in 0.044s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04846, val loss: 0.04775, in 0.037s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04406, val loss: 0.04341, in 0.037s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04026, val loss: 0.03963, in 0.036s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03710, val loss: 0.03651, in 0.062s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03450, val loss: 0.03394, in 0.040s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03224, val loss: 0.03169, in 0.038s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.03028, val loss: 0.02975, in 0.036s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02873, val loss: 0.02820, in 0.035s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02721, val loss: 0.02671, in 0.033s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02593, val loss: 0.02544, in 0.032s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02492, val loss: 0.02446, in 0.035s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02403, val loss: 0.02359, in 0.035s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02328, val loss: 0.02286, in 0.051s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02263, val loss: 0.02221, in 0.138s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02205, val loss: 0.02164, in 0.272s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02155, val loss: 0.02116, in 0.614s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02106, val loss: 0.02067, in 0.198s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02061, val loss: 0.02025, in 0.256s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02023, val loss: 0.01989, in 0.069s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01989, val loss: 0.01957, in 0.041s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01959, val loss: 0.01927, in 0.044s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01923, val loss: 0.01892, in 0.039s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01896, val loss: 0.01867, in 0.041s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01867, val loss: 0.01839, in 0.034s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01839, val loss: 0.01813, in 0.031s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01815, val loss: 0.01791, in 0.029s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01789, val loss: 0.01766, in 0.029s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01768, val loss: 0.01746, in 0.033s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01744, val loss: 0.01723, in 0.032s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01727, val loss: 0.01707, in 0.034s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01707, val loss: 0.01689, in 0.035s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01689, val loss: 0.01670, in 0.040s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01674, val loss: 0.01655, in 0.036s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01660, val loss: 0.01641, in 0.090s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01645, val loss: 0.01628, in 0.045s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01632, val loss: 0.01615, in 0.060s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01620, val loss: 0.01604, in 0.077s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01606, val loss: 0.01591, in 0.048s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01595, val loss: 0.01581, in 0.066s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01582, val loss: 0.01568, in 0.046s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01571, val loss: 0.01558, in 0.045s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01558, val loss: 0.01545, in 0.048s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01547, val loss: 0.01534, in 0.039s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01536, val loss: 0.01523, in 0.046s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01528, val loss: 0.01515, in 0.049s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01518, val loss: 0.01505, in 0.041s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01506, val loss: 0.01495, in 0.044s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01496, val loss: 0.01485, in 0.045s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01486, val loss: 0.01476, in 0.041s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01476, val loss: 0.01467, in 0.059s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01467, val loss: 0.01458, in 0.058s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01453, val loss: 0.01444, in 0.072s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01446, val loss: 0.01438, in 0.131s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01438, val loss: 0.01430, in 0.052s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01430, val loss: 0.01423, in 0.049s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01422, val loss: 0.01416, in 0.071s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01416, val loss: 0.01411, in 0.058s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01405, val loss: 0.01401, in 0.060s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01398, val loss: 0.01395, in 0.051s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01389, val loss: 0.01386, in 0.056s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01380, val loss: 0.01378, in 0.064s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01375, val loss: 0.01374, in 0.059s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01368, val loss: 0.01368, in 0.085s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01362, val loss: 0.01363, in 0.065s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01356, val loss: 0.01357, in 0.061s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01349, val loss: 0.01351, in 0.059s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01343, val loss: 0.01345, in 0.066s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01338, val loss: 0.01340, in 0.046s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01333, val loss: 0.01335, in 0.045s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01326, val loss: 0.01328, in 0.037s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01320, val loss: 0.01322, in 0.037s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01312, val loss: 0.01315, in 0.035s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01307, val loss: 0.01311, in 0.034s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01302, val loss: 0.01306, in 0.037s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01298, val loss: 0.01302, in 0.035s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01295, val loss: 0.01299, in 0.051s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01289, val loss: 0.01293, in 0.051s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01284, val loss: 0.01290, in 0.035s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01280, val loss: 0.01286, in 0.034s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01276, val loss: 0.01282, in 0.038s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01270, val loss: 0.01277, in 0.036s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01266, val loss: 0.01273, in 0.039s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01261, val loss: 0.01269, in 0.040s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01257, val loss: 0.01265, in 0.036s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01253, val loss: 0.01261, in 0.034s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01248, val loss: 0.01258, in 0.029s\n",
      "Fit 100 trees in 6.050 s, (3100 total leaves)\n",
      "Time spent computing histograms: 3.051s\n",
      "Time spent finding best splits:  0.950s\n",
      "Time spent applying splits:      1.238s\n",
      "Time spent predicting:           0.074s\n",
      "Binning 0.089 GB of training data: 0.167 s\n",
      "Binning 0.010 GB of validation data: 0.015 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41433, val loss: 0.41754, in 0.044s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.34513, val loss: 0.34739, in 0.041s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.28826, val loss: 0.29018, in 0.039s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.24233, val loss: 0.24371, in 0.049s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.20461, val loss: 0.20585, in 0.041s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.17363, val loss: 0.17486, in 0.040s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.14850, val loss: 0.14960, in 0.042s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.12777, val loss: 0.12892, in 0.042s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11093, val loss: 0.11183, in 0.042s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09697, val loss: 0.09785, in 0.045s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08541, val loss: 0.08641, in 0.037s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.07559, val loss: 0.07669, in 0.045s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.06760, val loss: 0.06884, in 0.036s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06117, val loss: 0.06231, in 0.036s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05565, val loss: 0.05690, in 0.037s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05122, val loss: 0.05243, in 0.047s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04740, val loss: 0.04866, in 0.037s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04417, val loss: 0.04550, in 0.048s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04133, val loss: 0.04278, in 0.043s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03906, val loss: 0.04053, in 0.041s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03706, val loss: 0.03864, in 0.037s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03528, val loss: 0.03677, in 0.068s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03386, val loss: 0.03534, in 0.039s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03268, val loss: 0.03417, in 0.041s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.03150, val loss: 0.03305, in 0.038s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03051, val loss: 0.03209, in 0.035s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02965, val loss: 0.03113, in 0.038s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02883, val loss: 0.03023, in 0.040s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02818, val loss: 0.02961, in 0.033s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02756, val loss: 0.02907, in 0.033s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02698, val loss: 0.02845, in 0.036s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02643, val loss: 0.02802, in 0.036s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.02604, val loss: 0.02762, in 0.042s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02561, val loss: 0.02717, in 0.229s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02515, val loss: 0.02677, in 0.643s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02478, val loss: 0.02640, in 0.229s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02448, val loss: 0.02612, in 0.252s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02415, val loss: 0.02575, in 0.030s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02392, val loss: 0.02556, in 0.035s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02355, val loss: 0.02524, in 0.037s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02333, val loss: 0.02505, in 0.034s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02293, val loss: 0.02467, in 0.035s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02259, val loss: 0.02441, in 0.028s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02215, val loss: 0.02408, in 0.030s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02192, val loss: 0.02389, in 0.031s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02173, val loss: 0.02369, in 0.038s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02155, val loss: 0.02349, in 0.048s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.02140, val loss: 0.02334, in 0.036s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02126, val loss: 0.02320, in 0.036s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02109, val loss: 0.02303, in 0.026s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02094, val loss: 0.02291, in 0.029s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02083, val loss: 0.02281, in 0.031s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02070, val loss: 0.02271, in 0.032s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02043, val loss: 0.02240, in 0.030s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.02030, val loss: 0.02227, in 0.027s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.02016, val loss: 0.02213, in 0.030s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02004, val loss: 0.02203, in 0.030s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01993, val loss: 0.02193, in 0.030s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01986, val loss: 0.02186, in 0.028s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01971, val loss: 0.02174, in 0.029s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01964, val loss: 0.02168, in 0.031s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01958, val loss: 0.02160, in 0.029s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01948, val loss: 0.02151, in 0.043s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01943, val loss: 0.02146, in 0.039s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01936, val loss: 0.02141, in 0.035s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01918, val loss: 0.02128, in 0.052s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01912, val loss: 0.02124, in 0.034s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01907, val loss: 0.02119, in 0.029s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01902, val loss: 0.02114, in 0.034s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01896, val loss: 0.02108, in 0.035s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01889, val loss: 0.02103, in 0.034s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01878, val loss: 0.02095, in 0.057s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01874, val loss: 0.02092, in 0.053s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01866, val loss: 0.02085, in 0.029s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01861, val loss: 0.02081, in 0.029s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01857, val loss: 0.02078, in 0.034s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01843, val loss: 0.02069, in 0.044s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01839, val loss: 0.02067, in 0.042s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01833, val loss: 0.02063, in 0.032s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01820, val loss: 0.02052, in 0.027s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01809, val loss: 0.02044, in 0.027s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01803, val loss: 0.02038, in 0.024s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01799, val loss: 0.02035, in 0.028s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01794, val loss: 0.02032, in 0.038s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01791, val loss: 0.02030, in 0.027s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01787, val loss: 0.02026, in 0.036s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01783, val loss: 0.02025, in 0.025s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01779, val loss: 0.02020, in 0.030s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01775, val loss: 0.02017, in 0.028s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01770, val loss: 0.02011, in 0.032s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01767, val loss: 0.02010, in 0.025s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01764, val loss: 0.02009, in 0.025s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01760, val loss: 0.02004, in 0.028s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01758, val loss: 0.02002, in 0.022s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01753, val loss: 0.01996, in 0.027s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01750, val loss: 0.01994, in 0.027s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01747, val loss: 0.01992, in 0.024s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01741, val loss: 0.01987, in 0.027s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01737, val loss: 0.01984, in 0.035s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01733, val loss: 0.01981, in 0.031s\n",
      "Fit 100 trees in 4.996 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.345s\n",
      "Time spent finding best splits:  0.721s\n",
      "Time spent applying splits:      1.117s\n",
      "Time spent predicting:           0.069s\n",
      "Binning 0.089 GB of training data: 0.153 s\n",
      "Binning 0.010 GB of validation data: 0.010 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.44772, val loss: 0.44490, in 0.044s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.40488, val loss: 0.40257, in 0.067s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.36962, val loss: 0.36765, in 0.040s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.34054, val loss: 0.33889, in 0.041s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.31590, val loss: 0.31445, in 0.040s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.29619, val loss: 0.29489, in 0.057s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.27887, val loss: 0.27772, in 0.036s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.26509, val loss: 0.26401, in 0.051s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.25304, val loss: 0.25202, in 0.048s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.24276, val loss: 0.24175, in 0.042s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.23399, val loss: 0.23304, in 0.047s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.22638, val loss: 0.22545, in 0.038s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.21997, val loss: 0.21903, in 0.047s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.21428, val loss: 0.21337, in 0.043s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.20943, val loss: 0.20851, in 0.034s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.20498, val loss: 0.20412, in 0.033s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.20144, val loss: 0.20051, in 0.033s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.19810, val loss: 0.19714, in 0.034s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.19503, val loss: 0.19406, in 0.035s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.19214, val loss: 0.19118, in 0.038s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18982, val loss: 0.18886, in 0.037s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18730, val loss: 0.18631, in 0.035s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18534, val loss: 0.18432, in 0.035s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18328, val loss: 0.18230, in 0.036s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18163, val loss: 0.18064, in 0.034s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.17997, val loss: 0.17899, in 0.034s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.17860, val loss: 0.17763, in 0.035s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.17690, val loss: 0.17597, in 0.037s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.17568, val loss: 0.17474, in 0.035s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.17459, val loss: 0.17361, in 0.036s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.17311, val loss: 0.17214, in 0.037s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.17203, val loss: 0.17114, in 0.041s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.17120, val loss: 0.17028, in 0.037s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.17009, val loss: 0.16918, in 0.033s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.16900, val loss: 0.16816, in 0.036s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16820, val loss: 0.16737, in 0.035s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.16725, val loss: 0.16651, in 0.035s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16637, val loss: 0.16562, in 0.036s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.16567, val loss: 0.16491, in 0.032s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.16501, val loss: 0.16421, in 0.035s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16423, val loss: 0.16344, in 0.033s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.16357, val loss: 0.16280, in 0.043s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16298, val loss: 0.16223, in 0.042s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.16239, val loss: 0.16164, in 0.034s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.16174, val loss: 0.16102, in 0.034s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16129, val loss: 0.16063, in 0.032s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16076, val loss: 0.16008, in 0.037s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.16010, val loss: 0.15945, in 0.036s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15961, val loss: 0.15896, in 0.035s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.15922, val loss: 0.15862, in 0.032s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15876, val loss: 0.15816, in 0.032s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15835, val loss: 0.15774, in 0.032s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15801, val loss: 0.15743, in 0.031s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15763, val loss: 0.15708, in 0.036s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15731, val loss: 0.15679, in 0.032s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15687, val loss: 0.15638, in 0.037s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15650, val loss: 0.15598, in 0.784s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15600, val loss: 0.15548, in 0.210s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15558, val loss: 0.15508, in 0.170s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15516, val loss: 0.15468, in 0.058s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15481, val loss: 0.15433, in 0.040s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15455, val loss: 0.15410, in 0.030s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15428, val loss: 0.15384, in 0.034s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15395, val loss: 0.15351, in 0.034s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15364, val loss: 0.15323, in 0.040s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15333, val loss: 0.15291, in 0.052s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15298, val loss: 0.15260, in 0.043s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15268, val loss: 0.15231, in 0.049s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15244, val loss: 0.15208, in 0.047s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15223, val loss: 0.15185, in 0.058s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15195, val loss: 0.15159, in 0.045s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15164, val loss: 0.15131, in 0.039s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.15131, val loss: 0.15101, in 0.055s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15114, val loss: 0.15087, in 0.031s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15090, val loss: 0.15066, in 0.028s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15067, val loss: 0.15045, in 0.029s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15041, val loss: 0.15022, in 0.037s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15018, val loss: 0.15002, in 0.026s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14993, val loss: 0.14979, in 0.035s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14974, val loss: 0.14963, in 0.068s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14952, val loss: 0.14943, in 0.026s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14933, val loss: 0.14927, in 0.030s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.14905, val loss: 0.14899, in 0.043s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14878, val loss: 0.14877, in 0.030s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14850, val loss: 0.14852, in 0.038s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.14827, val loss: 0.14830, in 0.035s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.14812, val loss: 0.14818, in 0.032s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.14778, val loss: 0.14787, in 0.031s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14762, val loss: 0.14772, in 0.034s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.14737, val loss: 0.14750, in 0.033s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14720, val loss: 0.14736, in 0.026s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.14706, val loss: 0.14725, in 0.031s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14682, val loss: 0.14699, in 0.027s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.14667, val loss: 0.14686, in 0.031s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14649, val loss: 0.14672, in 0.036s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14635, val loss: 0.14662, in 0.032s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14614, val loss: 0.14643, in 0.046s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14585, val loss: 0.14617, in 0.039s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14566, val loss: 0.14599, in 0.030s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14546, val loss: 0.14580, in 0.032s\n",
      "Fit 100 trees in 5.051 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.479s\n",
      "Time spent finding best splits:  0.770s\n",
      "Time spent applying splits:      1.038s\n",
      "Time spent predicting:           0.077s\n",
      "Binning 0.089 GB of training data: 0.160 s\n",
      "Binning 0.010 GB of validation data: 0.017 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.40726, val loss: 0.44369, in 0.037s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.33665, val loss: 0.36730, in 0.028s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.27945, val loss: 0.30537, in 0.026s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.23313, val loss: 0.25519, in 0.033s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.19507, val loss: 0.21378, in 0.025s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.16446, val loss: 0.18073, in 0.028s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13969, val loss: 0.15379, in 0.027s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11953, val loss: 0.13188, in 0.031s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10320, val loss: 0.11412, in 0.025s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.08990, val loss: 0.09960, in 0.026s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.07914, val loss: 0.08775, in 0.028s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.07043, val loss: 0.07810, in 0.027s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.06373, val loss: 0.07080, in 0.027s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05773, val loss: 0.06421, in 0.030s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05330, val loss: 0.05913, in 0.025s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04862, val loss: 0.05376, in 0.028s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04484, val loss: 0.04942, in 0.027s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04241, val loss: 0.04662, in 0.029s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03974, val loss: 0.04347, in 0.028s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03757, val loss: 0.04089, in 0.033s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03626, val loss: 0.03946, in 0.032s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03468, val loss: 0.03759, in 0.033s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03341, val loss: 0.03606, in 0.031s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03237, val loss: 0.03482, in 0.027s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03152, val loss: 0.03376, in 0.027s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03099, val loss: 0.03320, in 0.033s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03034, val loss: 0.03246, in 0.031s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02973, val loss: 0.03170, in 0.029s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02924, val loss: 0.03109, in 0.031s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02885, val loss: 0.03050, in 0.029s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02851, val loss: 0.03009, in 0.029s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02823, val loss: 0.02974, in 0.028s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02805, val loss: 0.02958, in 0.029s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02788, val loss: 0.02941, in 0.053s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02773, val loss: 0.02928, in 0.046s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02762, val loss: 0.02917, in 0.029s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02746, val loss: 0.02895, in 0.025s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02735, val loss: 0.02885, in 0.034s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02727, val loss: 0.02877, in 0.030s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02720, val loss: 0.02870, in 0.030s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02710, val loss: 0.02858, in 0.028s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02704, val loss: 0.02852, in 0.026s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02696, val loss: 0.02842, in 0.033s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02691, val loss: 0.02838, in 0.034s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02682, val loss: 0.02822, in 0.032s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02674, val loss: 0.02813, in 0.033s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02669, val loss: 0.02803, in 0.031s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02663, val loss: 0.02799, in 0.033s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02658, val loss: 0.02794, in 0.034s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02654, val loss: 0.02791, in 0.052s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02648, val loss: 0.02786, in 0.032s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02645, val loss: 0.02783, in 0.031s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02637, val loss: 0.02771, in 0.028s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02633, val loss: 0.02768, in 0.033s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02629, val loss: 0.02764, in 0.030s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02626, val loss: 0.02760, in 0.111s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02622, val loss: 0.02758, in 0.117s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02616, val loss: 0.02745, in 0.082s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02613, val loss: 0.02743, in 0.046s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02610, val loss: 0.02741, in 0.034s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.02608, val loss: 0.02739, in 0.038s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02603, val loss: 0.02735, in 0.032s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02598, val loss: 0.02731, in 0.027s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02594, val loss: 0.02727, in 0.029s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02590, val loss: 0.02725, in 0.029s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02586, val loss: 0.02723, in 0.026s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02583, val loss: 0.02721, in 0.035s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02581, val loss: 0.02720, in 0.029s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02578, val loss: 0.02717, in 0.048s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02575, val loss: 0.02714, in 0.037s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02573, val loss: 0.02712, in 0.040s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02569, val loss: 0.02710, in 0.034s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02566, val loss: 0.02709, in 0.043s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02564, val loss: 0.02706, in 0.074s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02562, val loss: 0.02705, in 0.872s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02559, val loss: 0.02702, in 0.090s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02557, val loss: 0.02700, in 0.223s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02551, val loss: 0.02695, in 0.043s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02549, val loss: 0.02693, in 0.032s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02547, val loss: 0.02692, in 0.030s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02545, val loss: 0.02691, in 0.032s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02544, val loss: 0.02690, in 0.026s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02540, val loss: 0.02688, in 0.030s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02539, val loss: 0.02687, in 0.022s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02537, val loss: 0.02685, in 0.024s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02535, val loss: 0.02685, in 0.021s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02534, val loss: 0.02684, in 0.026s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02531, val loss: 0.02683, in 0.033s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02529, val loss: 0.02681, in 0.035s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02527, val loss: 0.02679, in 0.030s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.02525, val loss: 0.02678, in 0.023s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02524, val loss: 0.02676, in 0.024s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02521, val loss: 0.02674, in 0.030s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02520, val loss: 0.02673, in 0.023s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02519, val loss: 0.02673, in 0.028s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.02517, val loss: 0.02672, in 0.026s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.02515, val loss: 0.02671, in 0.038s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02514, val loss: 0.02670, in 0.032s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02513, val loss: 0.02670, in 0.085s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02512, val loss: 0.02668, in 0.212s\n",
      "Fit 100 trees in 4.949 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.276s\n",
      "Time spent finding best splits:  0.862s\n",
      "Time spent applying splits:      1.084s\n",
      "Time spent predicting:           0.051s\n",
      "Binning 0.089 GB of training data: 0.200 s\n",
      "Binning 0.010 GB of validation data: 0.018 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.41089, val loss: 0.40295, in 0.050s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.33786, val loss: 0.33124, in 0.039s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.27854, val loss: 0.27308, in 0.037s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.23043, val loss: 0.22582, in 0.037s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.19138, val loss: 0.18752, in 0.041s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15963, val loss: 0.15639, in 0.039s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.13388, val loss: 0.13112, in 0.039s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11289, val loss: 0.11053, in 0.042s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.09580, val loss: 0.09380, in 0.036s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.08195, val loss: 0.08022, in 0.036s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.07059, val loss: 0.06912, in 0.037s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06139, val loss: 0.06012, in 0.039s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05388, val loss: 0.05275, in 0.042s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.04770, val loss: 0.04674, in 0.055s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04265, val loss: 0.04178, in 0.046s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.03841, val loss: 0.03769, in 0.041s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03493, val loss: 0.03437, in 0.039s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.03208, val loss: 0.03166, in 0.038s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02974, val loss: 0.02939, in 0.038s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02780, val loss: 0.02757, in 0.034s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02614, val loss: 0.02603, in 0.041s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 6, train loss: 0.02478, val loss: 0.02475, in 0.068s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02364, val loss: 0.02371, in 0.056s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02271, val loss: 0.02280, in 0.053s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02190, val loss: 0.02201, in 0.046s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02119, val loss: 0.02131, in 0.048s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.02063, val loss: 0.02080, in 0.055s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02013, val loss: 0.02036, in 0.050s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01970, val loss: 0.01999, in 0.048s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01931, val loss: 0.01961, in 0.040s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01898, val loss: 0.01929, in 0.046s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01868, val loss: 0.01900, in 0.042s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01843, val loss: 0.01878, in 0.039s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01820, val loss: 0.01855, in 0.044s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01802, val loss: 0.01836, in 0.043s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01782, val loss: 0.01818, in 0.038s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.01766, val loss: 0.01806, in 0.048s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01750, val loss: 0.01789, in 0.044s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01739, val loss: 0.01779, in 0.030s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01727, val loss: 0.01767, in 0.030s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01717, val loss: 0.01758, in 0.028s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01706, val loss: 0.01747, in 0.032s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01696, val loss: 0.01739, in 0.036s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.01686, val loss: 0.01734, in 0.037s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01678, val loss: 0.01727, in 0.036s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01670, val loss: 0.01718, in 0.039s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01663, val loss: 0.01711, in 0.040s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01655, val loss: 0.01707, in 0.032s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01648, val loss: 0.01701, in 0.041s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01640, val loss: 0.01694, in 0.047s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.01635, val loss: 0.01688, in 0.039s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01628, val loss: 0.01683, in 0.037s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01624, val loss: 0.01678, in 0.042s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01618, val loss: 0.01673, in 0.040s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01613, val loss: 0.01669, in 0.042s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01609, val loss: 0.01664, in 0.037s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01604, val loss: 0.01660, in 0.044s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01599, val loss: 0.01656, in 0.052s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.01595, val loss: 0.01652, in 0.078s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01590, val loss: 0.01648, in 0.065s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01584, val loss: 0.01644, in 0.037s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01580, val loss: 0.01640, in 0.041s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01577, val loss: 0.01637, in 0.044s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01571, val loss: 0.01632, in 0.055s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01567, val loss: 0.01631, in 0.039s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01564, val loss: 0.01628, in 0.037s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01560, val loss: 0.01625, in 0.033s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01557, val loss: 0.01621, in 0.046s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01553, val loss: 0.01617, in 0.035s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01550, val loss: 0.01614, in 0.038s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01547, val loss: 0.01613, in 0.045s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01544, val loss: 0.01611, in 0.033s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01542, val loss: 0.01608, in 0.031s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01539, val loss: 0.01606, in 0.023s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01537, val loss: 0.01605, in 0.029s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01534, val loss: 0.01604, in 0.029s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01531, val loss: 0.01601, in 0.030s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01527, val loss: 0.01599, in 0.031s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01525, val loss: 0.01596, in 0.032s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01595, in 0.024s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01521, val loss: 0.01593, in 0.032s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01519, val loss: 0.01591, in 0.029s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.01516, val loss: 0.01589, in 0.026s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01514, val loss: 0.01587, in 0.030s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01513, val loss: 0.01586, in 0.024s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01511, val loss: 0.01584, in 0.029s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01509, val loss: 0.01583, in 0.024s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01508, val loss: 0.01581, in 0.024s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.01506, val loss: 0.01580, in 0.025s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01504, val loss: 0.01578, in 0.028s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01503, val loss: 0.01577, in 0.030s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01501, val loss: 0.01575, in 0.025s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01498, val loss: 0.01573, in 0.262s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01495, val loss: 0.01572, in 0.391s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01494, val loss: 0.01571, in 0.483s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01492, val loss: 0.01569, in 0.308s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01491, val loss: 0.01567, in 0.033s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01489, val loss: 0.01566, in 0.036s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01487, val loss: 0.01564, in 0.034s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01485, val loss: 0.01563, in 0.028s\n",
      "Fit 100 trees in 5.488 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.536s\n",
      "Time spent finding best splits:  0.838s\n",
      "Time spent applying splits:      1.219s\n",
      "Time spent predicting:           0.058s\n",
      "Binning 0.089 GB of training data: 0.163 s\n",
      "Binning 0.010 GB of validation data: 0.012 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.41054, val loss: 0.40985, in 0.041s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.33796, val loss: 0.33718, in 0.035s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.27842, val loss: 0.27769, in 0.035s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.23002, val loss: 0.22939, in 0.035s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.19085, val loss: 0.19037, in 0.035s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.15882, val loss: 0.15829, in 0.043s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.13279, val loss: 0.13225, in 0.037s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11141, val loss: 0.11094, in 0.037s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.09404, val loss: 0.09354, in 0.041s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.07987, val loss: 0.07944, in 0.035s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06813, val loss: 0.06762, in 0.035s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05856, val loss: 0.05801, in 0.041s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05061, val loss: 0.05007, in 0.041s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.04428, val loss: 0.04375, in 0.055s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03909, val loss: 0.03858, in 0.039s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03440, val loss: 0.03388, in 0.036s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03064, val loss: 0.03013, in 0.036s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02758, val loss: 0.02710, in 0.032s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02510, val loss: 0.02466, in 0.035s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02311, val loss: 0.02269, in 0.036s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02145, val loss: 0.02102, in 0.042s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01999, val loss: 0.01958, in 0.046s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01884, val loss: 0.01845, in 0.031s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01780, val loss: 0.01744, in 0.032s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01692, val loss: 0.01657, in 0.037s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01614, val loss: 0.01581, in 0.032s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01541, val loss: 0.01511, in 0.040s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01484, val loss: 0.01457, in 0.060s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01424, val loss: 0.01397, in 0.030s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01380, val loss: 0.01350, in 0.030s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01331, val loss: 0.01303, in 0.031s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01297, val loss: 0.01272, in 0.033s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01262, val loss: 0.01239, in 0.033s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01222, val loss: 0.01202, in 0.034s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01195, val loss: 0.01178, in 0.030s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01170, val loss: 0.01155, in 0.032s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01145, val loss: 0.01131, in 0.036s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01122, val loss: 0.01108, in 0.032s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01103, val loss: 0.01092, in 0.031s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.01084, val loss: 0.01074, in 0.030s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01068, val loss: 0.01059, in 0.032s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01053, val loss: 0.01046, in 0.034s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01039, val loss: 0.01030, in 0.030s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01020, in 0.032s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01011, val loss: 0.01005, in 0.030s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00999, val loss: 0.00993, in 0.035s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00988, val loss: 0.00981, in 0.044s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00978, val loss: 0.00973, in 0.031s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00968, val loss: 0.00964, in 0.032s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00958, val loss: 0.00956, in 0.044s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00951, val loss: 0.00948, in 0.040s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00943, val loss: 0.00940, in 0.034s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00936, val loss: 0.00935, in 0.031s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00929, val loss: 0.00929, in 0.027s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00918, val loss: 0.00919, in 0.027s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00912, val loss: 0.00912, in 0.030s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00904, val loss: 0.00905, in 0.026s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00897, val loss: 0.00899, in 0.042s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00891, val loss: 0.00893, in 0.027s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00884, val loss: 0.00887, in 0.028s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00878, val loss: 0.00880, in 0.019s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00873, val loss: 0.00876, in 0.029s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00869, val loss: 0.00870, in 0.028s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00865, val loss: 0.00865, in 0.029s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00861, val loss: 0.00862, in 0.029s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00856, val loss: 0.00858, in 0.025s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00850, val loss: 0.00852, in 0.026s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00846, val loss: 0.00848, in 0.026s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00840, val loss: 0.00843, in 0.027s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00835, val loss: 0.00839, in 0.022s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00831, val loss: 0.00836, in 0.026s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00826, val loss: 0.00832, in 0.028s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00822, val loss: 0.00830, in 0.027s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00816, val loss: 0.00824, in 0.029s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00812, val loss: 0.00819, in 0.030s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00807, val loss: 0.00814, in 0.025s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00802, val loss: 0.00810, in 0.033s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00800, val loss: 0.00808, in 0.024s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00797, val loss: 0.00806, in 0.020s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00794, val loss: 0.00804, in 0.027s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.00789, val loss: 0.00802, in 0.025s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00785, val loss: 0.00797, in 0.031s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00781, val loss: 0.00793, in 0.025s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00777, val loss: 0.00790, in 0.029s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00774, val loss: 0.00787, in 0.026s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00770, val loss: 0.00784, in 0.031s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00765, val loss: 0.00780, in 0.043s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00763, val loss: 0.00777, in 0.084s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00760, val loss: 0.00775, in 0.033s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00757, val loss: 0.00773, in 0.032s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00755, val loss: 0.00772, in 0.024s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00752, val loss: 0.00768, in 0.032s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00750, val loss: 0.00767, in 0.029s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00747, val loss: 0.00764, in 0.027s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00741, val loss: 0.00760, in 0.029s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00739, val loss: 0.00757, in 0.029s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00736, val loss: 0.00756, in 0.025s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00733, val loss: 0.00754, in 0.029s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00731, val loss: 0.00752, in 0.023s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00728, val loss: 0.00749, in 0.042s\n",
      "Fit 100 trees in 3.531 s, (3100 total leaves)\n",
      "Time spent computing histograms: 1.819s\n",
      "Time spent finding best splits:  0.448s\n",
      "Time spent applying splits:      0.678s\n",
      "Time spent predicting:           0.046s\n",
      "Binning 0.089 GB of training data: 0.164 s\n",
      "Binning 0.010 GB of validation data: 0.012 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.40993, val loss: 0.41050, in 0.041s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.33698, val loss: 0.33742, in 0.048s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.27774, val loss: 0.27806, in 0.040s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.22956, val loss: 0.22975, in 0.045s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.19050, val loss: 0.19059, in 0.038s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.15869, val loss: 0.15872, in 0.034s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.13282, val loss: 0.13274, in 0.032s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.11175, val loss: 0.11159, in 0.034s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.09457, val loss: 0.09433, in 0.034s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08059, val loss: 0.08027, in 0.034s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06917, val loss: 0.06876, in 0.036s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05988, val loss: 0.05942, in 0.034s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05222, val loss: 0.05168, in 0.030s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04597, val loss: 0.04539, in 0.032s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04082, val loss: 0.04020, in 0.033s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.03657, val loss: 0.03591, in 0.033s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03307, val loss: 0.03237, in 0.032s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03014, val loss: 0.02942, in 0.034s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02748, val loss: 0.02679, in 0.033s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.02537, val loss: 0.02467, in 0.032s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02363, val loss: 0.02291, in 0.030s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02223, val loss: 0.02148, in 0.035s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02099, val loss: 0.02023, in 0.033s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01987, val loss: 0.01908, in 0.033s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01894, val loss: 0.01815, in 0.087s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01817, val loss: 0.01737, in 0.093s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01755, val loss: 0.01674, in 0.080s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01697, val loss: 0.01614, in 0.082s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.01643, val loss: 0.01558, in 0.038s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01596, val loss: 0.01510, in 0.040s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01546, val loss: 0.01464, in 0.039s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01489, val loss: 0.01411, in 0.032s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01457, val loss: 0.01379, in 0.033s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01420, val loss: 0.01343, in 0.038s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01393, val loss: 0.01318, in 0.034s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01370, val loss: 0.01295, in 0.032s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01337, val loss: 0.01264, in 0.036s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01312, val loss: 0.01240, in 0.045s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01287, val loss: 0.01217, in 0.046s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.01268, val loss: 0.01200, in 0.032s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01249, val loss: 0.01183, in 0.032s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01233, val loss: 0.01168, in 0.031s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01215, val loss: 0.01152, in 0.035s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01202, val loss: 0.01139, in 0.031s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01185, val loss: 0.01125, in 0.034s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01174, val loss: 0.01115, in 0.042s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01161, val loss: 0.01104, in 0.039s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01150, val loss: 0.01092, in 0.038s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01141, val loss: 0.01084, in 0.038s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01128, val loss: 0.01073, in 0.034s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01114, val loss: 0.01061, in 0.038s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01102, val loss: 0.01049, in 0.041s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01093, val loss: 0.01041, in 0.037s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01084, val loss: 0.01032, in 0.042s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01078, val loss: 0.01027, in 0.053s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01071, val loss: 0.01020, in 0.040s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01064, val loss: 0.01013, in 0.033s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01058, val loss: 0.01009, in 0.047s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01052, val loss: 0.01004, in 0.035s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01045, val loss: 0.00997, in 0.037s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01040, val loss: 0.00993, in 0.032s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01035, val loss: 0.00988, in 0.043s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01031, val loss: 0.00984, in 0.045s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01025, val loss: 0.00980, in 0.034s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01022, val loss: 0.00976, in 0.025s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01018, val loss: 0.00972, in 0.047s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01012, val loss: 0.00967, in 0.030s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01009, val loss: 0.00965, in 0.027s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01004, val loss: 0.00960, in 0.031s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01002, val loss: 0.00958, in 0.040s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00997, val loss: 0.00954, in 0.055s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00994, val loss: 0.00951, in 0.039s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00991, val loss: 0.00948, in 0.035s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00988, val loss: 0.00946, in 0.035s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00985, val loss: 0.00943, in 0.036s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00982, val loss: 0.00941, in 0.030s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00976, val loss: 0.00937, in 0.043s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00974, val loss: 0.00935, in 0.035s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00969, val loss: 0.00930, in 0.058s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00963, val loss: 0.00926, in 0.038s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00961, val loss: 0.00925, in 0.047s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00958, val loss: 0.00922, in 0.074s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00955, val loss: 0.00919, in 0.029s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00952, val loss: 0.00917, in 0.029s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00949, val loss: 0.00914, in 0.031s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00946, val loss: 0.00911, in 0.027s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00944, val loss: 0.00909, in 0.029s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00941, val loss: 0.00908, in 0.030s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00940, val loss: 0.00906, in 0.033s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00938, val loss: 0.00905, in 0.027s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00935, val loss: 0.00903, in 0.025s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00933, val loss: 0.00901, in 0.028s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00930, val loss: 0.00899, in 0.029s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00929, val loss: 0.00897, in 0.039s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00927, val loss: 0.00896, in 0.030s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00925, val loss: 0.00895, in 0.023s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00923, val loss: 0.00894, in 0.033s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00921, val loss: 0.00892, in 0.032s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00919, val loss: 0.00891, in 0.028s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00916, val loss: 0.00888, in 0.026s\n",
      "Fit 100 trees in 4.023 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.017s\n",
      "Time spent finding best splits:  0.525s\n",
      "Time spent applying splits:      0.796s\n",
      "Time spent predicting:           0.053s\n",
      "Binning 0.089 GB of training data: 0.160 s\n",
      "Binning 0.010 GB of validation data: 0.010 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.41304, val loss: 0.41046, in 0.033s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 6, train loss: 0.34224, val loss: 0.34015, in 0.038s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.28476, val loss: 0.28294, in 0.034s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.23785, val loss: 0.23620, in 0.035s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.19965, val loss: 0.19822, in 0.039s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.16860, val loss: 0.16723, in 0.042s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14322, val loss: 0.14201, in 0.042s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.12245, val loss: 0.12126, in 0.045s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10550, val loss: 0.10438, in 0.041s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09162, val loss: 0.09063, in 0.051s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08035, val loss: 0.07941, in 0.046s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07107, val loss: 0.07018, in 0.049s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06328, val loss: 0.06249, in 0.039s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05701, val loss: 0.05623, in 0.055s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05167, val loss: 0.05097, in 0.038s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.04717, val loss: 0.04653, in 0.039s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04349, val loss: 0.04288, in 0.038s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04057, val loss: 0.04005, in 0.036s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.03801, val loss: 0.03751, in 0.035s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03589, val loss: 0.03545, in 0.042s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03411, val loss: 0.03367, in 0.062s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03266, val loss: 0.03224, in 0.041s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03139, val loss: 0.03106, in 0.034s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03035, val loss: 0.03008, in 0.033s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02944, val loss: 0.02923, in 0.033s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02864, val loss: 0.02842, in 0.036s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02792, val loss: 0.02775, in 0.048s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02730, val loss: 0.02719, in 0.037s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02660, val loss: 0.02652, in 0.031s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02614, val loss: 0.02608, in 0.031s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02566, val loss: 0.02564, in 0.032s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.02530, val loss: 0.02526, in 0.033s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02484, val loss: 0.02482, in 0.030s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02458, val loss: 0.02455, in 0.033s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02425, val loss: 0.02423, in 0.037s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02403, val loss: 0.02402, in 0.031s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02384, val loss: 0.02385, in 0.031s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02364, val loss: 0.02364, in 0.035s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02343, val loss: 0.02342, in 0.030s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02301, val loss: 0.02302, in 0.033s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.02280, val loss: 0.02281, in 0.034s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.02244, val loss: 0.02246, in 0.030s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.02210, val loss: 0.02216, in 0.029s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02181, val loss: 0.02187, in 0.063s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02167, val loss: 0.02174, in 0.029s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02142, val loss: 0.02150, in 0.031s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 19, train loss: 0.02130, val loss: 0.02139, in 0.028s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02118, val loss: 0.02127, in 0.025s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02095, val loss: 0.02105, in 0.040s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02076, val loss: 0.02086, in 0.042s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.02057, val loss: 0.02071, in 0.031s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02047, val loss: 0.02062, in 0.026s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.02022, val loss: 0.02039, in 0.032s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.02012, val loss: 0.02031, in 0.033s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02002, val loss: 0.02024, in 0.028s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01995, val loss: 0.02017, in 0.030s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01980, val loss: 0.02000, in 0.038s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01970, val loss: 0.01992, in 0.036s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01959, val loss: 0.01982, in 0.026s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01950, val loss: 0.01975, in 0.028s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01943, val loss: 0.01968, in 0.021s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.01913, val loss: 0.01944, in 0.032s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01902, val loss: 0.01936, in 0.035s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01896, val loss: 0.01932, in 0.043s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01891, val loss: 0.01928, in 0.095s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01880, val loss: 0.01916, in 0.037s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01874, val loss: 0.01912, in 0.026s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01865, val loss: 0.01898, in 0.036s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01861, val loss: 0.01895, in 0.030s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01854, val loss: 0.01887, in 0.033s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01850, val loss: 0.01884, in 0.032s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01846, val loss: 0.01882, in 0.036s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01835, val loss: 0.01868, in 0.040s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01828, val loss: 0.01863, in 0.021s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01824, val loss: 0.01859, in 0.032s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01819, val loss: 0.01854, in 0.022s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01815, val loss: 0.01851, in 0.026s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01812, val loss: 0.01849, in 0.030s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01792, val loss: 0.01826, in 0.044s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01789, val loss: 0.01823, in 0.044s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01783, val loss: 0.01815, in 0.033s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01780, val loss: 0.01814, in 0.034s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01772, val loss: 0.01807, in 0.031s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01769, val loss: 0.01805, in 0.031s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01765, val loss: 0.01802, in 0.025s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01755, val loss: 0.01793, in 0.026s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01751, val loss: 0.01788, in 0.023s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01749, val loss: 0.01785, in 0.032s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01745, val loss: 0.01783, in 0.026s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01743, val loss: 0.01781, in 0.034s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01738, val loss: 0.01777, in 0.027s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01733, val loss: 0.01769, in 0.025s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01724, val loss: 0.01759, in 0.027s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01722, val loss: 0.01757, in 0.025s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01716, val loss: 0.01753, in 0.030s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01713, val loss: 0.01749, in 0.024s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01710, val loss: 0.01747, in 0.026s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01706, val loss: 0.01745, in 0.022s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01703, val loss: 0.01741, in 0.029s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01702, val loss: 0.01740, in 0.028s\n",
      "Fit 100 trees in 3.691 s, (3100 total leaves)\n",
      "Time spent computing histograms: 1.800s\n",
      "Time spent finding best splits:  0.514s\n",
      "Time spent applying splits:      0.724s\n",
      "Time spent predicting:           0.052s\n",
      "Binning 0.089 GB of training data: 0.164 s\n",
      "Binning 0.010 GB of validation data: 0.018 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 6, train loss: 0.40836, val loss: 0.40684, in 0.040s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.33393, val loss: 0.33268, in 0.041s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 6, train loss: 0.27351, val loss: 0.27249, in 0.042s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 6, train loss: 0.22453, val loss: 0.22369, in 0.041s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.18474, val loss: 0.18409, in 0.054s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.15245, val loss: 0.15196, in 0.051s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 6, train loss: 0.12621, val loss: 0.12583, in 0.250s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10490, val loss: 0.10465, in 0.484s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.08759, val loss: 0.08743, in 0.512s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.07352, val loss: 0.07343, in 0.232s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.06207, val loss: 0.06206, in 0.063s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05274, val loss: 0.05280, in 0.454s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04512, val loss: 0.04522, in 0.076s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03895, val loss: 0.03911, in 0.044s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.03392, val loss: 0.03413, in 0.051s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02979, val loss: 0.03004, in 0.048s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02643, val loss: 0.02672, in 0.043s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02369, val loss: 0.02401, in 0.054s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02145, val loss: 0.02180, in 0.058s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01960, val loss: 0.01999, in 0.032s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01809, val loss: 0.01851, in 0.042s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01686, val loss: 0.01729, in 0.034s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01582, val loss: 0.01628, in 0.040s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01497, val loss: 0.01545, in 0.032s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01426, val loss: 0.01476, in 0.058s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01368, val loss: 0.01417, in 0.083s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01320, val loss: 0.01370, in 0.076s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01280, val loss: 0.01333, in 0.035s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01246, val loss: 0.01300, in 0.033s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01217, val loss: 0.01271, in 0.034s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01193, val loss: 0.01247, in 0.032s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01173, val loss: 0.01229, in 0.049s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01155, val loss: 0.01211, in 0.033s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01140, val loss: 0.01198, in 0.029s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01126, val loss: 0.01186, in 0.036s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01114, val loss: 0.01174, in 0.030s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01104, val loss: 0.01166, in 0.029s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.01096, val loss: 0.01159, in 0.030s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01088, val loss: 0.01153, in 0.030s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01081, val loss: 0.01146, in 0.030s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01076, val loss: 0.01141, in 0.032s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01070, val loss: 0.01134, in 0.035s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01065, val loss: 0.01129, in 0.045s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01060, val loss: 0.01125, in 0.045s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01056, val loss: 0.01121, in 0.028s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01052, val loss: 0.01117, in 0.030s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01049, val loss: 0.01114, in 0.030s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01046, val loss: 0.01112, in 0.040s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01043, val loss: 0.01110, in 0.039s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01039, val loss: 0.01107, in 0.034s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01036, val loss: 0.01104, in 0.033s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01034, val loss: 0.01103, in 0.032s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01032, val loss: 0.01101, in 0.038s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.01029, val loss: 0.01099, in 0.042s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01096, in 0.039s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01023, val loss: 0.01094, in 0.043s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01021, val loss: 0.01093, in 0.040s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01019, val loss: 0.01091, in 0.034s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.01017, val loss: 0.01091, in 0.041s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01015, val loss: 0.01089, in 0.038s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01013, val loss: 0.01087, in 0.035s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01011, val loss: 0.01086, in 0.033s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01009, val loss: 0.01084, in 0.030s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01007, val loss: 0.01083, in 0.050s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01006, val loss: 0.01082, in 0.030s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01004, val loss: 0.01081, in 0.031s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01002, val loss: 0.01079, in 0.030s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01001, val loss: 0.01078, in 0.038s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01000, val loss: 0.01077, in 0.035s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00998, val loss: 0.01075, in 0.049s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00997, val loss: 0.01075, in 0.049s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00996, val loss: 0.01074, in 0.035s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00994, val loss: 0.01073, in 0.037s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00993, val loss: 0.01072, in 0.042s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00992, val loss: 0.01071, in 0.030s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00991, val loss: 0.01070, in 0.033s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00990, val loss: 0.01070, in 0.035s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00989, val loss: 0.01069, in 0.024s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00987, val loss: 0.01068, in 0.036s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00986, val loss: 0.01068, in 0.027s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00985, val loss: 0.01068, in 0.027s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00984, val loss: 0.01067, in 0.026s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00984, val loss: 0.01067, in 0.025s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00983, val loss: 0.01066, in 0.032s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00981, val loss: 0.01066, in 0.025s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00981, val loss: 0.01065, in 0.055s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00980, val loss: 0.01065, in 0.027s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00978, val loss: 0.01064, in 0.021s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00978, val loss: 0.01064, in 0.025s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00977, val loss: 0.01063, in 0.029s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00976, val loss: 0.01063, in 0.023s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00975, val loss: 0.01062, in 0.024s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00974, val loss: 0.01061, in 0.029s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00973, val loss: 0.01061, in 0.024s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00972, val loss: 0.01060, in 0.025s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00971, val loss: 0.01058, in 0.026s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00970, val loss: 0.01058, in 0.025s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00969, val loss: 0.01058, in 0.027s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00968, val loss: 0.01057, in 0.027s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00968, val loss: 0.01056, in 0.023s\n",
      "Fit 100 trees in 5.715 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.603s\n",
      "Time spent finding best splits:  0.869s\n",
      "Time spent applying splits:      1.279s\n",
      "Time spent predicting:           0.062s\n",
      "Binning 0.089 GB of training data: 0.188 s\n",
      "Binning 0.010 GB of validation data: 0.016 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.42720, val loss: 0.40833, in 0.047s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.36689, val loss: 0.35095, in 0.049s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.31692, val loss: 0.30451, in 0.042s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.27385, val loss: 0.26696, in 0.044s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.23915, val loss: 0.23509, in 0.042s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.20846, val loss: 0.20977, in 0.042s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18464, val loss: 0.19001, in 0.043s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16600, val loss: 0.17406, in 0.057s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14924, val loss: 0.16232, in 0.051s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.13288, val loss: 0.15081, in 0.041s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.12056, val loss: 0.14268, in 0.037s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11105, val loss: 0.13491, in 0.040s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10235, val loss: 0.12854, in 0.047s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09522, val loss: 0.12366, in 0.031s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08906, val loss: 0.11959, in 0.033s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.08395, val loss: 0.11606, in 0.030s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.07947, val loss: 0.11280, in 0.036s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07601, val loss: 0.11103, in 0.038s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.07236, val loss: 0.10901, in 0.038s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.06954, val loss: 0.10809, in 0.040s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.06665, val loss: 0.10687, in 0.037s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06440, val loss: 0.10517, in 0.042s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06230, val loss: 0.10393, in 0.062s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.06058, val loss: 0.10277, in 0.047s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05885, val loss: 0.10194, in 0.037s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05731, val loss: 0.10125, in 0.041s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05623, val loss: 0.10081, in 0.042s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.05491, val loss: 0.10047, in 0.034s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05344, val loss: 0.09966, in 0.035s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05246, val loss: 0.09878, in 0.038s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05171, val loss: 0.09826, in 0.287s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05096, val loss: 0.09813, in 0.279s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05048, val loss: 0.09777, in 0.349s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04997, val loss: 0.09741, in 0.174s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04897, val loss: 0.09722, in 0.033s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04859, val loss: 0.09682, in 0.040s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04797, val loss: 0.09651, in 0.031s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04730, val loss: 0.09607, in 0.030s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04695, val loss: 0.09590, in 0.029s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04651, val loss: 0.09544, in 0.036s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04602, val loss: 0.09510, in 0.027s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04554, val loss: 0.09454, in 0.033s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04505, val loss: 0.09420, in 0.035s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04476, val loss: 0.09382, in 0.034s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04444, val loss: 0.09400, in 0.050s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04392, val loss: 0.09374, in 0.029s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04372, val loss: 0.09354, in 0.034s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04342, val loss: 0.09305, in 0.028s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04311, val loss: 0.09304, in 0.028s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04269, val loss: 0.09257, in 0.037s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.04243, val loss: 0.09238, in 0.034s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04232, val loss: 0.09233, in 0.030s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04219, val loss: 0.09220, in 0.037s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04186, val loss: 0.09225, in 0.031s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04159, val loss: 0.09221, in 0.024s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04119, val loss: 0.09200, in 0.027s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04103, val loss: 0.09145, in 0.030s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04077, val loss: 0.09127, in 0.024s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04053, val loss: 0.09143, in 0.031s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04012, val loss: 0.09131, in 0.038s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.03997, val loss: 0.09098, in 0.038s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03968, val loss: 0.09100, in 0.035s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03941, val loss: 0.09084, in 0.041s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03932, val loss: 0.09069, in 0.040s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03918, val loss: 0.09058, in 0.038s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03907, val loss: 0.09023, in 0.036s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03867, val loss: 0.08978, in 0.055s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03844, val loss: 0.08967, in 0.036s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03820, val loss: 0.08952, in 0.036s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03805, val loss: 0.08957, in 0.038s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03778, val loss: 0.08953, in 0.035s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03768, val loss: 0.08942, in 0.039s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03758, val loss: 0.08925, in 0.045s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03749, val loss: 0.08923, in 0.034s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03733, val loss: 0.08919, in 0.028s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03717, val loss: 0.08912, in 0.025s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03702, val loss: 0.08907, in 0.031s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03683, val loss: 0.08909, in 0.030s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.03676, val loss: 0.08910, in 0.034s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03659, val loss: 0.08906, in 0.025s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03650, val loss: 0.08891, in 0.033s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.03639, val loss: 0.08863, in 0.031s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03631, val loss: 0.08852, in 0.039s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03617, val loss: 0.08835, in 0.044s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03594, val loss: 0.08829, in 0.050s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03579, val loss: 0.08816, in 0.041s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03568, val loss: 0.08803, in 0.036s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03556, val loss: 0.08799, in 0.028s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03546, val loss: 0.08785, in 0.032s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03524, val loss: 0.08795, in 0.039s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03492, val loss: 0.08777, in 0.034s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03483, val loss: 0.08754, in 0.037s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03478, val loss: 0.08755, in 0.039s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.03456, val loss: 0.08732, in 0.035s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.03444, val loss: 0.08738, in 0.028s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03438, val loss: 0.08727, in 0.044s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03432, val loss: 0.08730, in 0.056s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.03424, val loss: 0.08698, in 0.044s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03408, val loss: 0.08694, in 0.054s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03396, val loss: 0.08686, in 0.033s\n",
      "Fit 100 trees in 4.945 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.339s\n",
      "Time spent finding best splits:  0.726s\n",
      "Time spent applying splits:      1.110s\n",
      "Time spent predicting:           0.058s\n",
      "Binning 0.089 GB of training data: 0.174 s\n",
      "Binning 0.010 GB of validation data: 0.017 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.42073, val loss: 0.41854, in 0.044s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.35629, val loss: 0.35403, in 0.049s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.30366, val loss: 0.30126, in 0.052s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.26013, val loss: 0.25761, in 0.065s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.22480, val loss: 0.22229, in 0.075s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.19581, val loss: 0.19326, in 0.045s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.17230, val loss: 0.16972, in 0.039s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15288, val loss: 0.15030, in 0.037s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.13685, val loss: 0.13428, in 0.041s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.12332, val loss: 0.12093, in 0.041s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11237, val loss: 0.10997, in 0.044s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10337, val loss: 0.10095, in 0.042s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09557, val loss: 0.09341, in 0.043s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.08935, val loss: 0.08724, in 0.036s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.08409, val loss: 0.08205, in 0.033s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.07957, val loss: 0.07755, in 0.036s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.07583, val loss: 0.07383, in 0.034s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07270, val loss: 0.07072, in 0.035s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06995, val loss: 0.06805, in 0.036s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06704, val loss: 0.06547, in 0.034s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06456, val loss: 0.06337, in 0.044s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06293, val loss: 0.06181, in 0.049s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.06140, val loss: 0.06031, in 0.037s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05972, val loss: 0.05884, in 0.035s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05856, val loss: 0.05769, in 0.032s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05766, val loss: 0.05681, in 0.037s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05638, val loss: 0.05570, in 0.031s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05532, val loss: 0.05480, in 0.034s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05469, val loss: 0.05419, in 0.033s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05409, val loss: 0.05361, in 0.048s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05360, val loss: 0.05312, in 0.031s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05314, val loss: 0.05268, in 0.038s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05221, val loss: 0.05200, in 0.034s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05146, val loss: 0.05145, in 0.037s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05115, val loss: 0.05118, in 0.037s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05085, val loss: 0.05091, in 0.038s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05048, val loss: 0.05061, in 0.327s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05019, val loss: 0.05033, in 0.297s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04966, val loss: 0.05000, in 0.319s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04932, val loss: 0.04969, in 0.167s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.04904, val loss: 0.04941, in 0.052s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04879, val loss: 0.04919, in 0.044s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04837, val loss: 0.04888, in 0.033s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04817, val loss: 0.04869, in 0.036s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04796, val loss: 0.04847, in 0.031s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04767, val loss: 0.04820, in 0.034s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04748, val loss: 0.04798, in 0.037s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04733, val loss: 0.04783, in 0.032s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04704, val loss: 0.04764, in 0.050s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04687, val loss: 0.04748, in 0.034s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.04673, val loss: 0.04735, in 0.039s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04659, val loss: 0.04723, in 0.044s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04640, val loss: 0.04702, in 0.031s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04626, val loss: 0.04690, in 0.039s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04610, val loss: 0.04673, in 0.034s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04598, val loss: 0.04661, in 0.038s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.04572, val loss: 0.04630, in 0.036s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04562, val loss: 0.04620, in 0.037s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04552, val loss: 0.04611, in 0.034s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.04543, val loss: 0.04601, in 0.040s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04513, val loss: 0.04587, in 0.035s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04481, val loss: 0.04567, in 0.032s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04466, val loss: 0.04555, in 0.034s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04460, val loss: 0.04549, in 0.034s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04449, val loss: 0.04541, in 0.033s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.04438, val loss: 0.04530, in 0.031s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04432, val loss: 0.04525, in 0.032s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04416, val loss: 0.04515, in 0.033s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.04409, val loss: 0.04509, in 0.040s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04401, val loss: 0.04502, in 0.040s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04383, val loss: 0.04493, in 0.033s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04377, val loss: 0.04487, in 0.031s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04371, val loss: 0.04481, in 0.045s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04360, val loss: 0.04472, in 0.036s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04352, val loss: 0.04465, in 0.034s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04347, val loss: 0.04460, in 0.032s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04329, val loss: 0.04452, in 0.035s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04323, val loss: 0.04447, in 0.027s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04308, val loss: 0.04440, in 0.031s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.04301, val loss: 0.04433, in 0.023s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.04292, val loss: 0.04425, in 0.077s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04286, val loss: 0.04419, in 0.047s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04277, val loss: 0.04413, in 0.034s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04264, val loss: 0.04406, in 0.031s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04258, val loss: 0.04399, in 0.036s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04253, val loss: 0.04394, in 0.032s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.04249, val loss: 0.04391, in 0.029s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04242, val loss: 0.04385, in 0.037s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04238, val loss: 0.04382, in 0.036s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04232, val loss: 0.04378, in 0.034s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04225, val loss: 0.04371, in 0.055s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04219, val loss: 0.04365, in 0.060s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04211, val loss: 0.04359, in 0.032s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04199, val loss: 0.04350, in 0.032s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04192, val loss: 0.04342, in 0.029s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04189, val loss: 0.04340, in 0.033s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04185, val loss: 0.04337, in 0.030s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04181, val loss: 0.04334, in 0.032s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04176, val loss: 0.04329, in 0.026s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04170, val loss: 0.04324, in 0.029s\n",
      "Fit 100 trees in 4.996 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.403s\n",
      "Time spent finding best splits:  0.728s\n",
      "Time spent applying splits:      0.955s\n",
      "Time spent predicting:           0.068s\n",
      "Binning 0.089 GB of training data: 0.165 s\n",
      "Binning 0.010 GB of validation data: 0.015 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.41741, val loss: 0.42346, in 0.041s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.35103, val loss: 0.35596, in 0.038s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.29718, val loss: 0.30113, in 0.037s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.25342, val loss: 0.25663, in 0.036s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.21785, val loss: 0.22047, in 0.037s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.18894, val loss: 0.19103, in 0.037s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.16549, val loss: 0.16709, in 0.034s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14638, val loss: 0.14758, in 0.033s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13077, val loss: 0.13166, in 0.034s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11805, val loss: 0.11870, in 0.040s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.10770, val loss: 0.10812, in 0.081s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09919, val loss: 0.09946, in 0.050s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.09222, val loss: 0.09233, in 0.041s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08653, val loss: 0.08651, in 0.043s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08183, val loss: 0.08172, in 0.034s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07790, val loss: 0.07768, in 0.034s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07467, val loss: 0.07439, in 0.032s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.07206, val loss: 0.07170, in 0.036s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06979, val loss: 0.06939, in 0.036s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06790, val loss: 0.06743, in 0.030s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06636, val loss: 0.06584, in 0.036s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.06502, val loss: 0.06446, in 0.028s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06387, val loss: 0.06330, in 0.034s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.06294, val loss: 0.06236, in 0.032s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.06206, val loss: 0.06151, in 0.031s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06136, val loss: 0.06081, in 0.029s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06079, val loss: 0.06021, in 0.030s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06018, val loss: 0.05962, in 0.043s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05971, val loss: 0.05914, in 0.069s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05931, val loss: 0.05872, in 0.077s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05893, val loss: 0.05832, in 0.051s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05862, val loss: 0.05802, in 0.047s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05833, val loss: 0.05774, in 0.046s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05806, val loss: 0.05748, in 0.101s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05781, val loss: 0.05724, in 0.040s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05759, val loss: 0.05704, in 0.029s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05739, val loss: 0.05685, in 0.032s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05717, val loss: 0.05665, in 0.031s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05697, val loss: 0.05645, in 0.037s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05679, val loss: 0.05626, in 0.044s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05660, val loss: 0.05609, in 0.049s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05647, val loss: 0.05595, in 0.031s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05628, val loss: 0.05575, in 0.031s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05612, val loss: 0.05560, in 0.053s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05600, val loss: 0.05548, in 0.042s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05586, val loss: 0.05536, in 0.036s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05573, val loss: 0.05526, in 0.234s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05562, val loss: 0.05516, in 0.818s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05551, val loss: 0.05509, in 0.143s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05538, val loss: 0.05498, in 0.205s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05527, val loss: 0.05490, in 0.038s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05516, val loss: 0.05480, in 0.034s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05505, val loss: 0.05470, in 0.033s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05489, val loss: 0.05454, in 0.037s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05481, val loss: 0.05447, in 0.031s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05471, val loss: 0.05440, in 0.031s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05459, val loss: 0.05427, in 0.033s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05447, val loss: 0.05418, in 0.030s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05440, val loss: 0.05411, in 0.036s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05429, val loss: 0.05399, in 0.034s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05421, val loss: 0.05393, in 0.034s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05410, val loss: 0.05383, in 0.035s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05402, val loss: 0.05376, in 0.036s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05390, val loss: 0.05365, in 0.036s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05382, val loss: 0.05358, in 0.034s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05374, val loss: 0.05350, in 0.027s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05364, val loss: 0.05342, in 0.024s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05359, val loss: 0.05337, in 0.024s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05353, val loss: 0.05334, in 0.029s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05341, val loss: 0.05326, in 0.028s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05335, val loss: 0.05321, in 0.024s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.05327, val loss: 0.05314, in 0.031s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05320, val loss: 0.05308, in 0.031s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05313, val loss: 0.05304, in 0.035s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05308, val loss: 0.05301, in 0.029s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05304, val loss: 0.05299, in 0.025s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05297, val loss: 0.05293, in 0.027s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.05287, val loss: 0.05285, in 0.029s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05282, val loss: 0.05281, in 0.030s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05271, val loss: 0.05271, in 0.037s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.05264, val loss: 0.05267, in 0.029s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05257, val loss: 0.05262, in 0.030s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05250, val loss: 0.05255, in 0.033s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05246, val loss: 0.05252, in 0.025s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05242, val loss: 0.05249, in 0.029s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05239, val loss: 0.05247, in 0.024s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05232, val loss: 0.05241, in 0.034s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05228, val loss: 0.05238, in 0.025s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.05223, val loss: 0.05233, in 0.031s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05218, val loss: 0.05229, in 0.028s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05214, val loss: 0.05227, in 0.023s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05207, val loss: 0.05223, in 0.031s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05204, val loss: 0.05222, in 0.020s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05198, val loss: 0.05216, in 0.032s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05191, val loss: 0.05211, in 0.024s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05188, val loss: 0.05211, in 0.025s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 22, train loss: 0.05181, val loss: 0.05208, in 0.029s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05176, val loss: 0.05207, in 0.026s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05169, val loss: 0.05200, in 0.028s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.05166, val loss: 0.05198, in 0.046s\n",
      "Fit 100 trees in 5.047 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.355s\n",
      "Time spent finding best splits:  0.802s\n",
      "Time spent applying splits:      1.108s\n",
      "Time spent predicting:           0.064s\n",
      "Binning 0.088 GB of training data: 0.159 s\n",
      "Binning 0.010 GB of validation data: 0.017 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41341, val loss: 0.41750, in 0.047s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.34349, val loss: 0.34801, in 0.045s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.28585, val loss: 0.29072, in 0.060s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.23962, val loss: 0.24471, in 0.044s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.20146, val loss: 0.20670, in 0.047s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.17011, val loss: 0.17561, in 0.048s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14469, val loss: 0.14997, in 0.036s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12380, val loss: 0.12977, in 0.036s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10695, val loss: 0.11292, in 0.033s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09280, val loss: 0.09900, in 0.035s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.08073, val loss: 0.08536, in 0.035s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.07067, val loss: 0.07621, in 0.050s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.06271, val loss: 0.06848, in 0.041s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05516, val loss: 0.06160, in 0.040s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04968, val loss: 0.05540, in 0.040s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04427, val loss: 0.04986, in 0.040s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04051, val loss: 0.04628, in 0.040s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03688, val loss: 0.04217, in 0.038s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.03392, val loss: 0.03883, in 0.034s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03098, val loss: 0.03604, in 0.034s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02857, val loss: 0.03366, in 0.064s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02656, val loss: 0.03130, in 0.059s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02485, val loss: 0.02937, in 0.039s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02337, val loss: 0.02797, in 0.036s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02247, val loss: 0.02689, in 0.039s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.02163, val loss: 0.02622, in 0.039s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02104, val loss: 0.02553, in 0.162s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02005, val loss: 0.02456, in 0.072s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01945, val loss: 0.02417, in 0.083s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01876, val loss: 0.02338, in 0.081s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01845, val loss: 0.02317, in 0.046s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01804, val loss: 0.02296, in 0.046s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01769, val loss: 0.02253, in 0.043s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01745, val loss: 0.02238, in 0.030s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01729, val loss: 0.02221, in 0.031s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01685, val loss: 0.02170, in 0.029s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01666, val loss: 0.02156, in 0.036s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01646, val loss: 0.02149, in 0.039s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01625, val loss: 0.02120, in 0.033s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01613, val loss: 0.02112, in 0.029s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01603, val loss: 0.02102, in 0.031s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01568, val loss: 0.02083, in 0.045s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01555, val loss: 0.02079, in 0.030s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01532, val loss: 0.02062, in 0.030s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01505, val loss: 0.02065, in 0.031s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01497, val loss: 0.02055, in 0.030s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01482, val loss: 0.02036, in 0.026s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01474, val loss: 0.02029, in 0.033s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01462, val loss: 0.02022, in 0.029s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01457, val loss: 0.02017, in 0.028s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01438, val loss: 0.01982, in 0.038s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01423, val loss: 0.01961, in 0.063s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01415, val loss: 0.01956, in 0.047s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01399, val loss: 0.01946, in 0.028s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01389, val loss: 0.01942, in 0.032s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01385, val loss: 0.01938, in 0.044s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01379, val loss: 0.01933, in 0.034s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01374, val loss: 0.01927, in 0.027s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01363, val loss: 0.01922, in 0.025s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01359, val loss: 0.01922, in 0.030s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01354, val loss: 0.01917, in 0.033s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01345, val loss: 0.01913, in 0.027s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01336, val loss: 0.01904, in 0.035s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01323, val loss: 0.01884, in 0.032s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01316, val loss: 0.01881, in 0.037s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01309, val loss: 0.01881, in 0.026s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01306, val loss: 0.01878, in 0.028s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01296, val loss: 0.01869, in 0.024s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01287, val loss: 0.01851, in 0.046s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01284, val loss: 0.01849, in 0.076s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01268, val loss: 0.01841, in 0.852s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01262, val loss: 0.01838, in 0.135s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.01260, val loss: 0.01836, in 0.070s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01257, val loss: 0.01834, in 0.194s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01253, val loss: 0.01831, in 0.071s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01246, val loss: 0.01830, in 0.027s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01243, val loss: 0.01827, in 0.036s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01238, val loss: 0.01824, in 0.047s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01234, val loss: 0.01822, in 0.046s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01229, val loss: 0.01821, in 0.026s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01225, val loss: 0.01818, in 0.023s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01221, val loss: 0.01816, in 0.024s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01216, val loss: 0.01811, in 0.030s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01212, val loss: 0.01809, in 0.025s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01209, val loss: 0.01802, in 0.022s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.01204, val loss: 0.01801, in 0.027s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01196, val loss: 0.01798, in 0.030s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01191, val loss: 0.01794, in 0.032s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01187, val loss: 0.01792, in 0.036s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01183, val loss: 0.01788, in 0.032s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01179, val loss: 0.01782, in 0.026s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01177, val loss: 0.01779, in 0.028s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01173, val loss: 0.01778, in 0.029s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01171, val loss: 0.01774, in 0.041s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01170, val loss: 0.01772, in 0.061s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01168, val loss: 0.01772, in 0.049s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01160, val loss: 0.01767, in 0.030s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01158, val loss: 0.01763, in 0.027s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01154, val loss: 0.01763, in 0.028s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01152, val loss: 0.01762, in 0.029s\n",
      "Fit 100 trees in 5.281 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.524s\n",
      "Time spent finding best splits:  0.813s\n",
      "Time spent applying splits:      1.144s\n",
      "Time spent predicting:           0.049s\n",
      "Binning 0.087 GB of training data: 0.162 s\n",
      "Binning 0.010 GB of validation data: 0.015 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.43164, val loss: 0.42838, in 0.035s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.37571, val loss: 0.37219, in 0.036s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.33061, val loss: 0.32673, in 0.035s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.29380, val loss: 0.28987, in 0.033s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.26363, val loss: 0.25961, in 0.038s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.23907, val loss: 0.23487, in 0.039s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.21897, val loss: 0.21508, in 0.039s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.20246, val loss: 0.19857, in 0.037s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18907, val loss: 0.18547, in 0.033s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.17809, val loss: 0.17468, in 0.041s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.16897, val loss: 0.16562, in 0.030s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.16147, val loss: 0.15845, in 0.024s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15535, val loss: 0.15239, in 0.030s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15021, val loss: 0.14757, in 0.032s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14592, val loss: 0.14356, in 0.043s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.14228, val loss: 0.14017, in 0.031s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13909, val loss: 0.13710, in 0.036s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13664, val loss: 0.13481, in 0.030s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13448, val loss: 0.13276, in 0.029s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.13199, val loss: 0.13026, in 0.036s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13042, val loss: 0.12878, in 0.043s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12890, val loss: 0.12725, in 0.033s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12773, val loss: 0.12614, in 0.040s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12646, val loss: 0.12486, in 0.035s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.12486, val loss: 0.12355, in 0.033s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12398, val loss: 0.12288, in 0.033s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.12324, val loss: 0.12226, in 0.032s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.12243, val loss: 0.12152, in 0.033s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.12176, val loss: 0.12102, in 0.033s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.12134, val loss: 0.12068, in 0.030s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.12080, val loss: 0.12024, in 0.029s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.12030, val loss: 0.11985, in 0.035s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11985, val loss: 0.11957, in 0.034s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11885, val loss: 0.11886, in 0.038s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11833, val loss: 0.11843, in 0.040s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11732, val loss: 0.11786, in 0.040s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.11701, val loss: 0.11773, in 0.040s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11674, val loss: 0.11761, in 0.037s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11559, val loss: 0.11651, in 0.042s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11479, val loss: 0.11589, in 0.052s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11438, val loss: 0.11543, in 0.056s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11366, val loss: 0.11475, in 0.049s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11335, val loss: 0.11451, in 0.045s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.11289, val loss: 0.11432, in 0.038s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11269, val loss: 0.11420, in 0.026s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11167, val loss: 0.11323, in 0.029s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.11141, val loss: 0.11308, in 0.032s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11064, val loss: 0.11240, in 0.029s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11042, val loss: 0.11223, in 0.028s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11001, val loss: 0.11182, in 0.035s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10965, val loss: 0.11160, in 0.026s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.10938, val loss: 0.11151, in 0.034s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10917, val loss: 0.11143, in 0.031s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10856, val loss: 0.11086, in 0.027s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.10821, val loss: 0.11072, in 0.027s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10792, val loss: 0.11049, in 0.029s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.10720, val loss: 0.10984, in 0.029s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10696, val loss: 0.10976, in 0.023s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10677, val loss: 0.10960, in 0.021s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.10645, val loss: 0.10940, in 0.022s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10608, val loss: 0.10900, in 0.029s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10591, val loss: 0.10895, in 0.021s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10564, val loss: 0.10867, in 0.024s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.10551, val loss: 0.10865, in 0.023s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.10524, val loss: 0.10855, in 0.023s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10504, val loss: 0.10839, in 0.026s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.10484, val loss: 0.10833, in 0.023s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10464, val loss: 0.10820, in 0.026s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10446, val loss: 0.10812, in 0.019s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10427, val loss: 0.10799, in 0.021s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10408, val loss: 0.10789, in 0.031s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10333, val loss: 0.10714, in 0.028s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10310, val loss: 0.10698, in 0.027s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10290, val loss: 0.10679, in 0.023s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10266, val loss: 0.10666, in 0.030s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10215, val loss: 0.10620, in 0.033s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.10189, val loss: 0.10600, in 0.038s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10149, val loss: 0.10569, in 0.033s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10135, val loss: 0.10561, in 0.029s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.10102, val loss: 0.10516, in 0.047s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10090, val loss: 0.10507, in 0.110s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10071, val loss: 0.10489, in 0.822s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10033, val loss: 0.10453, in 0.089s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.10011, val loss: 0.10428, in 0.121s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09999, val loss: 0.10421, in 0.031s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.09969, val loss: 0.10401, in 0.021s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09957, val loss: 0.10395, in 0.029s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.09940, val loss: 0.10387, in 0.027s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.09926, val loss: 0.10372, in 0.024s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.09883, val loss: 0.10334, in 0.035s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.09873, val loss: 0.10327, in 0.025s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.09852, val loss: 0.10310, in 0.030s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09839, val loss: 0.10300, in 0.031s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09826, val loss: 0.10295, in 0.026s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09814, val loss: 0.10281, in 0.036s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09804, val loss: 0.10274, in 0.036s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.09776, val loss: 0.10263, in 0.046s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09763, val loss: 0.10257, in 0.027s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.09752, val loss: 0.10254, in 0.025s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.09734, val loss: 0.10240, in 0.024s\n",
      "Fit 100 trees in 4.464 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.043s\n",
      "Time spent finding best splits:  0.674s\n",
      "Time spent applying splits:      1.050s\n",
      "Time spent predicting:           0.043s\n",
      "Binning 0.087 GB of training data: 0.159 s\n",
      "Binning 0.010 GB of validation data: 0.019 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.42792, val loss: 0.42452, in 0.032s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.36927, val loss: 0.36696, in 0.029s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.32158, val loss: 0.32014, in 0.033s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.28286, val loss: 0.28210, in 0.033s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.25124, val loss: 0.25101, in 0.036s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.22577, val loss: 0.22599, in 0.032s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.20488, val loss: 0.20536, in 0.032s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.18787, val loss: 0.18855, in 0.031s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.17394, val loss: 0.17479, in 0.037s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.16227, val loss: 0.16315, in 0.033s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.15268, val loss: 0.15363, in 0.035s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14528, val loss: 0.14633, in 0.063s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.13893, val loss: 0.13996, in 0.032s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.13357, val loss: 0.13459, in 0.030s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12938, val loss: 0.13043, in 0.033s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.12575, val loss: 0.12683, in 0.028s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12242, val loss: 0.12349, in 0.031s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.12005, val loss: 0.12115, in 0.025s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11779, val loss: 0.11895, in 0.026s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11589, val loss: 0.11697, in 0.027s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11444, val loss: 0.11555, in 0.027s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11301, val loss: 0.11411, in 0.024s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11179, val loss: 0.11280, in 0.024s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11088, val loss: 0.11199, in 0.024s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10984, val loss: 0.11098, in 0.027s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.10893, val loss: 0.11014, in 0.034s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.10822, val loss: 0.10946, in 0.025s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10759, val loss: 0.10888, in 0.029s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10699, val loss: 0.10842, in 0.026s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.10638, val loss: 0.10789, in 0.034s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10589, val loss: 0.10739, in 0.032s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.10542, val loss: 0.10704, in 0.040s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10495, val loss: 0.10653, in 0.036s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.10442, val loss: 0.10612, in 0.035s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10407, val loss: 0.10587, in 0.033s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10371, val loss: 0.10550, in 0.034s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.10344, val loss: 0.10532, in 0.033s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10309, val loss: 0.10502, in 0.033s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.10269, val loss: 0.10469, in 0.032s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10240, val loss: 0.10442, in 0.038s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10210, val loss: 0.10417, in 0.033s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10173, val loss: 0.10379, in 0.034s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.10145, val loss: 0.10352, in 0.043s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10123, val loss: 0.10332, in 0.036s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10102, val loss: 0.10313, in 0.041s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10074, val loss: 0.10286, in 0.043s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.10045, val loss: 0.10259, in 0.037s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10024, val loss: 0.10240, in 0.032s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.10008, val loss: 0.10227, in 0.031s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.09992, val loss: 0.10213, in 0.031s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.09976, val loss: 0.10202, in 0.039s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.09956, val loss: 0.10183, in 0.039s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09939, val loss: 0.10168, in 0.036s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09925, val loss: 0.10158, in 0.029s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.09910, val loss: 0.10147, in 0.032s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.09898, val loss: 0.10138, in 0.023s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.09886, val loss: 0.10128, in 0.027s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.09868, val loss: 0.10114, in 0.028s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.09860, val loss: 0.10104, in 0.020s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09852, val loss: 0.10098, in 0.022s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.09835, val loss: 0.10086, in 0.024s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09829, val loss: 0.10082, in 0.022s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.09818, val loss: 0.10077, in 0.020s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.09804, val loss: 0.10067, in 0.023s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.09792, val loss: 0.10057, in 0.027s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09784, val loss: 0.10049, in 0.025s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09776, val loss: 0.10037, in 0.025s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09766, val loss: 0.10036, in 0.038s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09756, val loss: 0.10031, in 0.025s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09749, val loss: 0.10027, in 0.022s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.09733, val loss: 0.10015, in 0.023s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.09722, val loss: 0.10005, in 0.024s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09708, val loss: 0.09993, in 0.021s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.09694, val loss: 0.09987, in 0.024s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.09687, val loss: 0.09987, in 0.022s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.09677, val loss: 0.09981, in 0.024s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.09659, val loss: 0.09971, in 0.026s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09652, val loss: 0.09966, in 0.029s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09638, val loss: 0.09956, in 0.028s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.09632, val loss: 0.09954, in 0.022s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09619, val loss: 0.09943, in 0.026s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09614, val loss: 0.09940, in 0.030s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.09608, val loss: 0.09939, in 0.027s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09599, val loss: 0.09932, in 0.034s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.09587, val loss: 0.09928, in 0.027s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.09574, val loss: 0.09921, in 0.023s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09563, val loss: 0.09914, in 0.021s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.09554, val loss: 0.09907, in 0.024s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.09545, val loss: 0.09899, in 0.025s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09538, val loss: 0.09896, in 0.023s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.09529, val loss: 0.09891, in 0.021s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.09519, val loss: 0.09885, in 0.024s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.09514, val loss: 0.09885, in 0.022s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.09503, val loss: 0.09879, in 0.024s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.09493, val loss: 0.09871, in 0.022s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09483, val loss: 0.09863, in 0.026s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09476, val loss: 0.09860, in 0.025s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09469, val loss: 0.09856, in 0.026s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.09460, val loss: 0.09855, in 0.026s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09455, val loss: 0.09852, in 0.032s\n",
      "Fit 100 trees in 3.173 s, (3100 total leaves)\n",
      "Time spent computing histograms: 1.465s\n",
      "Time spent finding best splits:  0.439s\n",
      "Time spent applying splits:      0.590s\n",
      "Time spent predicting:           0.043s\n",
      "Binning 0.080 GB of training data: 0.973 s\n",
      "Binning 0.009 GB of validation data: 0.081 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.41759, val loss: 0.42090, in 0.043s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.35116, val loss: 0.35402, in 0.034s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.29727, val loss: 0.29973, in 0.033s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.25345, val loss: 0.25561, in 0.031s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.21782, val loss: 0.21969, in 0.036s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.18884, val loss: 0.19047, in 0.035s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.16525, val loss: 0.16672, in 0.030s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.14582, val loss: 0.14716, in 0.032s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.13006, val loss: 0.13127, in 0.034s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11724, val loss: 0.11841, in 0.032s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10667, val loss: 0.10779, in 0.034s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09810, val loss: 0.09919, in 0.035s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.09103, val loss: 0.09208, in 0.030s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.08530, val loss: 0.08631, in 0.034s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.08057, val loss: 0.08158, in 0.031s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.07660, val loss: 0.07761, in 0.032s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07324, val loss: 0.07427, in 0.030s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07051, val loss: 0.07154, in 0.032s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06819, val loss: 0.06925, in 0.031s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06627, val loss: 0.06734, in 0.035s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06459, val loss: 0.06564, in 0.034s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06321, val loss: 0.06428, in 0.032s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06205, val loss: 0.06315, in 0.031s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06103, val loss: 0.06211, in 0.031s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.06022, val loss: 0.06130, in 0.036s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05949, val loss: 0.06058, in 0.032s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05885, val loss: 0.05995, in 0.029s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05830, val loss: 0.05945, in 0.032s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05783, val loss: 0.05900, in 0.029s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05736, val loss: 0.05856, in 0.030s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05694, val loss: 0.05816, in 0.032s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05658, val loss: 0.05779, in 0.034s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05623, val loss: 0.05749, in 0.028s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05595, val loss: 0.05725, in 0.030s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05565, val loss: 0.05695, in 0.031s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05536, val loss: 0.05669, in 0.026s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05513, val loss: 0.05646, in 0.027s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05491, val loss: 0.05626, in 0.028s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05463, val loss: 0.05604, in 0.025s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05443, val loss: 0.05586, in 0.034s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05424, val loss: 0.05567, in 0.039s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05409, val loss: 0.05554, in 0.024s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05394, val loss: 0.05540, in 0.027s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05365, val loss: 0.05509, in 0.027s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.05347, val loss: 0.05492, in 0.028s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05325, val loss: 0.05467, in 0.026s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05314, val loss: 0.05457, in 0.026s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05297, val loss: 0.05440, in 0.027s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05285, val loss: 0.05431, in 0.025s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.05271, val loss: 0.05418, in 0.029s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05259, val loss: 0.05410, in 0.025s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.05247, val loss: 0.05401, in 0.024s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05236, val loss: 0.05392, in 0.023s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05225, val loss: 0.05385, in 0.025s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05215, val loss: 0.05375, in 0.028s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.05206, val loss: 0.05366, in 0.030s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05195, val loss: 0.05358, in 0.022s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05186, val loss: 0.05348, in 0.052s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.05173, val loss: 0.05335, in 0.025s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05158, val loss: 0.05319, in 0.023s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05150, val loss: 0.05313, in 0.026s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.05140, val loss: 0.05307, in 0.026s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05132, val loss: 0.05304, in 0.020s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.05123, val loss: 0.05294, in 0.027s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05116, val loss: 0.05291, in 0.023s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05107, val loss: 0.05283, in 0.022s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05100, val loss: 0.05276, in 0.026s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05089, val loss: 0.05272, in 0.028s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05078, val loss: 0.05261, in 0.036s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05072, val loss: 0.05257, in 0.025s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05064, val loss: 0.05252, in 0.028s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05058, val loss: 0.05248, in 0.027s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05053, val loss: 0.05243, in 0.025s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05044, val loss: 0.05237, in 0.021s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05038, val loss: 0.05233, in 0.022s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05026, val loss: 0.05225, in 0.024s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05019, val loss: 0.05222, in 0.026s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05013, val loss: 0.05216, in 0.027s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05007, val loss: 0.05212, in 0.025s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04998, val loss: 0.05207, in 0.020s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04993, val loss: 0.05202, in 0.023s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04988, val loss: 0.05197, in 0.027s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04978, val loss: 0.05190, in 0.025s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04973, val loss: 0.05185, in 0.026s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04968, val loss: 0.05182, in 0.023s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04965, val loss: 0.05180, in 0.022s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04960, val loss: 0.05179, in 0.023s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.04956, val loss: 0.05176, in 0.022s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04949, val loss: 0.05173, in 0.023s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04941, val loss: 0.05165, in 0.027s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04935, val loss: 0.05161, in 0.025s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.04921, val loss: 0.05149, in 0.022s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04915, val loss: 0.05146, in 0.025s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04911, val loss: 0.05142, in 0.025s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04904, val loss: 0.05137, in 0.039s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04896, val loss: 0.05134, in 0.026s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04891, val loss: 0.05133, in 0.047s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.04885, val loss: 0.05132, in 0.030s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04881, val loss: 0.05129, in 0.023s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04877, val loss: 0.05126, in 0.027s\n",
      "Fit 100 trees in 3.987 s, (3100 total leaves)\n",
      "Time spent computing histograms: 1.453s\n",
      "Time spent finding best splits:  0.410s\n",
      "Time spent applying splits:      0.580s\n",
      "Time spent predicting:           0.041s\n",
      "Binning 0.075 GB of training data: 0.158 s\n",
      "Binning 0.008 GB of validation data: 0.013 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.48805, val loss: 0.48691, in 0.046s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.47829, val loss: 0.47693, in 0.034s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.47021, val loss: 0.46866, in 0.033s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.46342, val loss: 0.46175, in 0.035s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.45776, val loss: 0.45591, in 0.042s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.45315, val loss: 0.45113, in 0.034s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.44912, val loss: 0.44705, in 0.031s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.44585, val loss: 0.44369, in 0.029s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.44319, val loss: 0.44101, in 0.031s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.44087, val loss: 0.43869, in 0.029s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.43901, val loss: 0.43682, in 0.037s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.43733, val loss: 0.43515, in 0.044s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.43596, val loss: 0.43375, in 0.033s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.43481, val loss: 0.43259, in 0.035s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.43361, val loss: 0.43140, in 0.032s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.43267, val loss: 0.43045, in 0.029s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.43196, val loss: 0.42978, in 0.057s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.43118, val loss: 0.42907, in 0.295s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.43041, val loss: 0.42828, in 0.688s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.42972, val loss: 0.42758, in 0.045s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.42915, val loss: 0.42710, in 0.040s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.42851, val loss: 0.42647, in 0.071s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.42806, val loss: 0.42610, in 0.032s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.42757, val loss: 0.42571, in 0.035s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.42691, val loss: 0.42501, in 0.035s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.42648, val loss: 0.42463, in 0.048s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.42615, val loss: 0.42433, in 0.045s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.42579, val loss: 0.42406, in 0.043s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.42549, val loss: 0.42383, in 0.046s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.42509, val loss: 0.42347, in 0.041s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.42466, val loss: 0.42307, in 0.043s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.42437, val loss: 0.42283, in 0.064s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.42408, val loss: 0.42259, in 0.051s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.42375, val loss: 0.42229, in 0.040s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.42338, val loss: 0.42194, in 0.034s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.42299, val loss: 0.42151, in 0.046s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.42275, val loss: 0.42135, in 0.039s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.42244, val loss: 0.42107, in 0.036s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.42217, val loss: 0.42087, in 0.035s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.42187, val loss: 0.42058, in 0.031s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.42156, val loss: 0.42024, in 0.039s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.42131, val loss: 0.42000, in 0.046s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.42110, val loss: 0.41985, in 0.028s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.42093, val loss: 0.41969, in 0.033s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.42064, val loss: 0.41943, in 0.032s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.42040, val loss: 0.41924, in 0.048s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.42010, val loss: 0.41893, in 0.031s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.41992, val loss: 0.41877, in 0.024s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41973, val loss: 0.41863, in 0.034s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41953, val loss: 0.41844, in 0.031s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41937, val loss: 0.41829, in 0.029s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41918, val loss: 0.41812, in 0.029s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41896, val loss: 0.41792, in 0.026s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.41881, val loss: 0.41779, in 0.023s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41863, val loss: 0.41763, in 0.029s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41848, val loss: 0.41750, in 0.023s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41830, val loss: 0.41737, in 0.033s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41814, val loss: 0.41728, in 0.024s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.41797, val loss: 0.41716, in 0.026s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41779, val loss: 0.41700, in 0.024s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41766, val loss: 0.41693, in 0.034s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41744, val loss: 0.41673, in 0.029s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41719, val loss: 0.41652, in 0.028s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.41704, val loss: 0.41641, in 0.026s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41684, val loss: 0.41622, in 0.029s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.41660, val loss: 0.41597, in 0.026s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41636, val loss: 0.41576, in 0.022s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41612, val loss: 0.41557, in 0.028s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.41600, val loss: 0.41545, in 0.023s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41584, val loss: 0.41534, in 0.025s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41565, val loss: 0.41518, in 0.025s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41553, val loss: 0.41508, in 0.030s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41532, val loss: 0.41489, in 0.025s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41515, val loss: 0.41473, in 0.025s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.41503, val loss: 0.41469, in 0.024s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41492, val loss: 0.41464, in 0.026s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41482, val loss: 0.41458, in 0.023s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41463, val loss: 0.41445, in 0.040s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41451, val loss: 0.41437, in 0.033s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41433, val loss: 0.41421, in 0.031s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41421, val loss: 0.41409, in 0.022s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41410, val loss: 0.41402, in 0.020s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41400, val loss: 0.41397, in 0.021s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41387, val loss: 0.41388, in 0.022s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.41367, val loss: 0.41370, in 0.038s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.41352, val loss: 0.41356, in 0.025s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41338, val loss: 0.41349, in 0.030s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.41320, val loss: 0.41334, in 0.033s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41310, val loss: 0.41328, in 0.027s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41296, val loss: 0.41314, in 0.032s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41281, val loss: 0.41300, in 0.035s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.41271, val loss: 0.41296, in 0.025s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41253, val loss: 0.41285, in 0.032s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41240, val loss: 0.41276, in 0.024s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.41233, val loss: 0.41276, in 0.023s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41223, val loss: 0.41273, in 0.024s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41214, val loss: 0.41265, in 0.022s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.41197, val loss: 0.41253, in 0.031s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.41185, val loss: 0.41245, in 0.024s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.41174, val loss: 0.41236, in 0.025s\n",
      "Fit 100 trees in 4.420 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.164s\n",
      "Time spent finding best splits:  0.700s\n",
      "Time spent applying splits:      0.891s\n",
      "Time spent predicting:           0.045s\n",
      "Binning 0.060 GB of training data: 0.140 s\n",
      "Binning 0.007 GB of validation data: 0.008 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.44378, val loss: 0.44420, in 0.033s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.39869, val loss: 0.39918, in 0.029s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.36176, val loss: 0.36233, in 0.028s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.33116, val loss: 0.33189, in 0.027s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.30629, val loss: 0.30691, in 0.033s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.28559, val loss: 0.28617, in 0.028s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.26890, val loss: 0.26952, in 0.030s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.25486, val loss: 0.25533, in 0.028s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.24308, val loss: 0.24354, in 0.029s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.23334, val loss: 0.23385, in 0.029s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.22466, val loss: 0.22515, in 0.029s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.21806, val loss: 0.21866, in 0.027s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.21175, val loss: 0.21222, in 0.028s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.20666, val loss: 0.20712, in 0.030s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.20179, val loss: 0.20218, in 0.028s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.19817, val loss: 0.19850, in 0.029s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.19445, val loss: 0.19470, in 0.026s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.19135, val loss: 0.19161, in 0.025s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.18824, val loss: 0.18855, in 0.028s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18600, val loss: 0.18624, in 0.027s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.18385, val loss: 0.18415, in 0.028s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.18165, val loss: 0.18190, in 0.026s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.17993, val loss: 0.18024, in 0.027s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.17860, val loss: 0.17889, in 0.034s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.17727, val loss: 0.17761, in 0.043s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.17588, val loss: 0.17624, in 0.030s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.17413, val loss: 0.17439, in 0.028s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.17299, val loss: 0.17328, in 0.030s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.17198, val loss: 0.17228, in 0.027s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.17107, val loss: 0.17138, in 0.039s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.16966, val loss: 0.16991, in 0.717s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16891, val loss: 0.16918, in 0.168s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.16823, val loss: 0.16852, in 0.033s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16753, val loss: 0.16784, in 0.029s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.16678, val loss: 0.16706, in 0.027s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.16597, val loss: 0.16635, in 0.028s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16532, val loss: 0.16583, in 0.027s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.16467, val loss: 0.16516, in 0.024s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.16399, val loss: 0.16448, in 0.033s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16347, val loss: 0.16396, in 0.029s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.16296, val loss: 0.16350, in 0.034s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.16221, val loss: 0.16274, in 0.028s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.16186, val loss: 0.16237, in 0.026s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.16104, val loss: 0.16152, in 0.027s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16037, val loss: 0.16087, in 0.030s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15978, val loss: 0.16037, in 0.027s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15930, val loss: 0.15987, in 0.024s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 19, train loss: 0.15876, val loss: 0.15936, in 0.027s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15829, val loss: 0.15895, in 0.028s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15773, val loss: 0.15837, in 0.024s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15728, val loss: 0.15800, in 0.028s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15688, val loss: 0.15768, in 0.027s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15646, val loss: 0.15728, in 0.030s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15604, val loss: 0.15685, in 0.036s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.15566, val loss: 0.15647, in 0.033s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15537, val loss: 0.15616, in 0.027s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.15503, val loss: 0.15583, in 0.027s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15451, val loss: 0.15528, in 0.027s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15405, val loss: 0.15484, in 0.027s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15375, val loss: 0.15453, in 0.024s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15320, val loss: 0.15404, in 0.027s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.15276, val loss: 0.15366, in 0.028s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15249, val loss: 0.15343, in 0.050s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15211, val loss: 0.15306, in 0.025s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.15178, val loss: 0.15271, in 0.021s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15154, val loss: 0.15250, in 0.026s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15129, val loss: 0.15227, in 0.026s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15100, val loss: 0.15202, in 0.020s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15076, val loss: 0.15179, in 0.027s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.15052, val loss: 0.15156, in 0.032s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15028, val loss: 0.15131, in 0.031s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14999, val loss: 0.15108, in 0.026s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14958, val loss: 0.15066, in 0.025s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.14917, val loss: 0.15022, in 0.024s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14887, val loss: 0.14992, in 0.034s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14862, val loss: 0.14968, in 0.025s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14829, val loss: 0.14942, in 0.023s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14792, val loss: 0.14913, in 0.021s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14759, val loss: 0.14884, in 0.024s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.14737, val loss: 0.14865, in 0.023s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14714, val loss: 0.14846, in 0.026s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14693, val loss: 0.14830, in 0.025s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14668, val loss: 0.14810, in 0.025s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14655, val loss: 0.14799, in 0.024s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14632, val loss: 0.14779, in 0.018s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14613, val loss: 0.14762, in 0.027s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14599, val loss: 0.14752, in 0.020s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.14561, val loss: 0.14712, in 0.024s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14543, val loss: 0.14696, in 0.023s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.14529, val loss: 0.14688, in 0.025s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14501, val loss: 0.14660, in 0.024s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14468, val loss: 0.14625, in 0.022s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14407, val loss: 0.14561, in 0.027s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14381, val loss: 0.14538, in 0.027s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.14363, val loss: 0.14521, in 0.045s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14335, val loss: 0.14492, in 0.020s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14283, val loss: 0.14449, in 0.028s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14255, val loss: 0.14424, in 0.024s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14235, val loss: 0.14410, in 0.025s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14218, val loss: 0.14397, in 0.024s\n",
      "Fit 100 trees in 3.798 s, (3100 total leaves)\n",
      "Time spent computing histograms: 1.711s\n",
      "Time spent finding best splits:  0.690s\n",
      "Time spent applying splits:      0.831s\n",
      "Time spent predicting:           0.035s\n",
      "Binning 0.057 GB of training data: 0.129 s\n",
      "Binning 0.006 GB of validation data: 0.012 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.43248, val loss: 0.42936, in 0.045s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.37752, val loss: 0.37473, in 0.026s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.33277, val loss: 0.33019, in 0.027s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.29644, val loss: 0.29400, in 0.036s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.26696, val loss: 0.26473, in 0.030s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.24293, val loss: 0.24078, in 0.030s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.22327, val loss: 0.22123, in 0.026s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.20726, val loss: 0.20529, in 0.026s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.19421, val loss: 0.19229, in 0.027s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18359, val loss: 0.18164, in 0.026s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.17493, val loss: 0.17300, in 0.025s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.16769, val loss: 0.16578, in 0.028s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16177, val loss: 0.15988, in 0.024s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15694, val loss: 0.15510, in 0.024s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15293, val loss: 0.15111, in 0.027s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14960, val loss: 0.14771, in 0.027s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.14673, val loss: 0.14489, in 0.027s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14444, val loss: 0.14259, in 0.030s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14253, val loss: 0.14072, in 0.039s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14087, val loss: 0.13906, in 0.029s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13944, val loss: 0.13767, in 0.023s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13816, val loss: 0.13641, in 0.027s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.13710, val loss: 0.13535, in 0.027s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13612, val loss: 0.13436, in 0.028s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13534, val loss: 0.13358, in 0.024s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13467, val loss: 0.13294, in 0.024s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13400, val loss: 0.13237, in 0.025s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13346, val loss: 0.13188, in 0.023s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13299, val loss: 0.13145, in 0.023s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.13249, val loss: 0.13104, in 0.026s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.13207, val loss: 0.13066, in 0.025s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.13168, val loss: 0.13034, in 0.023s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.13122, val loss: 0.13000, in 0.024s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13085, val loss: 0.12966, in 0.025s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.13053, val loss: 0.12941, in 0.024s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.13023, val loss: 0.12918, in 0.026s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12993, val loss: 0.12889, in 0.024s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12959, val loss: 0.12861, in 0.023s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12937, val loss: 0.12843, in 0.025s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.12914, val loss: 0.12820, in 0.023s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12881, val loss: 0.12791, in 0.025s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12866, val loss: 0.12778, in 0.022s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12846, val loss: 0.12765, in 0.026s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12826, val loss: 0.12750, in 0.024s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.12811, val loss: 0.12738, in 0.027s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12800, val loss: 0.12729, in 0.022s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.12781, val loss: 0.12714, in 0.023s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12765, val loss: 0.12705, in 0.023s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12753, val loss: 0.12696, in 0.022s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12738, val loss: 0.12684, in 0.022s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12726, val loss: 0.12674, in 0.026s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12716, val loss: 0.12669, in 0.020s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12705, val loss: 0.12662, in 0.024s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.12692, val loss: 0.12650, in 0.020s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12681, val loss: 0.12644, in 0.022s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12671, val loss: 0.12637, in 0.022s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12662, val loss: 0.12629, in 0.023s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12651, val loss: 0.12621, in 0.020s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12638, val loss: 0.12615, in 0.023s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12629, val loss: 0.12610, in 0.141s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12622, val loss: 0.12608, in 0.407s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.12613, val loss: 0.12601, in 0.312s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.12600, val loss: 0.12593, in 0.173s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.12593, val loss: 0.12591, in 0.018s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12583, val loss: 0.12586, in 0.023s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12576, val loss: 0.12583, in 0.022s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12567, val loss: 0.12582, in 0.021s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12557, val loss: 0.12576, in 0.033s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12543, val loss: 0.12568, in 0.031s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12531, val loss: 0.12558, in 0.022s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12520, val loss: 0.12549, in 0.025s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.12513, val loss: 0.12548, in 0.046s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12494, val loss: 0.12535, in 0.035s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.12487, val loss: 0.12534, in 0.023s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12475, val loss: 0.12528, in 0.021s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.12465, val loss: 0.12521, in 0.020s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12457, val loss: 0.12519, in 0.021s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.12446, val loss: 0.12515, in 0.023s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12439, val loss: 0.12512, in 0.017s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12430, val loss: 0.12506, in 0.026s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12421, val loss: 0.12500, in 0.019s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12415, val loss: 0.12498, in 0.021s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12392, val loss: 0.12484, in 0.025s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.12384, val loss: 0.12478, in 0.022s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12374, val loss: 0.12473, in 0.020s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12365, val loss: 0.12468, in 0.021s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.12360, val loss: 0.12465, in 0.018s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.12352, val loss: 0.12464, in 0.023s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12345, val loss: 0.12460, in 0.018s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12337, val loss: 0.12456, in 0.019s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12325, val loss: 0.12447, in 0.023s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.12320, val loss: 0.12445, in 0.018s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12313, val loss: 0.12442, in 0.019s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12303, val loss: 0.12438, in 0.020s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12294, val loss: 0.12433, in 0.021s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12285, val loss: 0.12434, in 0.020s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12278, val loss: 0.12430, in 0.019s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.12271, val loss: 0.12426, in 0.019s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.12264, val loss: 0.12419, in 0.019s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12258, val loss: 0.12418, in 0.023s\n",
      "Fit 100 trees in 3.559 s, (3100 total leaves)\n",
      "Time spent computing histograms: 1.619s\n",
      "Time spent finding best splits:  0.537s\n",
      "Time spent applying splits:      0.828s\n",
      "Time spent predicting:           0.036s\n",
      "Binning 0.046 GB of training data: 0.122 s\n",
      "Binning 0.005 GB of validation data: 0.009 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.40562, val loss: 0.42206, in 0.021s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.33079, val loss: 0.34394, in 0.019s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.27017, val loss: 0.28040, in 0.021s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.22102, val loss: 0.22905, in 0.020s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.18115, val loss: 0.18737, in 0.019s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14882, val loss: 0.15362, in 0.020s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12255, val loss: 0.12616, in 0.019s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10120, val loss: 0.10388, in 0.022s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.08388, val loss: 0.08590, in 0.021s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06973, val loss: 0.07122, in 0.019s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05826, val loss: 0.05932, in 0.021s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04890, val loss: 0.04971, in 0.017s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04121, val loss: 0.04187, in 0.020s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03504, val loss: 0.03553, in 0.018s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02995, val loss: 0.03038, in 0.020s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02578, val loss: 0.02611, in 0.024s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02234, val loss: 0.02257, in 0.019s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01955, val loss: 0.01973, in 0.020s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01725, val loss: 0.01742, in 0.018s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01538, val loss: 0.01554, in 0.020s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01378, val loss: 0.01397, in 0.020s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01241, val loss: 0.01264, in 0.017s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01124, val loss: 0.01154, in 0.019s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01033, val loss: 0.01062, in 0.018s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00952, val loss: 0.00994, in 0.020s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00889, val loss: 0.00940, in 0.020s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00836, val loss: 0.00884, in 0.021s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00787, val loss: 0.00843, in 0.021s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00746, val loss: 0.00806, in 0.023s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00714, val loss: 0.00775, in 0.026s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00679, val loss: 0.00751, in 0.025s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00654, val loss: 0.00730, in 0.021s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00631, val loss: 0.00715, in 0.021s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00612, val loss: 0.00697, in 0.019s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00594, val loss: 0.00680, in 0.020s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00574, val loss: 0.00667, in 0.020s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00558, val loss: 0.00655, in 0.019s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00546, val loss: 0.00645, in 0.017s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00534, val loss: 0.00639, in 0.021s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00523, val loss: 0.00630, in 0.020s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00512, val loss: 0.00622, in 0.021s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.00504, val loss: 0.00618, in 0.024s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00496, val loss: 0.00613, in 0.019s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00489, val loss: 0.00610, in 0.019s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00484, val loss: 0.00605, in 0.019s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00476, val loss: 0.00601, in 0.019s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00468, val loss: 0.00596, in 0.018s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00462, val loss: 0.00590, in 0.018s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00457, val loss: 0.00588, in 0.021s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00451, val loss: 0.00584, in 0.020s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00447, val loss: 0.00583, in 0.021s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00443, val loss: 0.00581, in 0.019s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00440, val loss: 0.00579, in 0.019s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00436, val loss: 0.00577, in 0.018s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00432, val loss: 0.00574, in 0.018s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00424, val loss: 0.00565, in 0.019s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00421, val loss: 0.00565, in 0.017s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00415, val loss: 0.00560, in 0.025s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00411, val loss: 0.00558, in 0.020s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00406, val loss: 0.00551, in 0.018s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00402, val loss: 0.00547, in 0.016s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00399, val loss: 0.00546, in 0.021s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00394, val loss: 0.00539, in 0.018s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00391, val loss: 0.00538, in 0.016s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00388, val loss: 0.00535, in 0.021s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.00386, val loss: 0.00534, in 0.029s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00382, val loss: 0.00529, in 0.022s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00379, val loss: 0.00524, in 0.022s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00376, val loss: 0.00523, in 0.026s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00374, val loss: 0.00518, in 0.027s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00372, val loss: 0.00518, in 0.026s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00370, val loss: 0.00515, in 0.023s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00368, val loss: 0.00514, in 0.023s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00366, val loss: 0.00513, in 0.026s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00364, val loss: 0.00513, in 0.040s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00360, val loss: 0.00511, in 0.035s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00357, val loss: 0.00504, in 0.038s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00356, val loss: 0.00502, in 0.028s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00354, val loss: 0.00501, in 0.028s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00352, val loss: 0.00501, in 0.022s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00350, val loss: 0.00500, in 0.020s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00349, val loss: 0.00499, in 0.022s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00347, val loss: 0.00499, in 0.017s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00345, val loss: 0.00497, in 0.018s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00343, val loss: 0.00496, in 0.019s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00342, val loss: 0.00495, in 0.022s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00340, val loss: 0.00494, in 0.020s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00339, val loss: 0.00492, in 0.015s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00486, in 0.016s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00335, val loss: 0.00485, in 0.017s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00333, val loss: 0.00485, in 0.019s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00332, val loss: 0.00484, in 0.017s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00331, val loss: 0.00483, in 0.022s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00329, val loss: 0.00481, in 0.017s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00328, val loss: 0.00481, in 0.022s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00326, val loss: 0.00480, in 0.020s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00479, in 0.021s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00324, val loss: 0.00479, in 0.018s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00322, val loss: 0.00475, in 0.017s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00321, val loss: 0.00472, in 0.019s\n",
      "Fit 100 trees in 2.254 s, (3100 total leaves)\n",
      "Time spent computing histograms: 0.911s\n",
      "Time spent finding best splits:  0.366s\n",
      "Time spent applying splits:      0.478s\n",
      "Time spent predicting:           0.027s\n",
      "Binning 0.019 GB of training data: 0.545 s\n",
      "Binning 0.002 GB of validation data: 0.004 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.40615, val loss: 0.41024, in 0.163s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.33047, val loss: 0.33439, in 0.016s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.26908, val loss: 0.27267, in 0.021s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.21939, val loss: 0.22281, in 0.018s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.17901, val loss: 0.18209, in 0.018s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.14635, val loss: 0.14922, in 0.024s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.11980, val loss: 0.12231, in 0.018s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09819, val loss: 0.10048, in 0.016s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.08073, val loss: 0.08286, in 0.014s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06652, val loss: 0.06844, in 0.015s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05490, val loss: 0.05685, in 0.013s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04547, val loss: 0.04736, in 0.015s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03775, val loss: 0.03952, in 0.022s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03150, val loss: 0.03318, in 0.013s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02641, val loss: 0.02799, in 0.017s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.02221, val loss: 0.02379, in 0.013s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01885, val loss: 0.02038, in 0.016s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01609, val loss: 0.01761, in 0.018s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.01384, val loss: 0.01532, in 0.017s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01202, val loss: 0.01344, in 0.016s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01051, val loss: 0.01180, in 0.017s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00929, val loss: 0.01046, in 0.017s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00830, val loss: 0.00943, in 0.016s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00745, val loss: 0.00863, in 0.016s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.00672, val loss: 0.00787, in 0.016s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00618, val loss: 0.00730, in 0.020s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00566, val loss: 0.00686, in 0.020s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00515, val loss: 0.00632, in 0.018s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00476, val loss: 0.00593, in 0.016s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00445, val loss: 0.00562, in 0.015s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00418, val loss: 0.00536, in 0.014s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00395, val loss: 0.00512, in 0.014s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00377, val loss: 0.00499, in 0.016s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00363, val loss: 0.00488, in 0.014s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00344, val loss: 0.00472, in 0.016s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00328, val loss: 0.00460, in 0.015s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00314, val loss: 0.00448, in 0.019s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00303, val loss: 0.00436, in 0.017s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00292, val loss: 0.00425, in 0.017s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00284, val loss: 0.00418, in 0.015s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00274, val loss: 0.00410, in 0.017s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00266, val loss: 0.00402, in 0.023s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00258, val loss: 0.00396, in 0.017s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00251, val loss: 0.00389, in 0.019s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00246, val loss: 0.00384, in 0.016s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00238, val loss: 0.00375, in 0.015s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00231, val loss: 0.00370, in 0.015s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00228, val loss: 0.00366, in 0.016s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00223, val loss: 0.00361, in 0.013s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00218, val loss: 0.00356, in 0.014s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00215, val loss: 0.00352, in 0.013s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00209, val loss: 0.00345, in 0.014s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00207, val loss: 0.00343, in 0.019s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00205, val loss: 0.00339, in 0.017s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00202, val loss: 0.00338, in 0.017s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00199, val loss: 0.00334, in 0.021s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00196, val loss: 0.00332, in 0.016s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00194, val loss: 0.00331, in 0.018s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00192, val loss: 0.00330, in 0.017s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00190, val loss: 0.00329, in 0.016s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00189, val loss: 0.00329, in 0.014s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00187, val loss: 0.00328, in 0.018s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00184, val loss: 0.00326, in 0.019s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00182, val loss: 0.00324, in 0.036s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00180, val loss: 0.00323, in 0.044s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00179, val loss: 0.00322, in 0.024s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00177, val loss: 0.00321, in 0.019s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00175, val loss: 0.00321, in 0.023s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00172, val loss: 0.00317, in 0.025s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00171, val loss: 0.00317, in 0.028s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00170, val loss: 0.00317, in 0.019s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00168, val loss: 0.00315, in 0.022s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00166, val loss: 0.00314, in 0.024s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00164, val loss: 0.00313, in 0.029s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00163, val loss: 0.00312, in 0.074s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00161, val loss: 0.00311, in 0.023s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00159, val loss: 0.00310, in 0.022s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00158, val loss: 0.00309, in 0.019s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00157, val loss: 0.00309, in 0.024s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00156, val loss: 0.00309, in 0.018s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00155, val loss: 0.00308, in 0.016s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00153, val loss: 0.00306, in 0.017s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00152, val loss: 0.00306, in 0.017s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00151, val loss: 0.00305, in 0.018s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00150, val loss: 0.00305, in 0.019s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.00149, val loss: 0.00304, in 0.016s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00148, val loss: 0.00304, in 0.018s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.00147, val loss: 0.00303, in 0.015s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00146, val loss: 0.00303, in 0.018s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00144, val loss: 0.00303, in 0.021s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00144, val loss: 0.00303, in 0.017s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00143, val loss: 0.00302, in 0.016s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00142, val loss: 0.00302, in 0.017s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00141, val loss: 0.00302, in 0.013s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00140, val loss: 0.00300, in 0.017s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00139, val loss: 0.00298, in 0.017s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00138, val loss: 0.00298, in 0.057s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00137, val loss: 0.00298, in 0.016s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00137, val loss: 0.00297, in 0.016s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00136, val loss: 0.00297, in 0.015s\n",
      "Fit 100 trees in 2.650 s, (3100 total leaves)\n",
      "Time spent computing histograms: 0.873s\n",
      "Time spent finding best splits:  0.341s\n",
      "Time spent applying splits:      0.551s\n",
      "Time spent predicting:           0.019s\n",
      "Binning 0.178 GB of training data: 0.271 s\n",
      "Binning 0.020 GB of validation data: 0.029 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.42129, val loss: 0.42489, in 0.053s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.35784, val loss: 0.36082, in 0.054s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.30599, val loss: 0.30846, in 0.056s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.26391, val loss: 0.26606, in 0.056s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.22913, val loss: 0.23094, in 0.056s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.20087, val loss: 0.20235, in 0.057s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.17756, val loss: 0.17878, in 0.053s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.15839, val loss: 0.15939, in 0.067s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.14251, val loss: 0.14339, in 0.104s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.12946, val loss: 0.13024, in 0.137s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.11864, val loss: 0.11937, in 0.141s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10907, val loss: 0.10980, in 0.079s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10083, val loss: 0.10147, in 0.083s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.09378, val loss: 0.09434, in 0.306s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.08777, val loss: 0.08831, in 0.468s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.08282, val loss: 0.08342, in 0.870s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07862, val loss: 0.07925, in 0.093s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07513, val loss: 0.07572, in 0.593s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.07201, val loss: 0.07260, in 0.057s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06934, val loss: 0.06991, in 0.060s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.06684, val loss: 0.06743, in 0.050s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06489, val loss: 0.06547, in 0.043s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06298, val loss: 0.06358, in 0.075s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06149, val loss: 0.06213, in 0.043s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06012, val loss: 0.06077, in 0.056s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05877, val loss: 0.05943, in 0.061s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05766, val loss: 0.05831, in 0.073s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05665, val loss: 0.05734, in 0.065s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05559, val loss: 0.05629, in 0.057s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05471, val loss: 0.05543, in 0.062s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05380, val loss: 0.05457, in 0.059s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05316, val loss: 0.05399, in 0.053s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05246, val loss: 0.05330, in 0.056s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05183, val loss: 0.05270, in 0.061s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05114, val loss: 0.05203, in 0.068s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05073, val loss: 0.05164, in 0.057s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05028, val loss: 0.05119, in 0.055s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04989, val loss: 0.05085, in 0.049s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04932, val loss: 0.05023, in 0.052s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04882, val loss: 0.04976, in 0.069s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04845, val loss: 0.04943, in 0.055s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.04811, val loss: 0.04909, in 0.047s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04773, val loss: 0.04873, in 0.055s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04740, val loss: 0.04840, in 0.048s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04707, val loss: 0.04807, in 0.065s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04666, val loss: 0.04765, in 0.054s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04638, val loss: 0.04736, in 0.045s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04598, val loss: 0.04698, in 0.040s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04563, val loss: 0.04662, in 0.053s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04537, val loss: 0.04634, in 0.054s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04511, val loss: 0.04610, in 0.046s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04490, val loss: 0.04587, in 0.050s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.04465, val loss: 0.04562, in 0.044s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04445, val loss: 0.04541, in 0.038s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04418, val loss: 0.04514, in 0.045s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04388, val loss: 0.04482, in 0.046s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04368, val loss: 0.04464, in 0.053s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04344, val loss: 0.04439, in 0.040s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04331, val loss: 0.04425, in 0.038s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04313, val loss: 0.04409, in 0.035s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04296, val loss: 0.04395, in 0.040s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04281, val loss: 0.04378, in 0.047s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04257, val loss: 0.04355, in 0.045s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04239, val loss: 0.04337, in 0.047s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04225, val loss: 0.04325, in 0.037s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04202, val loss: 0.04301, in 0.037s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04190, val loss: 0.04289, in 0.049s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04170, val loss: 0.04269, in 0.053s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04153, val loss: 0.04253, in 0.044s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04134, val loss: 0.04235, in 0.044s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04124, val loss: 0.04221, in 0.036s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.04101, val loss: 0.04200, in 0.041s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04084, val loss: 0.04185, in 0.037s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04072, val loss: 0.04174, in 0.044s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04059, val loss: 0.04161, in 0.044s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04040, val loss: 0.04143, in 0.046s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04030, val loss: 0.04135, in 0.039s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04018, val loss: 0.04126, in 0.038s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04009, val loss: 0.04119, in 0.040s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.03998, val loss: 0.04110, in 0.071s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03985, val loss: 0.04098, in 0.039s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03971, val loss: 0.04084, in 0.040s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.03953, val loss: 0.04066, in 0.046s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.03947, val loss: 0.04062, in 0.037s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03933, val loss: 0.04050, in 0.039s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03925, val loss: 0.04043, in 0.033s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03913, val loss: 0.04031, in 0.038s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03899, val loss: 0.04018, in 0.047s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03881, val loss: 0.04002, in 0.043s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03876, val loss: 0.03999, in 0.049s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03855, val loss: 0.03975, in 0.052s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03844, val loss: 0.03963, in 0.042s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.03832, val loss: 0.03951, in 0.051s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03821, val loss: 0.03943, in 0.041s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.03813, val loss: 0.03937, in 0.043s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.03802, val loss: 0.03927, in 0.049s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.03795, val loss: 0.03919, in 0.040s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03789, val loss: 0.03914, in 0.032s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03781, val loss: 0.03908, in 0.046s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03768, val loss: 0.03895, in 0.053s\n",
      "Fit 100 trees in 7.743 s, (3100 total leaves)\n",
      "Time spent computing histograms: 3.560s\n",
      "Time spent finding best splits:  0.993s\n",
      "Time spent applying splits:      1.613s\n",
      "Time spent predicting:           0.129s\n",
      "Binning 0.178 GB of training data: 0.254 s\n",
      "Binning 0.020 GB of validation data: 0.028 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.40592, val loss: 0.40606, in 0.066s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.32970, val loss: 0.32985, in 0.047s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.26800, val loss: 0.26815, in 0.043s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.21797, val loss: 0.21812, in 0.046s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.17741, val loss: 0.17757, in 0.041s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.14460, val loss: 0.14478, in 0.046s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11791, val loss: 0.11811, in 0.048s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.09631, val loss: 0.09652, in 0.045s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.07886, val loss: 0.07908, in 0.045s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06470, val loss: 0.06496, in 0.061s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05320, val loss: 0.05346, in 0.077s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04388, val loss: 0.04416, in 0.058s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03596, val loss: 0.03623, in 0.053s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02955, val loss: 0.02980, in 0.042s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02433, val loss: 0.02456, in 0.041s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.02010, val loss: 0.02032, in 0.044s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01670, val loss: 0.01691, in 0.046s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01388, val loss: 0.01408, in 0.045s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01159, val loss: 0.01179, in 0.044s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00980, val loss: 0.00998, in 0.040s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00828, val loss: 0.00844, in 0.243s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00704, val loss: 0.00720, in 0.403s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00605, val loss: 0.00620, in 0.327s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00525, val loss: 0.00541, in 0.103s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00459, val loss: 0.00475, in 0.117s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00403, val loss: 0.00418, in 0.369s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00354, val loss: 0.00368, in 0.049s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00313, val loss: 0.00326, in 0.041s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00284, val loss: 0.00297, in 0.036s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00257, val loss: 0.00270, in 0.034s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00236, val loss: 0.00249, in 0.032s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00219, val loss: 0.00233, in 0.032s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00205, val loss: 0.00218, in 0.086s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00192, val loss: 0.00205, in 0.101s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00182, val loss: 0.00195, in 0.148s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00173, val loss: 0.00187, in 0.197s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00162, val loss: 0.00177, in 0.087s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00155, val loss: 0.00169, in 0.104s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00147, val loss: 0.00161, in 0.098s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00157, in 0.057s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00136, val loss: 0.00151, in 0.046s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00133, val loss: 0.00148, in 0.037s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00143, in 0.031s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00125, val loss: 0.00139, in 0.040s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00123, val loss: 0.00138, in 0.036s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00120, val loss: 0.00136, in 0.037s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00118, val loss: 0.00133, in 0.039s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00115, val loss: 0.00130, in 0.045s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00114, val loss: 0.00129, in 0.040s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00112, val loss: 0.00127, in 0.036s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00110, val loss: 0.00125, in 0.046s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00108, val loss: 0.00123, in 0.049s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00107, val loss: 0.00122, in 0.038s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00105, val loss: 0.00121, in 0.050s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.00103, val loss: 0.00118, in 0.053s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00101, val loss: 0.00117, in 0.046s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00101, val loss: 0.00116, in 0.075s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00100, val loss: 0.00116, in 0.079s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00098, val loss: 0.00114, in 0.044s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00097, val loss: 0.00113, in 0.041s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00095, val loss: 0.00112, in 0.033s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00094, val loss: 0.00110, in 0.033s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00093, val loss: 0.00110, in 0.035s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00092, val loss: 0.00109, in 0.035s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00091, val loss: 0.00107, in 0.055s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00089, val loss: 0.00106, in 0.026s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00088, val loss: 0.00105, in 0.033s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00088, val loss: 0.00105, in 0.032s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00087, val loss: 0.00104, in 0.036s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00087, val loss: 0.00104, in 0.031s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00086, val loss: 0.00103, in 0.038s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00085, val loss: 0.00102, in 0.042s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00084, val loss: 0.00102, in 0.032s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00083, val loss: 0.00101, in 0.033s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00082, val loss: 0.00101, in 0.039s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00081, val loss: 0.00100, in 0.034s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00081, val loss: 0.00100, in 0.028s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00079, val loss: 0.00097, in 0.031s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00078, val loss: 0.00097, in 0.032s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00078, val loss: 0.00097, in 0.033s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00077, val loss: 0.00097, in 0.047s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00077, val loss: 0.00097, in 0.052s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00077, val loss: 0.00096, in 0.034s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00076, val loss: 0.00096, in 0.039s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00076, val loss: 0.00096, in 0.035s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00075, val loss: 0.00095, in 0.034s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00075, val loss: 0.00094, in 0.043s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00074, val loss: 0.00094, in 0.039s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00074, val loss: 0.00094, in 0.034s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00072, val loss: 0.00093, in 0.033s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00072, val loss: 0.00093, in 0.038s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00072, val loss: 0.00092, in 0.027s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00071, val loss: 0.00092, in 0.035s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00071, val loss: 0.00092, in 0.033s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00070, val loss: 0.00091, in 0.034s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00069, val loss: 0.00089, in 0.034s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00068, val loss: 0.00089, in 0.035s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00068, val loss: 0.00089, in 0.034s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00068, val loss: 0.00089, in 0.056s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00068, val loss: 0.00089, in 0.049s\n",
      "Fit 100 trees in 6.430 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.894s\n",
      "Time spent finding best splits:  0.863s\n",
      "Time spent applying splits:      1.284s\n",
      "Time spent predicting:           0.097s\n",
      "Binning 0.178 GB of training data: 1.866 s\n",
      "Binning 0.020 GB of validation data: 0.042 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.40999, val loss: 0.41211, in 0.054s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.33741, val loss: 0.33960, in 0.063s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.27826, val loss: 0.28047, in 0.066s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.23011, val loss: 0.23193, in 0.049s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.19081, val loss: 0.19254, in 0.046s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15903, val loss: 0.16079, in 0.046s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.13295, val loss: 0.13447, in 0.045s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11194, val loss: 0.11354, in 0.054s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.09477, val loss: 0.09628, in 0.046s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.08082, val loss: 0.08237, in 0.052s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06893, val loss: 0.07027, in 0.049s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05927, val loss: 0.06057, in 0.042s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05147, val loss: 0.05282, in 0.048s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04500, val loss: 0.04623, in 0.133s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03976, val loss: 0.04078, in 0.130s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03514, val loss: 0.03604, in 0.084s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03134, val loss: 0.03212, in 0.043s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02818, val loss: 0.02887, in 0.049s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02550, val loss: 0.02619, in 0.081s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.02325, val loss: 0.02386, in 0.087s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02147, val loss: 0.02208, in 0.046s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.02006, val loss: 0.02067, in 0.044s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01877, val loss: 0.01930, in 0.043s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01775, val loss: 0.01820, in 0.041s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01693, val loss: 0.01739, in 0.067s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01618, val loss: 0.01657, in 0.067s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01555, val loss: 0.01593, in 0.078s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01500, val loss: 0.01537, in 0.039s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01458, val loss: 0.01494, in 0.040s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01420, val loss: 0.01457, in 0.042s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01386, val loss: 0.01423, in 0.037s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01355, val loss: 0.01390, in 0.036s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01330, val loss: 0.01362, in 0.041s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01309, val loss: 0.01341, in 0.038s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01285, val loss: 0.01319, in 0.035s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01264, val loss: 0.01297, in 0.039s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01232, val loss: 0.01261, in 0.040s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01208, val loss: 0.01236, in 0.044s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01192, val loss: 0.01220, in 0.039s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01180, val loss: 0.01207, in 0.055s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01164, val loss: 0.01194, in 0.109s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01147, val loss: 0.01176, in 0.086s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01129, val loss: 0.01155, in 0.043s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01115, val loss: 0.01143, in 0.037s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01104, val loss: 0.01131, in 0.062s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01096, val loss: 0.01122, in 0.035s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01084, val loss: 0.01109, in 1.392s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01073, val loss: 0.01099, in 0.114s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.01063, val loss: 0.01089, in 0.840s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01056, val loss: 0.01083, in 0.084s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01046, val loss: 0.01072, in 0.071s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01037, val loss: 0.01062, in 0.062s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01028, val loss: 0.01053, in 0.041s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.01022, val loss: 0.01048, in 0.085s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01015, val loss: 0.01041, in 0.208s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.01009, val loss: 0.01036, in 0.137s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.01002, val loss: 0.01028, in 0.038s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00997, val loss: 0.01024, in 0.046s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00989, val loss: 0.01017, in 0.048s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00985, val loss: 0.01013, in 0.048s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00978, val loss: 0.01007, in 0.048s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00974, val loss: 0.01002, in 0.046s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00967, val loss: 0.00994, in 0.055s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00962, val loss: 0.00988, in 0.051s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00957, val loss: 0.00984, in 0.045s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00951, val loss: 0.00978, in 0.066s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00944, val loss: 0.00969, in 0.036s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00939, val loss: 0.00964, in 0.060s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00933, val loss: 0.00958, in 0.089s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00929, val loss: 0.00954, in 0.039s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00924, val loss: 0.00949, in 0.037s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00920, val loss: 0.00944, in 0.045s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00918, val loss: 0.00942, in 0.045s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00914, val loss: 0.00939, in 0.038s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00912, val loss: 0.00935, in 0.041s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00908, val loss: 0.00932, in 0.038s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00906, val loss: 0.00931, in 0.043s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00904, val loss: 0.00929, in 0.041s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00900, val loss: 0.00925, in 0.045s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00896, val loss: 0.00922, in 0.046s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00891, val loss: 0.00917, in 0.042s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00889, val loss: 0.00915, in 0.044s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00887, val loss: 0.00912, in 0.040s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00883, val loss: 0.00908, in 0.043s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00882, val loss: 0.00907, in 0.033s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00878, val loss: 0.00904, in 0.041s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00877, val loss: 0.00902, in 0.041s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00873, val loss: 0.00899, in 0.044s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00870, val loss: 0.00896, in 0.038s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00869, val loss: 0.00894, in 0.041s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00866, val loss: 0.00892, in 0.039s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00862, val loss: 0.00889, in 0.038s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00860, val loss: 0.00887, in 0.059s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00855, val loss: 0.00881, in 0.049s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00852, val loss: 0.00878, in 0.041s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00848, val loss: 0.00875, in 0.041s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00847, val loss: 0.00873, in 0.044s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00843, val loss: 0.00869, in 0.044s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00840, val loss: 0.00866, in 0.044s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00834, val loss: 0.00861, in 0.050s\n",
      "Fit 100 trees in 9.747 s, (3100 total leaves)\n",
      "Time spent computing histograms: 3.863s\n",
      "Time spent finding best splits:  0.916s\n",
      "Time spent applying splits:      1.687s\n",
      "Time spent predicting:           0.132s\n",
      "Binning 0.178 GB of training data: 0.279 s\n",
      "Binning 0.020 GB of validation data: 0.031 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 6, train loss: 0.42185, val loss: 0.42230, in 0.057s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.35856, val loss: 0.35900, in 0.058s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.30660, val loss: 0.30709, in 0.073s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.26446, val loss: 0.26499, in 0.053s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.22961, val loss: 0.23011, in 0.050s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.20093, val loss: 0.20157, in 0.044s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.17733, val loss: 0.17801, in 0.051s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15791, val loss: 0.15864, in 0.046s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.14227, val loss: 0.14302, in 0.046s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.12906, val loss: 0.12984, in 0.058s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.11800, val loss: 0.11878, in 0.062s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.10896, val loss: 0.10974, in 0.056s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.10170, val loss: 0.10252, in 0.075s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.09517, val loss: 0.09600, in 0.059s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08987, val loss: 0.09068, in 0.057s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08560, val loss: 0.08646, in 0.052s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.08190, val loss: 0.08280, in 0.055s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 6, train loss: 0.07906, val loss: 0.07997, in 0.055s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.07607, val loss: 0.07701, in 0.055s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.07362, val loss: 0.07458, in 0.060s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.07149, val loss: 0.07247, in 0.069s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06974, val loss: 0.07075, in 0.068s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06830, val loss: 0.06930, in 0.056s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06701, val loss: 0.06803, in 0.059s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06593, val loss: 0.06697, in 0.054s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06491, val loss: 0.06597, in 0.061s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.06405, val loss: 0.06514, in 0.057s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06329, val loss: 0.06439, in 0.068s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.06264, val loss: 0.06374, in 0.067s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06203, val loss: 0.06316, in 0.057s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06152, val loss: 0.06265, in 0.048s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06104, val loss: 0.06219, in 0.053s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06063, val loss: 0.06178, in 0.095s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.06025, val loss: 0.06139, in 0.083s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05986, val loss: 0.06096, in 0.049s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.05943, val loss: 0.06056, in 0.041s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05914, val loss: 0.06027, in 0.042s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05880, val loss: 0.05995, in 0.051s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05846, val loss: 0.05963, in 0.056s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05815, val loss: 0.05932, in 0.041s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05789, val loss: 0.05908, in 0.046s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05763, val loss: 0.05882, in 0.043s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05739, val loss: 0.05858, in 0.044s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05702, val loss: 0.05819, in 0.038s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.05675, val loss: 0.05793, in 0.045s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05636, val loss: 0.05753, in 0.047s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05614, val loss: 0.05731, in 0.043s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05592, val loss: 0.05710, in 0.050s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05561, val loss: 0.05679, in 0.053s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05537, val loss: 0.05655, in 0.142s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05521, val loss: 0.05639, in 0.907s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05500, val loss: 0.05619, in 0.539s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05480, val loss: 0.05600, in 0.262s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05464, val loss: 0.05584, in 0.035s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05446, val loss: 0.05564, in 0.036s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05426, val loss: 0.05545, in 0.042s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05414, val loss: 0.05533, in 0.037s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05397, val loss: 0.05516, in 0.045s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05387, val loss: 0.05506, in 0.057s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05367, val loss: 0.05489, in 0.037s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05350, val loss: 0.05473, in 0.046s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05329, val loss: 0.05452, in 0.048s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.05320, val loss: 0.05444, in 0.045s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05310, val loss: 0.05434, in 0.050s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05294, val loss: 0.05416, in 0.029s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05283, val loss: 0.05405, in 0.033s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05257, val loss: 0.05383, in 0.038s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05247, val loss: 0.05374, in 0.047s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05234, val loss: 0.05360, in 0.031s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05222, val loss: 0.05349, in 0.068s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05214, val loss: 0.05341, in 0.034s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05205, val loss: 0.05332, in 0.037s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05196, val loss: 0.05324, in 0.055s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05179, val loss: 0.05308, in 0.039s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05165, val loss: 0.05296, in 0.042s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05158, val loss: 0.05291, in 0.033s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05146, val loss: 0.05280, in 0.034s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05129, val loss: 0.05263, in 0.032s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05121, val loss: 0.05256, in 0.029s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05109, val loss: 0.05246, in 0.035s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05102, val loss: 0.05240, in 0.042s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05090, val loss: 0.05229, in 0.089s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.05075, val loss: 0.05214, in 0.053s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05069, val loss: 0.05210, in 0.035s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05064, val loss: 0.05205, in 0.048s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.05050, val loss: 0.05191, in 0.041s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.05041, val loss: 0.05183, in 0.040s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.05034, val loss: 0.05176, in 0.034s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.05022, val loss: 0.05164, in 0.046s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.05014, val loss: 0.05156, in 0.043s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.05007, val loss: 0.05149, in 0.036s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04993, val loss: 0.05134, in 0.043s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.04984, val loss: 0.05126, in 0.056s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04980, val loss: 0.05123, in 0.045s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04972, val loss: 0.05117, in 0.057s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04967, val loss: 0.05112, in 0.041s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.04959, val loss: 0.05105, in 0.040s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04944, val loss: 0.05092, in 0.048s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.04933, val loss: 0.05082, in 0.040s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.04917, val loss: 0.05068, in 0.039s\n",
      "Fit 100 trees in 7.007 s, (3100 total leaves)\n",
      "Time spent computing histograms: 3.298s\n",
      "Time spent finding best splits:  0.944s\n",
      "Time spent applying splits:      1.435s\n",
      "Time spent predicting:           0.101s\n",
      "Binning 0.178 GB of training data: 0.267 s\n",
      "Binning 0.020 GB of validation data: 0.029 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.40509, val loss: 0.40497, in 0.061s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.32820, val loss: 0.32808, in 0.040s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.26592, val loss: 0.26581, in 0.066s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.21547, val loss: 0.21536, in 0.037s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.17461, val loss: 0.17449, in 0.043s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14151, val loss: 0.14139, in 0.038s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11470, val loss: 0.11458, in 0.053s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.09298, val loss: 0.09286, in 0.036s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.07539, val loss: 0.07527, in 0.038s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.06114, val loss: 0.06102, in 0.036s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.04960, val loss: 0.04948, in 0.039s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.04025, val loss: 0.04012, in 0.038s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.03267, val loss: 0.03255, in 0.039s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.02654, val loss: 0.02641, in 0.041s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.02157, val loss: 0.02144, in 0.045s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.01754, val loss: 0.01741, in 0.038s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01428, val loss: 0.01415, in 0.046s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.01164, val loss: 0.01151, in 0.037s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00950, val loss: 0.00936, in 0.047s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00776, val loss: 0.00763, in 0.059s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00636, val loss: 0.00622, in 0.030s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00522, val loss: 0.00508, in 0.032s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00430, val loss: 0.00416, in 0.036s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00355, val loss: 0.00341, in 0.035s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00295, val loss: 0.00281, in 0.036s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00246, val loss: 0.00231, in 0.039s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00206, val loss: 0.00192, in 0.047s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00174, val loss: 0.00159, in 0.091s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00148, val loss: 0.00133, in 0.030s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00127, val loss: 0.00112, in 0.032s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00109, val loss: 0.00095, in 0.034s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00096, val loss: 0.00081, in 0.032s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00084, val loss: 0.00070, in 0.031s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00075, val loss: 0.00061, in 0.040s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00068, val loss: 0.00053, in 0.031s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00062, val loss: 0.00047, in 0.031s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00057, val loss: 0.00042, in 0.029s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00053, val loss: 0.00038, in 0.031s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00050, val loss: 0.00035, in 0.042s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00047, val loss: 0.00033, in 0.037s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00045, val loss: 0.00031, in 0.041s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00043, val loss: 0.00029, in 0.038s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00042, val loss: 0.00027, in 0.058s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00041, val loss: 0.00026, in 0.041s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00040, val loss: 0.00025, in 0.775s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.00039, val loss: 0.00025, in 0.188s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00039, val loss: 0.00024, in 0.082s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00038, val loss: 0.00024, in 0.036s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00038, val loss: 0.00023, in 0.031s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.00037, val loss: 0.00023, in 0.036s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00037, val loss: 0.00023, in 0.040s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.00037, val loss: 0.00022, in 0.043s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00037, val loss: 0.00022, in 0.035s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00037, val loss: 0.00022, in 0.037s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00036, val loss: 0.00022, in 0.038s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00022, in 0.028s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00022, in 0.067s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00036, val loss: 0.00022, in 0.146s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00022, in 0.060s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00022, in 0.055s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00036, val loss: 0.00022, in 0.040s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.00036, val loss: 0.00021, in 0.041s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.034s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.034s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00036, val loss: 0.00021, in 0.040s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00036, val loss: 0.00021, in 0.043s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.046s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.00036, val loss: 0.00021, in 0.042s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.00036, val loss: 0.00021, in 0.035s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00021, in 0.040s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.043s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00036, val loss: 0.00021, in 0.036s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.034s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00036, val loss: 0.00021, in 0.047s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.00036, val loss: 0.00021, in 0.050s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.042s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00036, val loss: 0.00021, in 0.038s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.00036, val loss: 0.00021, in 0.116s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00036, val loss: 0.00021, in 0.081s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00021, in 0.070s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00021, in 0.040s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.033s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00036, val loss: 0.00021, in 0.032s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.00036, val loss: 0.00021, in 0.033s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.032s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00021, in 0.032s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00021, in 0.054s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00021, in 0.047s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.104s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.00036, val loss: 0.00021, in 0.037s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00021, in 0.034s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.033s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.033s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00021, in 0.032s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.033s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00021, in 0.048s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.00036, val loss: 0.00021, in 0.038s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.00036, val loss: 0.00021, in 0.031s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.068s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.00036, val loss: 0.00021, in 0.030s\n",
      "Fit 100 trees in 5.770 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.488s\n",
      "Time spent finding best splits:  0.613s\n",
      "Time spent applying splits:      1.294s\n",
      "Time spent predicting:           0.076s\n",
      "Binning 0.092 GB of training data: 0.182 s\n",
      "Binning 0.010 GB of validation data: 0.014 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.45221, val loss: 0.43413, in 0.026s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.40963, val loss: 0.39282, in 0.024s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.37449, val loss: 0.35841, in 0.025s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.34440, val loss: 0.33013, in 0.031s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.32046, val loss: 0.30645, in 0.036s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.30064, val loss: 0.28768, in 0.030s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.28317, val loss: 0.27328, in 0.026s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.26838, val loss: 0.25856, in 0.026s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.25634, val loss: 0.24827, in 0.024s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.24640, val loss: 0.23916, in 0.025s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.23788, val loss: 0.23069, in 0.022s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.22798, val loss: 0.22312, in 0.025s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.21821, val loss: 0.21720, in 0.023s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.21112, val loss: 0.21101, in 0.023s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.20311, val loss: 0.20283, in 0.023s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.19646, val loss: 0.19584, in 0.026s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.19236, val loss: 0.19170, in 0.031s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18428, val loss: 0.18465, in 0.035s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18039, val loss: 0.18140, in 0.030s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.17782, val loss: 0.17926, in 0.025s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.17587, val loss: 0.17775, in 0.023s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.17220, val loss: 0.17484, in 0.026s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.16905, val loss: 0.17218, in 0.028s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.16648, val loss: 0.16970, in 0.027s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.16476, val loss: 0.16784, in 0.020s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.16273, val loss: 0.16610, in 0.025s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.16130, val loss: 0.16459, in 0.022s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15799, val loss: 0.16190, in 0.023s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.15667, val loss: 0.16054, in 0.022s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.15463, val loss: 0.15895, in 0.023s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15314, val loss: 0.15834, in 0.024s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15066, val loss: 0.15632, in 0.026s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14946, val loss: 0.15600, in 0.025s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14850, val loss: 0.15560, in 0.022s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14554, val loss: 0.15386, in 0.025s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14472, val loss: 0.15347, in 0.020s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14380, val loss: 0.15244, in 0.026s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14242, val loss: 0.15133, in 0.025s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13992, val loss: 0.15008, in 0.023s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13909, val loss: 0.14987, in 0.021s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13841, val loss: 0.14919, in 0.030s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13740, val loss: 0.14895, in 0.033s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13591, val loss: 0.14804, in 0.037s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13507, val loss: 0.14782, in 0.030s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13368, val loss: 0.14671, in 0.042s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13323, val loss: 0.14676, in 0.027s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13162, val loss: 0.14559, in 0.030s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13094, val loss: 0.14477, in 0.027s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13026, val loss: 0.14451, in 0.030s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12910, val loss: 0.14367, in 0.030s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12805, val loss: 0.14307, in 0.032s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12671, val loss: 0.14231, in 0.034s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.12607, val loss: 0.14193, in 0.034s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12547, val loss: 0.14145, in 0.038s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12497, val loss: 0.14134, in 0.030s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12422, val loss: 0.13985, in 0.029s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12308, val loss: 0.13930, in 0.027s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12277, val loss: 0.13928, in 0.027s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12233, val loss: 0.13916, in 0.031s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12166, val loss: 0.13804, in 0.029s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 18, train loss: 0.12109, val loss: 0.13756, in 0.031s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.12018, val loss: 0.13704, in 0.027s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11987, val loss: 0.13708, in 0.033s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11951, val loss: 0.13699, in 0.048s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.11876, val loss: 0.13647, in 0.147s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11856, val loss: 0.13653, in 0.226s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11836, val loss: 0.13658, in 0.664s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11801, val loss: 0.13632, in 0.980s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11743, val loss: 0.13595, in 0.067s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11718, val loss: 0.13597, in 0.044s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11693, val loss: 0.13585, in 0.724s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11583, val loss: 0.13523, in 0.096s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11545, val loss: 0.13486, in 0.099s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.11483, val loss: 0.13439, in 0.041s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11463, val loss: 0.13440, in 0.037s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11417, val loss: 0.13434, in 0.043s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11381, val loss: 0.13423, in 0.034s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11364, val loss: 0.13411, in 0.028s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11336, val loss: 0.13409, in 0.037s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11288, val loss: 0.13389, in 0.035s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11242, val loss: 0.13356, in 0.065s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.11225, val loss: 0.13361, in 0.041s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11172, val loss: 0.13277, in 0.020s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11112, val loss: 0.13249, in 0.024s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11098, val loss: 0.13240, in 0.025s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11054, val loss: 0.13169, in 0.020s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11023, val loss: 0.13155, in 0.040s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10973, val loss: 0.13120, in 0.023s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10958, val loss: 0.13098, in 0.022s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10948, val loss: 0.13103, in 0.035s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10901, val loss: 0.13094, in 0.026s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.10868, val loss: 0.13071, in 0.021s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10803, val loss: 0.13071, in 0.027s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10765, val loss: 0.13037, in 0.033s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.10730, val loss: 0.12991, in 0.025s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.10708, val loss: 0.12975, in 0.028s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.10667, val loss: 0.12969, in 0.032s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.10630, val loss: 0.12938, in 0.031s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.10609, val loss: 0.12932, in 0.030s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.10577, val loss: 0.12927, in 0.049s\n",
      "Fit 100 trees in 6.057 s, (3100 total leaves)\n",
      "Time spent computing histograms: 2.383s\n",
      "Time spent finding best splits:  0.776s\n",
      "Time spent applying splits:      1.346s\n",
      "Time spent predicting:           0.094s\n",
      "Binning 0.089 GB of training data: 0.207 s\n",
      "Binning 0.010 GB of validation data: 0.041 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.41256, val loss: 0.40960, in 0.047s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.34127, val loss: 0.33870, in 0.073s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.28339, val loss: 0.28120, in 0.053s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.23626, val loss: 0.23431, in 0.041s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.19781, val loss: 0.19613, in 0.041s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.16640, val loss: 0.16485, in 0.046s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14094, val loss: 0.13957, in 0.235s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.12004, val loss: 0.11882, in 0.063s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.10282, val loss: 0.10169, in 0.059s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.08879, val loss: 0.08775, in 0.055s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.07710, val loss: 0.07616, in 0.072s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.06752, val loss: 0.06664, in 0.037s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05954, val loss: 0.05874, in 0.034s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.05308, val loss: 0.05232, in 0.033s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.04766, val loss: 0.04694, in 0.057s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.04319, val loss: 0.04251, in 0.188s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.03945, val loss: 0.03881, in 0.771s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.03640, val loss: 0.03578, in 0.810s\n",
      "[19/100] "
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "ct0 = ColumnTransformer(\n",
    "        [('target_encoder', TargetEncoder(handle_unknown='ignore'), ['spn_fmi',\n",
    "                                                                        'ecuSource',\n",
    "                                                                        'LampStatus',\n",
    "                                                                        'activeTransitionCount'\n",
    "                                                                    ]\n",
    "          )],\n",
    "        remainder='passthrough')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "xgbc_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor0', ct0),\n",
    "        ('StandardScaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(estimator = HistGradientBoostingRegressor(verbose=2, random_state=434), max_iter=100, random_state=343)),\n",
    "        ('smote', SMOTE(random_state=344)),\n",
    "        ('xgbc', XGBClassifier(# tree_method = \"hist\",                                \n",
    "                               enable_categorical=True, \n",
    "                                eval_metric='mlogloss',\n",
    "                                objective = 'multi:softmax',\n",
    "                                num_class = 5,\n",
    "                                device = \"cuda\",\n",
    "                                random_state = 535                         \n",
    "                            )\n",
    "        )\n",
    "    ]\n",
    ").fit(X_train, y_train) \n",
    "\n",
    "y_pred = xgbc_pipe.predict(X_test)  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865cd97a",
   "metadata": {},
   "source": [
    "~ For Ref / Backup purposes ~\n",
    "\n",
    "\n",
    "ct1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), [  'AcceleratorPedal',\n",
    "                                        'BarometricPressure',\n",
    "                                        'CruiseControlSetSpeed',\n",
    "                                        'DistanceLtd',\n",
    "                                        'EngineCoolantTemperature',\n",
    "                                        'EngineLoad',\n",
    "                                        'EngineOilPressure',\n",
    "                                        'EngineOilTemperature',\n",
    "                                        'EngineRpm',\n",
    "                                        'EngineTimeLtd',\n",
    "                                        'FuelLevel',\n",
    "                                        'FuelLtd',\n",
    "                                        'FuelRate',\n",
    "                                        'FuelTemperature',\n",
    "                                        'IntakeManifoldTemperature',\n",
    "                                        'Speed',\n",
    "                                        'Throttle',\n",
    "                                        'active',\n",
    "                                        'TurboBoostPressure',\n",
    "                                        'CruiseControlActive',\n",
    "                                        'IgnStatus',\n",
    "                                        'ParkingBrake',\n",
    "                                        'SwitchedBatteryVoltage'\n",
    "                                        ]),\n",
    "\n",
    "         ('num_imputer', IterativeImputer(estimator=ExtraTreesRegressor(), max_iter=10, random_state=343), [ \n",
    "                                        'AcceleratorPedal',\n",
    "                                        'BarometricPressure',\n",
    "                                        'CruiseControlSetSpeed',\n",
    "                                        'DistanceLtd',\n",
    "                                        'EngineCoolantTemperature',\n",
    "                                        'EngineLoad',\n",
    "                                        'EngineOilPressure',\n",
    "                                        'EngineOilTemperature',\n",
    "                                        'EngineRpm',\n",
    "                                        'EngineTimeLtd',\n",
    "                                        'FuelLevel',\n",
    "                                        'FuelLtd',\n",
    "                                        'FuelRate',\n",
    "                                        'FuelTemperature',\n",
    "                                        'IntakeManifoldTemperature',\n",
    "                                        'Speed',\n",
    "                                        'Throttle',\n",
    "                                        'active',\n",
    "                                        'TurboBoostPressure',\n",
    "                                        'CruiseControlActive',\n",
    "                                        'IgnStatus',\n",
    "                                        'ParkingBrake',\n",
    "                                        'SwitchedBatteryVoltage',\n",
    "                                        'spn_fmi',\n",
    "                                        'ecuSource',\n",
    "                                        'LampStatus',\n",
    "                                        'activeTransitionCount'\n",
    "                                        ]) \n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0913a0",
   "metadata": {},
   "source": [
    "~ For Ref / Backup purposes ~\n",
    "\n",
    "\n",
    "xgbc_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor0', ct0),\n",
    "        ('StandardScaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(estimator=ExtraTreesRegressor(), max_iter=10, random_state=343)),\n",
    "        ('smote', SMOTE(random_state=3434)),\n",
    "        ('xgbc', XGBClassifier( enable_categorical=True, \n",
    "                               # max_cat_to_onehot=1,\n",
    "                                booster='gbtree', \n",
    "                                eval_metric='mlogloss',\n",
    "                                objective = 'multi:softprob'\n",
    "                            )\n",
    "        )\n",
    "    ]\n",
    ").fit(X_train, y_train) \n",
    "\n",
    "y_pred = xgbc_pipe.predict(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f8da37",
   "metadata": {},
   "source": [
    "~ For Ref / Backup purposes ~\n",
    "\n",
    "Other imputer methodologies to try: XGBImputer(), GradientBoostingRegressor(), ExtraTreesRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69576d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b487eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0162133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.517894736842105\n",
      "RMSE: 1.87560516549782\n",
      "MAE: 0.92\n",
      "MAPE: 1469595667878793.5\n",
      "R2: -0.20023997994874532\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'RMSE: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'MAPE: {mean_absolute_percentage_error(y_test, y_pred)}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeed7bc",
   "metadata": {},
   "source": [
    "xgb = XGBClassifier(\n",
    "                    eval_metric='mlogloss'\n",
    "                    \n",
    "                    ).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f379a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae8d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a5e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4], shape=(949528,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651cef33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               0\n",
       "1               0\n",
       "2               0\n",
       "3               0\n",
       "4               0\n",
       "           ...   \n",
       "949523    9999999\n",
       "949524    9999999\n",
       "949525    9999999\n",
       "949526    9999999\n",
       "949527    9999999\n",
       "Name: time_interval_to_SPN5246_class, Length: 949528, dtype: category\n",
       "Categories (5, int64): [0, 1, 2, 3, 9999999]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e81ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d014285d",
   "metadata": {},
   "source": [
    "\n",
    "#RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': range(1, 10, 1),\n",
    "    'min_child_weight':range(1, 6, 1),\n",
    "    'learning_rate': stats.uniform(0.01, 0.1),\n",
    "    'subsample':[i/10.0 for i in range(1, 10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(1, 10)],\n",
    "    'n_estimators':stats.randint(1, 70),\n",
    "    'gamma':[i/10.0 for i in range(0, 5)],\n",
    "   # 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "    'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# xgb_model = XGBClassifier()\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, shuffle=True, random_state=343)\n",
    "random_search = RandomizedSearchCV(xgbc_pipe[1], param_distributions=param_dist, n_iter=20, cv=cv, scoring='precision_macro', verbose=2, n_jobs=-1, random_state=321)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676e4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ad609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7431578947368421"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c162d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133,  22,   2,   0,  71],\n",
       "       [  0,   2,   1,   0,   1],\n",
       "       [  0,   1,   0,   0,   0],\n",
       "       [  0,   0,   0,   1,   0],\n",
       "       [123,  21,   2,   0, 570]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.58      0.55       228\n",
      "           1       0.04      0.50      0.08         4\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       0.89      0.80      0.84       716\n",
      "\n",
      "    accuracy                           0.74       950\n",
      "   macro avg       0.49      0.58      0.49       950\n",
      "weighted avg       0.80      0.74      0.77       950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d8de46",
   "metadata": {},
   "source": [
    "cv = LeaveOneOut()\n",
    "scores = cross_val_score(xgbc_pipe, X_test, y_test, cv=10, scoring='recall_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2774a41c",
   "metadata": {},
   "source": [
    "print('Cross Validation Macro Precision Scores:', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c28ee6",
   "metadata": {},
   "source": [
    "### Top Features' Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19c82e",
   "metadata": {},
   "source": [
    "selection = SelectFromModel(xgbc_pipe[1], threshold=0.0001, prefit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cdffa6",
   "metadata": {},
   "source": [
    "X_selected = selection.transform(X_train)\n",
    "X_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc496a70",
   "metadata": {},
   "source": [
    "plot_importance_object = plot_importance(xgbc_pipe[1], importance_type='gain')\n",
    "plt.title('Feature Importance for Full Derate Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d08f9",
   "metadata": {},
   "source": [
    "feature_importances = xgbc_pipe[1].feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_27_features = feature_importance_df.head(27)\n",
    "\n",
    "print(top_27_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459a5906",
   "metadata": {},
   "source": [
    "print(\"Top 27 features:\", top_27_features['Feature'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d4f45",
   "metadata": {},
   "source": [
    "### Import fresh test data (previously held out) for a fresh round of testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/In2019_df_Cat9999999.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99af91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RecordID</th>\n",
       "      <th>ESS_Id</th>\n",
       "      <th>EventTimeStamp</th>\n",
       "      <th>eventDescription</th>\n",
       "      <th>actionDescription</th>\n",
       "      <th>ecuSoftwareVersion</th>\n",
       "      <th>ecuSerialNumber</th>\n",
       "      <th>ecuModel</th>\n",
       "      <th>...</th>\n",
       "      <th>Speed</th>\n",
       "      <th>SwitchedBatteryVoltage</th>\n",
       "      <th>Throttle</th>\n",
       "      <th>TurboBoostPressure</th>\n",
       "      <th>spn_fmi</th>\n",
       "      <th>is_fullderate</th>\n",
       "      <th>is_fullderate_group</th>\n",
       "      <th>EquipID_Index</th>\n",
       "      <th>time_to_next_SPN5246</th>\n",
       "      <th>time_interval_to_SPN5246_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>952775</td>\n",
       "      <td>1062090</td>\n",
       "      <td>1104925</td>\n",
       "      <td>73930906</td>\n",
       "      <td>2019-01-11 12:51:18</td>\n",
       "      <td>High Voltage (Fuel Level)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>46.52031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.4</td>\n",
       "      <td>13.05</td>\n",
       "      <td>96.0_3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>301_1</td>\n",
       "      <td>239999976.0</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>952776</td>\n",
       "      <td>1062091</td>\n",
       "      <td>1104926</td>\n",
       "      <td>73930907</td>\n",
       "      <td>2019-01-11 12:51:18</td>\n",
       "      <td>High Voltage (Left Fuel Level Sensor)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>46.52031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.4</td>\n",
       "      <td>13.05</td>\n",
       "      <td>829.0_3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>301_1</td>\n",
       "      <td>239999976.0</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>952781</td>\n",
       "      <td>1062096</td>\n",
       "      <td>1104931</td>\n",
       "      <td>73934247</td>\n",
       "      <td>2019-01-11 13:11:40</td>\n",
       "      <td>High Voltage (Fuel Level)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0_3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>301_1</td>\n",
       "      <td>239999976.0</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>952782</td>\n",
       "      <td>1062097</td>\n",
       "      <td>1104932</td>\n",
       "      <td>73934248</td>\n",
       "      <td>2019-01-11 13:11:40</td>\n",
       "      <td>High Voltage (Left Fuel Level Sensor)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>829.0_3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>301_1</td>\n",
       "      <td>239999976.0</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>952809</td>\n",
       "      <td>1062135</td>\n",
       "      <td>1104970</td>\n",
       "      <td>73942005</td>\n",
       "      <td>2019-01-11 13:13:38</td>\n",
       "      <td>High Voltage (Fuel Level)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>96.0_3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>301_1</td>\n",
       "      <td>239999976.0</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112014</th>\n",
       "      <td>977126</td>\n",
       "      <td>1089938</td>\n",
       "      <td>1137548</td>\n",
       "      <td>80503703</td>\n",
       "      <td>2019-03-16 11:22:32</td>\n",
       "      <td>Incorrect Data J1939 Network #1 Primary Vehicl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAAI000051*AAAM010056*Z091290   *A82J170202A_b...</td>\n",
       "      <td>6232171647</td>\n",
       "      <td>EC80ESP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639.0_2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105437340_0</td>\n",
       "      <td>239999976.0</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112015</th>\n",
       "      <td>977150</td>\n",
       "      <td>1089962</td>\n",
       "      <td>1137572</td>\n",
       "      <td>80509396</td>\n",
       "      <td>2019-03-16 11:24:04</td>\n",
       "      <td>Special Instructions Engine Starter Solenoid L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5569997 *E250.e003*</td>\n",
       "      <td>K1243673</td>\n",
       "      <td>FAOM-xx810S-EC3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1321.0_14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105437340_0</td>\n",
       "      <td>239999976.0</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112016</th>\n",
       "      <td>977151</td>\n",
       "      <td>1089963</td>\n",
       "      <td>1137573</td>\n",
       "      <td>80509397</td>\n",
       "      <td>2019-03-16 11:27:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5569997 *E250.e003*</td>\n",
       "      <td>K1243673</td>\n",
       "      <td>FAOM-xx810S-EC3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>520321.0_13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105437340_0</td>\n",
       "      <td>239999976.0</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112017</th>\n",
       "      <td>978491</td>\n",
       "      <td>1091502</td>\n",
       "      <td>1139112</td>\n",
       "      <td>80907838</td>\n",
       "      <td>2019-03-20 10:57:34</td>\n",
       "      <td>Special Instructions Engine Starter Solenoid L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K1243673</td>\n",
       "      <td>FAOM-xx810S-EC3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1321.0_14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105437340_0</td>\n",
       "      <td>239999976.0</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112018</th>\n",
       "      <td>978891</td>\n",
       "      <td>1091973</td>\n",
       "      <td>1139583</td>\n",
       "      <td>81025027</td>\n",
       "      <td>2019-03-21 10:05:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5569997 *E250.e003*</td>\n",
       "      <td>K1243673</td>\n",
       "      <td>FAOM-xx810S-EC3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>520321.0_13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105437340_0</td>\n",
       "      <td>239999976.0</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112019 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.1  Unnamed: 0  RecordID    ESS_Id       EventTimeStamp  \\\n",
       "0             952775     1062090   1104925  73930906  2019-01-11 12:51:18   \n",
       "1             952776     1062091   1104926  73930907  2019-01-11 12:51:18   \n",
       "2             952781     1062096   1104931  73934247  2019-01-11 13:11:40   \n",
       "3             952782     1062097   1104932  73934248  2019-01-11 13:11:40   \n",
       "4             952809     1062135   1104970  73942005  2019-01-11 13:13:38   \n",
       "...              ...         ...       ...       ...                  ...   \n",
       "112014        977126     1089938   1137548  80503703  2019-03-16 11:22:32   \n",
       "112015        977150     1089962   1137572  80509396  2019-03-16 11:24:04   \n",
       "112016        977151     1089963   1137573  80509397  2019-03-16 11:27:41   \n",
       "112017        978491     1091502   1139112  80907838  2019-03-20 10:57:34   \n",
       "112018        978891     1091973   1139583  81025027  2019-03-21 10:05:14   \n",
       "\n",
       "                                         eventDescription  actionDescription  \\\n",
       "0                               High Voltage (Fuel Level)                NaN   \n",
       "1                   High Voltage (Left Fuel Level Sensor)                NaN   \n",
       "2                               High Voltage (Fuel Level)                NaN   \n",
       "3                   High Voltage (Left Fuel Level Sensor)                NaN   \n",
       "4                               High Voltage (Fuel Level)                NaN   \n",
       "...                                                   ...                ...   \n",
       "112014  Incorrect Data J1939 Network #1 Primary Vehicl...                NaN   \n",
       "112015  Special Instructions Engine Starter Solenoid L...                NaN   \n",
       "112016                                                NaN                NaN   \n",
       "112017  Special Instructions Engine Starter Solenoid L...                NaN   \n",
       "112018                                                NaN                NaN   \n",
       "\n",
       "                                       ecuSoftwareVersion ecuSerialNumber  \\\n",
       "0                                                 unknown         unknown   \n",
       "1                                                 unknown         unknown   \n",
       "2                                                 unknown         unknown   \n",
       "3                                                 unknown         unknown   \n",
       "4                                                 unknown         unknown   \n",
       "...                                                   ...             ...   \n",
       "112014  AAAI000051*AAAM010056*Z091290   *A82J170202A_b...      6232171647   \n",
       "112015                                5569997 *E250.e003*        K1243673   \n",
       "112016                                5569997 *E250.e003*        K1243673   \n",
       "112017                                                NaN        K1243673   \n",
       "112018                                5569997 *E250.e003*        K1243673   \n",
       "\n",
       "               ecuModel  ...     Speed  SwitchedBatteryVoltage  Throttle  \\\n",
       "0               unknown  ...  46.52031                     NaN      34.4   \n",
       "1               unknown  ...  46.52031                     NaN      34.4   \n",
       "2               unknown  ...       NaN                     NaN       NaN   \n",
       "3               unknown  ...       NaN                     NaN       NaN   \n",
       "4               unknown  ...   0.00000                     NaN       0.0   \n",
       "...                 ...  ...       ...                     ...       ...   \n",
       "112014          EC80ESP  ...       NaN                     NaN       NaN   \n",
       "112015  FAOM-xx810S-EC3  ...   0.00000                     NaN     100.0   \n",
       "112016  FAOM-xx810S-EC3  ...   0.00000                     NaN     100.0   \n",
       "112017  FAOM-xx810S-EC3  ...       NaN                     NaN       NaN   \n",
       "112018  FAOM-xx810S-EC3  ...       NaN                     NaN       NaN   \n",
       "\n",
       "        TurboBoostPressure        spn_fmi  is_fullderate  is_fullderate_group  \\\n",
       "0                    13.05       96.0_3.0              0                    1   \n",
       "1                    13.05      829.0_3.0              0                    1   \n",
       "2                      NaN       96.0_3.0              0                    1   \n",
       "3                      NaN      829.0_3.0              0                    1   \n",
       "4                     1.16       96.0_3.0              0                    1   \n",
       "...                    ...            ...            ...                  ...   \n",
       "112014                 NaN      639.0_2.0              0                    0   \n",
       "112015                0.29    1321.0_14.0              0                    0   \n",
       "112016                0.29  520321.0_13.0              0                    0   \n",
       "112017                 NaN    1321.0_14.0              0                    0   \n",
       "112018                 NaN  520321.0_13.0              0                    0   \n",
       "\n",
       "        EquipID_Index  time_to_next_SPN5246  time_interval_to_SPN5246_class  \n",
       "0               301_1           239999976.0                         9999999  \n",
       "1               301_1           239999976.0                         9999999  \n",
       "2               301_1           239999976.0                         9999999  \n",
       "3               301_1           239999976.0                         9999999  \n",
       "4               301_1           239999976.0                         9999999  \n",
       "...               ...                   ...                             ...  \n",
       "112014    105437340_0           239999976.0                         9999999  \n",
       "112015    105437340_0           239999976.0                         9999999  \n",
       "112016    105437340_0           239999976.0                         9999999  \n",
       "112017    105437340_0           239999976.0                         9999999  \n",
       "112018    105437340_0           239999976.0                         9999999  \n",
       "\n",
       "[112019 rows x 53 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreshTest_In2019 = test\n",
    "FreshTest_In2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11409ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "FreshTest_In2019[['ecuSource', 'LampStatus', 'time_interval_to_SPN5246_class', 'ecuSerialNumber', 'ecuModel', 'ecuMake']] = FreshTest_In2019[['ecuSource', 'LampStatus', 'time_interval_to_SPN5246_class', 'ecuSerialNumber', 'ecuModel', 'ecuMake']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c807738",
   "metadata": {},
   "outputs": [],
   "source": [
    "FreshTest_In2019[['activeTransitionCount']] = FreshTest_In2019[['activeTransitionCount']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db52a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecuSource</th>\n",
       "      <th>active</th>\n",
       "      <th>activeTransitionCount</th>\n",
       "      <th>AcceleratorPedal</th>\n",
       "      <th>BarometricPressure</th>\n",
       "      <th>CruiseControlActive</th>\n",
       "      <th>CruiseControlSetSpeed</th>\n",
       "      <th>DistanceLtd</th>\n",
       "      <th>EngineCoolantTemperature</th>\n",
       "      <th>EngineLoad</th>\n",
       "      <th>...</th>\n",
       "      <th>FuelTemperature</th>\n",
       "      <th>IgnStatus</th>\n",
       "      <th>IntakeManifoldTemperature</th>\n",
       "      <th>LampStatus</th>\n",
       "      <th>ParkingBrake</th>\n",
       "      <th>Speed</th>\n",
       "      <th>SwitchedBatteryVoltage</th>\n",
       "      <th>Throttle</th>\n",
       "      <th>TurboBoostPressure</th>\n",
       "      <th>spn_fmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>True</td>\n",
       "      <td>126</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389864.2</td>\n",
       "      <td>145.4</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.6</td>\n",
       "      <td>True</td>\n",
       "      <td>84.2</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>False</td>\n",
       "      <td>46.52031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.4</td>\n",
       "      <td>13.05</td>\n",
       "      <td>96.0_3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>True</td>\n",
       "      <td>126</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389864.2</td>\n",
       "      <td>145.4</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.6</td>\n",
       "      <td>True</td>\n",
       "      <td>84.2</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>False</td>\n",
       "      <td>46.52031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.4</td>\n",
       "      <td>13.05</td>\n",
       "      <td>829.0_3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "      <td>126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0_3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "      <td>126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>829.0_3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>True</td>\n",
       "      <td>126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389870.2</td>\n",
       "      <td>156.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.8</td>\n",
       "      <td>True</td>\n",
       "      <td>107.6</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>96.0_3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112014</th>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639.0_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112015</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147893.8</td>\n",
       "      <td>82.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>68.0</td>\n",
       "      <td>63487.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1321.0_14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112016</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147893.8</td>\n",
       "      <td>91.4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>73.4</td>\n",
       "      <td>63487.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>520321.0_13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112017</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63487.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1321.0_14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112018</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>520321.0_13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112019 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ecuSource  active activeTransitionCount  AcceleratorPedal  \\\n",
       "0             49    True                   126              34.0   \n",
       "1             49    True                   126              34.0   \n",
       "2             49   False                   126               NaN   \n",
       "3             49   False                   126               NaN   \n",
       "4             49    True                   126               0.0   \n",
       "...          ...     ...                   ...               ...   \n",
       "112014        11   False                   127               NaN   \n",
       "112015         3    True                     1               0.0   \n",
       "112016         3    True                     4               0.0   \n",
       "112017         3   False                     5               NaN   \n",
       "112018         3   False                    12               NaN   \n",
       "\n",
       "        BarometricPressure CruiseControlActive  CruiseControlSetSpeed  \\\n",
       "0                     14.5               False                    0.0   \n",
       "1                     14.5               False                    0.0   \n",
       "2                      NaN                 NaN                    NaN   \n",
       "3                      NaN                 NaN                    NaN   \n",
       "4                     14.5               False                    0.0   \n",
       "...                    ...                 ...                    ...   \n",
       "112014                 NaN                 NaN                    NaN   \n",
       "112015                14.5               False                    0.0   \n",
       "112016                14.5               False                    0.0   \n",
       "112017                 NaN                 NaN                    NaN   \n",
       "112018                 NaN                 NaN                    NaN   \n",
       "\n",
       "        DistanceLtd  EngineCoolantTemperature  EngineLoad  ...  \\\n",
       "0          389864.2                     145.4        46.0  ...   \n",
       "1          389864.2                     145.4        46.0  ...   \n",
       "2               NaN                       NaN         NaN  ...   \n",
       "3               NaN                       NaN         NaN  ...   \n",
       "4          389870.2                     156.2        13.0  ...   \n",
       "...             ...                       ...         ...  ...   \n",
       "112014          NaN                       NaN         NaN  ...   \n",
       "112015     147893.8                      82.4        25.0  ...   \n",
       "112016     147893.8                      91.4        24.0  ...   \n",
       "112017          NaN                       NaN         NaN  ...   \n",
       "112018          NaN                       NaN         NaN  ...   \n",
       "\n",
       "        FuelTemperature  IgnStatus  IntakeManifoldTemperature  LampStatus  \\\n",
       "0                  71.6       True                       84.2      1279.0   \n",
       "1                  71.6       True                       84.2      1279.0   \n",
       "2                   NaN        NaN                        NaN       255.0   \n",
       "3                   NaN        NaN                        NaN       255.0   \n",
       "4                  87.8       True                      107.6      1279.0   \n",
       "...                 ...        ...                        ...         ...   \n",
       "112014              NaN        NaN                        NaN     50175.0   \n",
       "112015              NaN       True                       68.0     63487.0   \n",
       "112016              NaN       True                       73.4     63487.0   \n",
       "112017              NaN        NaN                        NaN     63487.0   \n",
       "112018              NaN        NaN                        NaN       255.0   \n",
       "\n",
       "        ParkingBrake     Speed  SwitchedBatteryVoltage  Throttle  \\\n",
       "0              False  46.52031                     NaN      34.4   \n",
       "1              False  46.52031                     NaN      34.4   \n",
       "2                NaN       NaN                     NaN       NaN   \n",
       "3                NaN       NaN                     NaN       NaN   \n",
       "4               True   0.00000                     NaN       0.0   \n",
       "...              ...       ...                     ...       ...   \n",
       "112014           NaN       NaN                     NaN       NaN   \n",
       "112015          True   0.00000                     NaN     100.0   \n",
       "112016          True   0.00000                     NaN     100.0   \n",
       "112017           NaN       NaN                     NaN       NaN   \n",
       "112018           NaN       NaN                     NaN       NaN   \n",
       "\n",
       "       TurboBoostPressure        spn_fmi  \n",
       "0                   13.05       96.0_3.0  \n",
       "1                   13.05      829.0_3.0  \n",
       "2                     NaN       96.0_3.0  \n",
       "3                     NaN      829.0_3.0  \n",
       "4                    1.16       96.0_3.0  \n",
       "...                   ...            ...  \n",
       "112014                NaN      639.0_2.0  \n",
       "112015               0.29    1321.0_14.0  \n",
       "112016               0.29  520321.0_13.0  \n",
       "112017                NaN    1321.0_14.0  \n",
       "112018                NaN  520321.0_13.0  \n",
       "\n",
       "[112019 rows x 27 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fresh_test = FreshTest_In2019.drop(columns = [    'Unnamed: 0',\n",
    "                                                    'Unnamed: 0.1',\n",
    "                                                    'RecordID',\n",
    "                                                    'ESS_Id',\n",
    "                                                    'actionDescription',\n",
    "                                                    'spn',\n",
    "                                                    'fmi',\n",
    "                                                    'faultValue',\n",
    "                                                    'MCTNumber',\n",
    "                                                    'Latitude',\n",
    "                                                    'Longitude',\n",
    "                                                    'is_fullderate',\n",
    "                                                    'is_fullderate_group',\n",
    "                                                    'time_to_next_SPN5246',\n",
    "                                                    'ServiceDistance',\n",
    "                                                    'EventTimeStamp',\n",
    "                                                    'eventDescription',\n",
    "                                                    'EquipmentID',\n",
    "                                                    'LocationTimeStamp',\n",
    "                                                    'EquipID_Index',\n",
    "                                                    'time_interval_to_SPN5246_class',\n",
    "                                                    'MCTNumber',                                  \n",
    "                                                    'FaultId',\n",
    "                                                    'ecuSoftwareVersion',\n",
    "                                                    'ecuSerialNumber',\n",
    "                                                    'ecuModel',\n",
    "                                                    'ecuMake'  \n",
    "                                                    ]\n",
    "                                     )  \n",
    "X_fresh_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fresh_test['spn_fmi'] = X_fresh_test['spn_fmi'].str.replace('.0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425389f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112019, 27)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fresh_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e82cf27",
   "metadata": {},
   "source": [
    "X_FreshTest_Transformed = ct.transform(X_fresh_test)\n",
    "X_FreshTest_Transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fresh_pred = xgbc_pipe.predict(X_fresh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f3e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 4, ..., 4, 4, 4], shape=(112019,), dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fresh_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e227a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fresh_pred_series = pd.Series(y_fresh_pred)\n",
    "y_fresh_pred_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In2019_withFresh_Y_Pred = pd.concat([FreshTest_In2019, y_fresh_pred_series], axis=1)\n",
    "In2019_withFresh_Y_Pred  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80915224",
   "metadata": {},
   "outputs": [],
   "source": [
    "In2019_withFresh_Y_Pred.to_csv('../data/In2019_withFresh_Y_Pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0d7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89034da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fresh_test = FreshTest_In2019['time_interval_to_SPN5246_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fresh_test_encoded = le_y.transform(y_fresh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa86d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695489158089252"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fresh_test_encoded, y_fresh_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f48a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   82,   163,   107,     0,  1656],\n",
       "       [   32,   184,    49,     0,   151],\n",
       "       [    5,    29,    70,     0,    36],\n",
       "       [    0,     0,     0,   100,     1],\n",
       "       [ 7665,  2684,  2028,     7, 96970]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_fresh_test_encoded, y_fresh_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119ff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.04      0.02      2008\n",
      "           1       0.06      0.44      0.11       416\n",
      "           2       0.03      0.50      0.06       140\n",
      "           3       0.93      0.99      0.96       101\n",
      "           4       0.98      0.89      0.93    109354\n",
      "\n",
      "    accuracy                           0.87    112019\n",
      "   macro avg       0.40      0.57      0.41    112019\n",
      "weighted avg       0.96      0.87      0.91    112019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_fresh_test_encoded, y_fresh_pred, zero_division = 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bae52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fresh_test_encoded.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4c9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fresh_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.6393290423945939\n",
      "RMSE: 1.2803628557540216\n",
      "MAE: 0.45012006891688017\n",
      "MAPE: 281467438481158.06\n",
      "R2: -4.143895251342525\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE: {mean_squared_error(y_fresh_test_encoded, y_fresh_pred)}')\n",
    "print(f'RMSE: {root_mean_squared_error(y_fresh_test_encoded, y_fresh_pred)}')\n",
    "print(f'MAE: {mean_absolute_error(y_fresh_test_encoded, y_fresh_pred)}')\n",
    "print(f'MAPE: {mean_absolute_percentage_error(y_fresh_test_encoded, y_fresh_pred)}')\n",
    "print(f'R2: {r2_score(y_fresh_test_encoded, y_fresh_pred)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9fdad",
   "metadata": {},
   "source": [
    "fresh_cv = LeaveOneOut()\n",
    "fresh_CV_scores = cross_val_score(xgbc_pipe, X_fresh_test, y_fresh_test_encoded, cv=10, scoring='recall_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a44749",
   "metadata": {},
   "source": [
    "print('Cross Validation Macro Precision Scores:', fresh_CV_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbdbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv('../data/submission_XGBClassifier_TunedHyperparameter_TargetEncoder_LearningRatePt05_MaxTreeDepth5_MinChild1_Estimators199_TestSizePt001_MostFeatures_ExcludingMapCode.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e88fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py:1667: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor0&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;target_encoder&#x27;,\n",
       "                                                  TargetEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;spn_fmi&#x27;, &#x27;ecuSource&#x27;,\n",
       "                                                   &#x27;LampStatus&#x27;,\n",
       "                                                   &#x27;activeTransitionCount&#x27;])])),\n",
       "                (&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                (&#x27;imputer&#x27;,\n",
       "                 IterativeImputer(estimator=HistGradientBoostingRegressor(random_state=434,\n",
       "                                                                          verbose=2),\n",
       "                                  max_iter=100, random_state=343))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor0&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;target_encoder&#x27;,\n",
       "                                                  TargetEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;spn_fmi&#x27;, &#x27;ecuSource&#x27;,\n",
       "                                                   &#x27;LampStatus&#x27;,\n",
       "                                                   &#x27;activeTransitionCount&#x27;])])),\n",
       "                (&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                (&#x27;imputer&#x27;,\n",
       "                 IterativeImputer(estimator=HistGradientBoostingRegressor(random_state=434,\n",
       "                                                                          verbose=2),\n",
       "                                  max_iter=100, random_state=343))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor0: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor0: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;target_encoder&#x27;,\n",
       "                                 TargetEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;spn_fmi&#x27;, &#x27;ecuSource&#x27;, &#x27;LampStatus&#x27;,\n",
       "                                  &#x27;activeTransitionCount&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>target_encoder</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;spn_fmi&#x27;, &#x27;ecuSource&#x27;, &#x27;LampStatus&#x27;, &#x27;activeTransitionCount&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TargetEncoder</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>TargetEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>remainder</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;active&#x27;, &#x27;AcceleratorPedal&#x27;, &#x27;BarometricPressure&#x27;, &#x27;CruiseControlActive&#x27;, &#x27;CruiseControlSetSpeed&#x27;, &#x27;DistanceLtd&#x27;, &#x27;EngineCoolantTemperature&#x27;, &#x27;EngineLoad&#x27;, &#x27;EngineOilPressure&#x27;, &#x27;EngineOilTemperature&#x27;, &#x27;EngineRpm&#x27;, &#x27;EngineTimeLtd&#x27;, &#x27;FuelLevel&#x27;, &#x27;FuelLtd&#x27;, &#x27;FuelRate&#x27;, &#x27;FuelTemperature&#x27;, &#x27;IgnStatus&#x27;, &#x27;IntakeManifoldTemperature&#x27;, &#x27;ParkingBrake&#x27;, &#x27;Speed&#x27;, &#x27;SwitchedBatteryVoltage&#x27;, &#x27;Throttle&#x27;, &#x27;TurboBoostPressure&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>imputer: IterativeImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.IterativeImputer.html\">?<span>Documentation for imputer: IterativeImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>IterativeImputer(estimator=HistGradientBoostingRegressor(random_state=434,\n",
       "                                                         verbose=2),\n",
       "                 max_iter=100, random_state=343)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: HistGradientBoostingRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>HistGradientBoostingRegressor(random_state=434, verbose=2)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>HistGradientBoostingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html\">?<span>Documentation for HistGradientBoostingRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>HistGradientBoostingRegressor(random_state=434, verbose=2)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor0',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('target_encoder',\n",
       "                                                  TargetEncoder(handle_unknown='ignore'),\n",
       "                                                  ['spn_fmi', 'ecuSource',\n",
       "                                                   'LampStatus',\n",
       "                                                   'activeTransitionCount'])])),\n",
       "                ('StandardScaler', StandardScaler()),\n",
       "                ('imputer',\n",
       "                 IterativeImputer(estimator=HistGradientBoostingRegressor(random_state=434,\n",
       "                                                                          verbose=2),\n",
       "                                  max_iter=100, random_state=343))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_pipe_XGBClassifier = xgbc_pipe[:-2]\n",
    "xgbc_pipe_XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad95a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31174432,  0.93955603,  0.71889447, ..., -3.81013106,\n",
       "        -0.68342646,  0.79040394],\n",
       "       [-0.08050484,  0.93955603,  0.71889447, ..., -3.81013106,\n",
       "        -0.68342646,  0.79040394],\n",
       "       [-0.31174432,  0.93955603,  0.99477606, ..., -4.13817461,\n",
       "         0.60061035,  1.91147397],\n",
       "       ...,\n",
       "       [ 0.12086283,  0.61285458, -1.16891381, ..., -4.22240056,\n",
       "         0.73202769, -0.70069687],\n",
       "       [ 1.39874232,  0.61285458, -1.16891381, ...,  0.23593036,\n",
       "         0.9541524 , -0.50560987],\n",
       "       [ 1.1354496 ,  0.61285458,  0.99477606, ...,  0.23593036,\n",
       "         0.90540834, -0.36429556]], shape=(112019, 27))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fresh_test_transformed_SHAP = xgbc_pipe_XGBClassifier.transform(X_fresh_test)\n",
    "X_fresh_test_transformed_SHAP  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4bf281",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgbc_pipe[4])\n",
    "explanation = explainer(xgbc_pipe[:-2].transform(X_fresh_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf318054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.15539858e-01,  2.68866271e-01,  1.31942406e-01,\n",
       "         -7.30043745e+00, -5.99136055e-01],\n",
       "        [ 4.43139493e-01, -3.80066812e-01, -1.31712770e+00,\n",
       "         -9.37789738e-01,  5.69590390e-01],\n",
       "        [-3.58197719e-01,  5.34089981e-04,  1.47685885e-01,\n",
       "         -5.26713841e-02, -2.42415935e-01],\n",
       "        ...,\n",
       "        [ 7.40963640e-03, -1.57891572e-01,  1.19375512e-01,\n",
       "          1.40306860e-01,  4.27690931e-02],\n",
       "        [-1.48272645e-02, -1.06920138e-01,  6.01806231e-02,\n",
       "          7.29044378e-02, -1.91577613e-01],\n",
       "        [ 3.43923480e-03,  1.72442570e-02, -6.79549351e-02,\n",
       "         -2.09890842e-01,  4.90162261e-02]],\n",
       "\n",
       "       [[-3.01662922e-01, -2.33363509e-01,  2.03301497e-02,\n",
       "         -7.28229952e+00, -6.29784822e-01],\n",
       "        [ 4.06701744e-01, -3.55521649e-01, -1.21941781e+00,\n",
       "         -9.37155247e-01,  5.65451622e-01],\n",
       "        [-3.86568010e-01, -1.11553341e-01,  1.91857591e-01,\n",
       "         -8.39809775e-02, -2.51318604e-01],\n",
       "        ...,\n",
       "        [ 2.23156400e-02, -1.83494434e-01,  1.18293822e-01,\n",
       "          1.40306860e-01,  4.41890545e-02],\n",
       "        [-3.98380682e-02, -1.05988592e-01,  6.41872138e-02,\n",
       "          7.29145631e-02, -1.93477109e-01],\n",
       "        [ 3.44195240e-03,  3.59272747e-03, -6.85706511e-02,\n",
       "         -2.09391996e-01,  4.97141182e-02]],\n",
       "\n",
       "       [[-1.10271037e-01,  1.23613477e-01,  7.13828951e-02,\n",
       "         -7.42590952e+00, -5.68036616e-01],\n",
       "        [ 4.01616931e-01, -2.72212207e-01, -1.29809141e+00,\n",
       "         -8.62550020e-01,  9.17159677e-01],\n",
       "        [-1.54298037e-01, -1.24692284e-02, -7.06513882e-01,\n",
       "          3.51388961e-01,  1.05988927e-01],\n",
       "        ...,\n",
       "        [-2.82735769e-02, -4.34202999e-02,  3.43701877e-02,\n",
       "          7.13702366e-02,  4.83293496e-02],\n",
       "        [ 1.40677691e-02, -4.56155511e-03,  5.05839959e-02,\n",
       "         -3.36449742e-01,  2.84967422e-01],\n",
       "        [-1.45529199e-03, -1.08675903e-03, -1.20409764e-01,\n",
       "         -1.77025914e-01, -5.35885850e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-7.05630302e-01, -9.58429873e-02,  8.15200210e-02,\n",
       "         -5.59767008e+00, -4.70815688e-01],\n",
       "        [-1.43494308e-01,  9.97744650e-02,  2.52301723e-01,\n",
       "         -7.98919261e-01,  3.43220145e-01],\n",
       "        [ 5.39777219e-01,  2.23895553e-02,  6.22631572e-02,\n",
       "         -7.92944193e-01, -2.14984253e-01],\n",
       "        ...,\n",
       "        [-1.56899050e-01, -6.79329261e-02,  2.89981753e-01,\n",
       "         -3.87125313e-01,  5.17457500e-02],\n",
       "        [-1.46858040e-02, -7.63093457e-02,  4.38828729e-02,\n",
       "         -5.47955632e-01,  5.60575612e-02],\n",
       "        [ 1.63736865e-02,  2.32638046e-02, -2.86067724e-02,\n",
       "         -3.22830826e-01, -5.33919223e-03]],\n",
       "\n",
       "       [[-3.47313076e-01, -7.95961678e-01, -1.39217004e-01,\n",
       "         -5.26330471e+00,  4.94670773e+00],\n",
       "        [-8.03150013e-02,  6.01418987e-02,  1.86718613e-01,\n",
       "         -8.64982128e-01,  1.93130255e-01],\n",
       "        [ 5.10008216e-01, -3.13297927e-01, -1.04237556e+00,\n",
       "         -6.91220999e-01,  5.82436733e-02],\n",
       "        ...,\n",
       "        [-1.07188690e-02, -1.82151562e-04, -5.08331023e-02,\n",
       "         -3.01681068e-02,  2.56712046e-02],\n",
       "        [ 3.35591227e-01, -8.27322006e-01, -8.83615673e-01,\n",
       "         -1.48027265e+00,  1.34867147e-01],\n",
       "        [ 3.80723318e-03, -1.60209779e-02,  7.39486963e-02,\n",
       "         -1.31191507e-01, -1.47873964e-02]],\n",
       "\n",
       "       [[-6.25855699e-02, -1.96542218e-01, -3.02964866e-01,\n",
       "         -5.48220634e+00,  1.26069558e+00],\n",
       "        [-1.81693822e-01,  5.19897193e-02,  1.09948315e-01,\n",
       "         -9.89058971e-01, -1.77342087e-01],\n",
       "        [-2.98237681e-01,  2.41662681e-01,  1.75908506e-02,\n",
       "          4.36295986e-01, -7.91440010e-02],\n",
       "        ...,\n",
       "        [ 7.74504803e-03, -4.37655784e-02, -1.04367686e-02,\n",
       "         -1.98651478e-03,  2.61281300e-02],\n",
       "        [ 2.25579903e-01,  7.33505934e-02, -3.33119422e-01,\n",
       "         -1.39240396e+00,  1.29175857e-01],\n",
       "        [ 5.07927919e-03,  6.58485070e-02, -6.81058168e-02,\n",
       "         -1.53145328e-01, -1.12895416e-02]]],\n",
       "      shape=(112019, 27, 5), dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.shap_values(xgbc_pipe[:-2].transform(X_fresh_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8860ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".values =\n",
       "array([[ 2.6886627e-01, -3.8006681e-01,  5.3408998e-04, ...,\n",
       "        -1.5789157e-01, -1.0692014e-01,  1.7244257e-02],\n",
       "       [-2.3336351e-01, -3.5552165e-01, -1.1155334e-01, ...,\n",
       "        -1.8349443e-01, -1.0598859e-01,  3.5927275e-03],\n",
       "       [ 1.2361348e-01, -2.7221221e-01, -1.2469228e-02, ...,\n",
       "        -4.3420300e-02, -4.5615551e-03, -1.0867590e-03],\n",
       "       ...,\n",
       "       [-9.5842987e-02,  9.9774465e-02,  2.2389555e-02, ...,\n",
       "        -6.7932926e-02, -7.6309346e-02,  2.3263805e-02],\n",
       "       [-7.9596168e-01,  6.0141899e-02, -3.1329793e-01, ...,\n",
       "        -1.8215156e-04, -8.2732201e-01, -1.6020978e-02],\n",
       "       [-1.9654222e-01,  5.1989719e-02,  2.4166268e-01, ...,\n",
       "        -4.3765578e-02,  7.3350593e-02,  6.5848507e-02]],\n",
       "      shape=(112019, 27), dtype=float32)\n",
       "\n",
       ".base_values =\n",
       "array([0.5611577, 0.5611577, 0.5611577, ..., 0.5611577, 0.5611577,\n",
       "       0.5611577], shape=(112019,), dtype=float32)\n",
       "\n",
       ".data =\n",
       "array([[-0.31174432,  0.93955603,  0.71889447, ..., -3.81013106,\n",
       "        -0.68342646,  0.79040394],\n",
       "       [-0.08050484,  0.93955603,  0.71889447, ..., -3.81013106,\n",
       "        -0.68342646,  0.79040394],\n",
       "       [-0.31174432,  0.93955603,  0.99477606, ..., -4.13817461,\n",
       "         0.60061035,  1.91147397],\n",
       "       ...,\n",
       "       [ 0.12086283,  0.61285458, -1.16891381, ..., -4.22240056,\n",
       "         0.73202769, -0.70069687],\n",
       "       [ 1.39874232,  0.61285458, -1.16891381, ...,  0.23593036,\n",
       "         0.9541524 , -0.50560987],\n",
       "       [ 1.1354496 ,  0.61285458,  0.99477606, ...,  0.23593036,\n",
       "         0.90540834, -0.36429556]], shape=(112019, 27))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbdeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.plots.beeswarm(explanation[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034aa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['target_encoder__spn_fmi', 'target_encoder__ecuSource',\n",
       "       'target_encoder__LampStatus',\n",
       "       'target_encoder__activeTransitionCount', 'remainder__active',\n",
       "       'remainder__AcceleratorPedal', 'remainder__BarometricPressure',\n",
       "       'remainder__CruiseControlActive',\n",
       "       'remainder__CruiseControlSetSpeed', 'remainder__DistanceLtd',\n",
       "       'remainder__EngineCoolantTemperature', 'remainder__EngineLoad',\n",
       "       'remainder__EngineOilPressure', 'remainder__EngineOilTemperature',\n",
       "       'remainder__EngineRpm', 'remainder__EngineTimeLtd',\n",
       "       'remainder__FuelLevel', 'remainder__FuelLtd',\n",
       "       'remainder__FuelRate', 'remainder__FuelTemperature',\n",
       "       'remainder__IgnStatus', 'remainder__IntakeManifoldTemperature',\n",
       "       'remainder__ParkingBrake', 'remainder__Speed',\n",
       "       'remainder__SwitchedBatteryVoltage', 'remainder__Throttle',\n",
       "       'remainder__TurboBoostPressure'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = xgbc_pipe[:-1].get_feature_names_out(input_features=X_fresh_test.columns)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e65d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_encoder__spn_fmi</th>\n",
       "      <th>target_encoder__ecuSource</th>\n",
       "      <th>target_encoder__LampStatus</th>\n",
       "      <th>target_encoder__activeTransitionCount</th>\n",
       "      <th>remainder__active</th>\n",
       "      <th>remainder__AcceleratorPedal</th>\n",
       "      <th>remainder__BarometricPressure</th>\n",
       "      <th>remainder__CruiseControlActive</th>\n",
       "      <th>remainder__CruiseControlSetSpeed</th>\n",
       "      <th>remainder__DistanceLtd</th>\n",
       "      <th>...</th>\n",
       "      <th>remainder__FuelLtd</th>\n",
       "      <th>remainder__FuelRate</th>\n",
       "      <th>remainder__FuelTemperature</th>\n",
       "      <th>remainder__IgnStatus</th>\n",
       "      <th>remainder__IntakeManifoldTemperature</th>\n",
       "      <th>remainder__ParkingBrake</th>\n",
       "      <th>remainder__Speed</th>\n",
       "      <th>remainder__SwitchedBatteryVoltage</th>\n",
       "      <th>remainder__Throttle</th>\n",
       "      <th>remainder__TurboBoostPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.311744</td>\n",
       "      <td>0.939556</td>\n",
       "      <td>0.718894</td>\n",
       "      <td>0.499082</td>\n",
       "      <td>0.959904</td>\n",
       "      <td>0.149189</td>\n",
       "      <td>0.257675</td>\n",
       "      <td>-0.327165</td>\n",
       "      <td>-5.080732</td>\n",
       "      <td>0.176883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159288</td>\n",
       "      <td>0.533559</td>\n",
       "      <td>1.492570</td>\n",
       "      <td>0.065547</td>\n",
       "      <td>-0.885156</td>\n",
       "      <td>-0.629721</td>\n",
       "      <td>0.717015</td>\n",
       "      <td>-3.810131</td>\n",
       "      <td>-0.683426</td>\n",
       "      <td>0.790404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.080505</td>\n",
       "      <td>0.939556</td>\n",
       "      <td>0.718894</td>\n",
       "      <td>0.499082</td>\n",
       "      <td>0.959904</td>\n",
       "      <td>0.149189</td>\n",
       "      <td>0.257675</td>\n",
       "      <td>-0.327165</td>\n",
       "      <td>-5.080732</td>\n",
       "      <td>0.176883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159288</td>\n",
       "      <td>0.533559</td>\n",
       "      <td>1.492570</td>\n",
       "      <td>0.065547</td>\n",
       "      <td>-0.885156</td>\n",
       "      <td>-0.629721</td>\n",
       "      <td>0.717015</td>\n",
       "      <td>-3.810131</td>\n",
       "      <td>-0.683426</td>\n",
       "      <td>0.790404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.311744</td>\n",
       "      <td>0.939556</td>\n",
       "      <td>0.994776</td>\n",
       "      <td>0.499082</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>1.419327</td>\n",
       "      <td>-2.643467</td>\n",
       "      <td>-0.128552</td>\n",
       "      <td>-0.283660</td>\n",
       "      <td>1.429443</td>\n",
       "      <td>...</td>\n",
       "      <td>1.172996</td>\n",
       "      <td>1.746517</td>\n",
       "      <td>6.471175</td>\n",
       "      <td>-2.585688</td>\n",
       "      <td>-0.451409</td>\n",
       "      <td>1.313515</td>\n",
       "      <td>1.233541</td>\n",
       "      <td>-4.138175</td>\n",
       "      <td>0.600610</td>\n",
       "      <td>1.911474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.080505</td>\n",
       "      <td>0.939556</td>\n",
       "      <td>0.994776</td>\n",
       "      <td>0.499082</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>-0.658090</td>\n",
       "      <td>0.118331</td>\n",
       "      <td>3.049573</td>\n",
       "      <td>0.301793</td>\n",
       "      <td>0.878576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862473</td>\n",
       "      <td>0.682318</td>\n",
       "      <td>-0.217708</td>\n",
       "      <td>0.057007</td>\n",
       "      <td>-0.842622</td>\n",
       "      <td>-0.628092</td>\n",
       "      <td>1.436479</td>\n",
       "      <td>0.235930</td>\n",
       "      <td>0.267937</td>\n",
       "      <td>0.289138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.311744</td>\n",
       "      <td>0.939556</td>\n",
       "      <td>0.718894</td>\n",
       "      <td>0.499082</td>\n",
       "      <td>0.959904</td>\n",
       "      <td>-0.781001</td>\n",
       "      <td>0.257675</td>\n",
       "      <td>-0.327165</td>\n",
       "      <td>-5.080732</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159321</td>\n",
       "      <td>-0.553531</td>\n",
       "      <td>2.192262</td>\n",
       "      <td>0.065547</td>\n",
       "      <td>0.033343</td>\n",
       "      <td>1.588005</td>\n",
       "      <td>-0.932102</td>\n",
       "      <td>0.208123</td>\n",
       "      <td>-1.425677</td>\n",
       "      <td>-0.599031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112014</th>\n",
       "      <td>0.856763</td>\n",
       "      <td>0.919120</td>\n",
       "      <td>1.919056</td>\n",
       "      <td>1.390262</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>1.542160</td>\n",
       "      <td>-9.153736</td>\n",
       "      <td>-0.314179</td>\n",
       "      <td>0.069247</td>\n",
       "      <td>0.634813</td>\n",
       "      <td>...</td>\n",
       "      <td>3.619135</td>\n",
       "      <td>1.786243</td>\n",
       "      <td>-0.260041</td>\n",
       "      <td>-7.128814</td>\n",
       "      <td>0.296078</td>\n",
       "      <td>0.239253</td>\n",
       "      <td>0.601252</td>\n",
       "      <td>0.253239</td>\n",
       "      <td>0.510275</td>\n",
       "      <td>2.411428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112015</th>\n",
       "      <td>1.398742</td>\n",
       "      <td>0.612855</td>\n",
       "      <td>-1.168914</td>\n",
       "      <td>-1.516991</td>\n",
       "      <td>0.959904</td>\n",
       "      <td>-0.781001</td>\n",
       "      <td>0.257675</td>\n",
       "      <td>-0.327165</td>\n",
       "      <td>-5.080732</td>\n",
       "      <td>-1.518775</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.338239</td>\n",
       "      <td>-0.622046</td>\n",
       "      <td>1.786942</td>\n",
       "      <td>0.065547</td>\n",
       "      <td>-1.521039</td>\n",
       "      <td>1.588005</td>\n",
       "      <td>-0.932102</td>\n",
       "      <td>-4.222401</td>\n",
       "      <td>0.732028</td>\n",
       "      <td>-0.700697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112016</th>\n",
       "      <td>0.120863</td>\n",
       "      <td>0.612855</td>\n",
       "      <td>-1.168914</td>\n",
       "      <td>-0.775548</td>\n",
       "      <td>0.959904</td>\n",
       "      <td>-0.781001</td>\n",
       "      <td>0.257675</td>\n",
       "      <td>-0.327165</td>\n",
       "      <td>-5.080732</td>\n",
       "      <td>-1.518775</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.338239</td>\n",
       "      <td>-0.635748</td>\n",
       "      <td>2.016488</td>\n",
       "      <td>0.065547</td>\n",
       "      <td>-1.309078</td>\n",
       "      <td>1.588005</td>\n",
       "      <td>-0.932102</td>\n",
       "      <td>-4.222401</td>\n",
       "      <td>0.732028</td>\n",
       "      <td>-0.700697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112017</th>\n",
       "      <td>1.398742</td>\n",
       "      <td>0.612855</td>\n",
       "      <td>-1.168914</td>\n",
       "      <td>0.671536</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>-0.612647</td>\n",
       "      <td>0.025109</td>\n",
       "      <td>3.039104</td>\n",
       "      <td>0.208354</td>\n",
       "      <td>-0.308203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186042</td>\n",
       "      <td>-0.598065</td>\n",
       "      <td>-0.217750</td>\n",
       "      <td>0.051740</td>\n",
       "      <td>-0.740600</td>\n",
       "      <td>-0.631899</td>\n",
       "      <td>1.392846</td>\n",
       "      <td>0.235930</td>\n",
       "      <td>0.954152</td>\n",
       "      <td>-0.505610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112018</th>\n",
       "      <td>1.135450</td>\n",
       "      <td>0.612855</td>\n",
       "      <td>0.994776</td>\n",
       "      <td>0.610383</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>-0.323520</td>\n",
       "      <td>0.159032</td>\n",
       "      <td>1.989444</td>\n",
       "      <td>-0.184643</td>\n",
       "      <td>1.235067</td>\n",
       "      <td>...</td>\n",
       "      <td>1.350958</td>\n",
       "      <td>-0.575915</td>\n",
       "      <td>-0.217776</td>\n",
       "      <td>0.035687</td>\n",
       "      <td>-0.390323</td>\n",
       "      <td>-0.630689</td>\n",
       "      <td>1.125687</td>\n",
       "      <td>0.235930</td>\n",
       "      <td>0.905408</td>\n",
       "      <td>-0.364296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112019 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target_encoder__spn_fmi  target_encoder__ecuSource  \\\n",
       "0                     -0.311744                   0.939556   \n",
       "1                     -0.080505                   0.939556   \n",
       "2                     -0.311744                   0.939556   \n",
       "3                     -0.080505                   0.939556   \n",
       "4                     -0.311744                   0.939556   \n",
       "...                         ...                        ...   \n",
       "112014                 0.856763                   0.919120   \n",
       "112015                 1.398742                   0.612855   \n",
       "112016                 0.120863                   0.612855   \n",
       "112017                 1.398742                   0.612855   \n",
       "112018                 1.135450                   0.612855   \n",
       "\n",
       "        target_encoder__LampStatus  target_encoder__activeTransitionCount  \\\n",
       "0                         0.718894                               0.499082   \n",
       "1                         0.718894                               0.499082   \n",
       "2                         0.994776                               0.499082   \n",
       "3                         0.994776                               0.499082   \n",
       "4                         0.718894                               0.499082   \n",
       "...                            ...                                    ...   \n",
       "112014                    1.919056                               1.390262   \n",
       "112015                   -1.168914                              -1.516991   \n",
       "112016                   -1.168914                              -0.775548   \n",
       "112017                   -1.168914                               0.671536   \n",
       "112018                    0.994776                               0.610383   \n",
       "\n",
       "        remainder__active  remainder__AcceleratorPedal  \\\n",
       "0                0.959904                     0.149189   \n",
       "1                0.959904                     0.149189   \n",
       "2               -1.041771                     1.419327   \n",
       "3               -1.041771                    -0.658090   \n",
       "4                0.959904                    -0.781001   \n",
       "...                   ...                          ...   \n",
       "112014          -1.041771                     1.542160   \n",
       "112015           0.959904                    -0.781001   \n",
       "112016           0.959904                    -0.781001   \n",
       "112017          -1.041771                    -0.612647   \n",
       "112018          -1.041771                    -0.323520   \n",
       "\n",
       "        remainder__BarometricPressure  remainder__CruiseControlActive  \\\n",
       "0                            0.257675                       -0.327165   \n",
       "1                            0.257675                       -0.327165   \n",
       "2                           -2.643467                       -0.128552   \n",
       "3                            0.118331                        3.049573   \n",
       "4                            0.257675                       -0.327165   \n",
       "...                               ...                             ...   \n",
       "112014                      -9.153736                       -0.314179   \n",
       "112015                       0.257675                       -0.327165   \n",
       "112016                       0.257675                       -0.327165   \n",
       "112017                       0.025109                        3.039104   \n",
       "112018                       0.159032                        1.989444   \n",
       "\n",
       "        remainder__CruiseControlSetSpeed  remainder__DistanceLtd  ...  \\\n",
       "0                              -5.080732                0.176883  ...   \n",
       "1                              -5.080732                0.176883  ...   \n",
       "2                              -0.283660                1.429443  ...   \n",
       "3                               0.301793                0.878576  ...   \n",
       "4                              -5.080732                0.176925  ...   \n",
       "...                                  ...                     ...  ...   \n",
       "112014                          0.069247                0.634813  ...   \n",
       "112015                         -5.080732               -1.518775  ...   \n",
       "112016                         -5.080732               -1.518775  ...   \n",
       "112017                          0.208354               -0.308203  ...   \n",
       "112018                         -0.184643                1.235067  ...   \n",
       "\n",
       "        remainder__FuelLtd  remainder__FuelRate  remainder__FuelTemperature  \\\n",
       "0                 0.159288             0.533559                    1.492570   \n",
       "1                 0.159288             0.533559                    1.492570   \n",
       "2                 1.172996             1.746517                    6.471175   \n",
       "3                 0.862473             0.682318                   -0.217708   \n",
       "4                 0.159321            -0.553531                    2.192262   \n",
       "...                    ...                  ...                         ...   \n",
       "112014            3.619135             1.786243                   -0.260041   \n",
       "112015           -1.338239            -0.622046                    1.786942   \n",
       "112016           -1.338239            -0.635748                    2.016488   \n",
       "112017           -0.186042            -0.598065                   -0.217750   \n",
       "112018            1.350958            -0.575915                   -0.217776   \n",
       "\n",
       "        remainder__IgnStatus  remainder__IntakeManifoldTemperature  \\\n",
       "0                   0.065547                             -0.885156   \n",
       "1                   0.065547                             -0.885156   \n",
       "2                  -2.585688                             -0.451409   \n",
       "3                   0.057007                             -0.842622   \n",
       "4                   0.065547                              0.033343   \n",
       "...                      ...                                   ...   \n",
       "112014             -7.128814                              0.296078   \n",
       "112015              0.065547                             -1.521039   \n",
       "112016              0.065547                             -1.309078   \n",
       "112017              0.051740                             -0.740600   \n",
       "112018              0.035687                             -0.390323   \n",
       "\n",
       "        remainder__ParkingBrake  remainder__Speed  \\\n",
       "0                     -0.629721          0.717015   \n",
       "1                     -0.629721          0.717015   \n",
       "2                      1.313515          1.233541   \n",
       "3                     -0.628092          1.436479   \n",
       "4                      1.588005         -0.932102   \n",
       "...                         ...               ...   \n",
       "112014                 0.239253          0.601252   \n",
       "112015                 1.588005         -0.932102   \n",
       "112016                 1.588005         -0.932102   \n",
       "112017                -0.631899          1.392846   \n",
       "112018                -0.630689          1.125687   \n",
       "\n",
       "        remainder__SwitchedBatteryVoltage  remainder__Throttle  \\\n",
       "0                               -3.810131            -0.683426   \n",
       "1                               -3.810131            -0.683426   \n",
       "2                               -4.138175             0.600610   \n",
       "3                                0.235930             0.267937   \n",
       "4                                0.208123            -1.425677   \n",
       "...                                   ...                  ...   \n",
       "112014                           0.253239             0.510275   \n",
       "112015                          -4.222401             0.732028   \n",
       "112016                          -4.222401             0.732028   \n",
       "112017                           0.235930             0.954152   \n",
       "112018                           0.235930             0.905408   \n",
       "\n",
       "        remainder__TurboBoostPressure  \n",
       "0                            0.790404  \n",
       "1                            0.790404  \n",
       "2                            1.911474  \n",
       "3                            0.289138  \n",
       "4                           -0.599031  \n",
       "...                               ...  \n",
       "112014                       2.411428  \n",
       "112015                      -0.700697  \n",
       "112016                      -0.700697  \n",
       "112017                      -0.505610  \n",
       "112018                      -0.364296  \n",
       "\n",
       "[112019 rows x 27 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHAP = pd.DataFrame(X_fresh_test_transformed_SHAP, columns=feature_names)\n",
    "df_SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ac146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.beeswarm(explanation, df_SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c98d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['target_encoder__spn_fmi', 'target_encoder__ecuSource',\n",
       "       'target_encoder__LampStatus',\n",
       "       'target_encoder__activeTransitionCount', 'remainder__active',\n",
       "       'remainder__AcceleratorPedal', 'remainder__BarometricPressure',\n",
       "       'remainder__CruiseControlActive',\n",
       "       'remainder__CruiseControlSetSpeed', 'remainder__DistanceLtd',\n",
       "       'remainder__EngineCoolantTemperature', 'remainder__EngineLoad',\n",
       "       'remainder__EngineOilPressure', 'remainder__EngineOilTemperature',\n",
       "       'remainder__EngineRpm', 'remainder__EngineTimeLtd',\n",
       "       'remainder__FuelLevel', 'remainder__FuelLtd',\n",
       "       'remainder__FuelRate', 'remainder__FuelTemperature',\n",
       "       'remainder__IgnStatus', 'remainder__IntakeManifoldTemperature',\n",
       "       'remainder__ParkingBrake', 'remainder__Speed',\n",
       "       'remainder__SwitchedBatteryVoltage', 'remainder__Throttle',\n",
       "       'remainder__TurboBoostPressure'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_pipe[:-1].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a534b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_encoder__spn_fmi',\n",
       " 'target_encoder__LampStatus',\n",
       " 'target_encoder__ecuSource',\n",
       " 'remainder__FuelLtd',\n",
       " 'remainder__EngineTimeLtd',\n",
       " 'remainder__ParkingBrake',\n",
       " 'remainder__FuelLevel',\n",
       " 'remainder__Speed',\n",
       " 'remainder__CruiseControlSetSpeed']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_pipe[:-1].get_feature_names_out()[[0, 2, 1, 17, 15, 22, 16, 23, 8]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0f557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_encoder__LampStatus',\n",
       " 'target_encoder__ecuSource',\n",
       " 'target_encoder__activeTransitionCount',\n",
       " 'remainder__EngineOilTemperature',\n",
       " 'target_encoder__spn_fmi',\n",
       " 'remainder__Throttle',\n",
       " 'remainder__FuelLevel',\n",
       " 'remainder__EngineOilPressure',\n",
       " 'remainder__IgnStatus']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_pipe[:-1].get_feature_names_out()[[2, 1, 3, 13, 0, 25, 16, 12, 20]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d3749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x650 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.plots.bar(explanation[:,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf604d",
   "metadata": {},
   "source": [
    "# Top Features' Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = SelectFromModel(xgbc_pipe[4], threshold=0.0001, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef91070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11, 0.0, 127, ..., nan, nan, '524287_31'],\n",
       "       [0, 0.0, 2, ..., nan, nan, '171_4'],\n",
       "       [11, 1.0, 127, ..., 0.0, 1.74, '789_2'],\n",
       "       ...,\n",
       "       [11, 0.0, 127, ..., nan, nan, '639_2'],\n",
       "       [0, 0.0, 1, ..., nan, nan, '111_17'],\n",
       "       [0, 0.0, 1, ..., nan, nan, '3226_9']],\n",
       "      shape=(948578, 27), dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected = selection.transform(X_train)\n",
    "X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34957eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance_object = plot_importance(xgbc_pipe[4], importance_type='gain')\n",
    "plt.title('Feature Importance for Full Derate Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637d395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Feature  Importance\n",
      "0                   ecuSource    0.263837\n",
      "2       activeTransitionCount    0.123124\n",
      "1                      active    0.089719\n",
      "3            AcceleratorPedal    0.049442\n",
      "4          BarometricPressure    0.042732\n",
      "14                  FuelLevel    0.038486\n",
      "11       EngineOilTemperature    0.027626\n",
      "15                    FuelLtd    0.026913\n",
      "17            FuelTemperature    0.024010\n",
      "19  IntakeManifoldTemperature    0.023417\n",
      "8    EngineCoolantTemperature    0.023152\n",
      "25         TurboBoostPressure    0.021538\n",
      "9                  EngineLoad    0.021513\n",
      "6       CruiseControlSetSpeed    0.019543\n",
      "24                   Throttle    0.018479\n",
      "20                 LampStatus    0.018161\n",
      "10          EngineOilPressure    0.017767\n",
      "12                  EngineRpm    0.017422\n",
      "13              EngineTimeLtd    0.016841\n",
      "22                      Speed    0.016376\n",
      "26                    spn_fmi    0.016283\n",
      "21               ParkingBrake    0.015988\n",
      "16                   FuelRate    0.015982\n",
      "7                 DistanceLtd    0.014203\n",
      "5         CruiseControlActive    0.013955\n",
      "23     SwitchedBatteryVoltage    0.012467\n",
      "18                  IgnStatus    0.011025\n"
     ]
    }
   ],
   "source": [
    "feature_importances = xgbc_pipe[4].feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_27_features = feature_importance_df.head(27)\n",
    "\n",
    "print(top_27_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27280014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 27 features: ['ecuSource', 'activeTransitionCount', 'active', 'AcceleratorPedal', 'BarometricPressure', 'FuelLevel', 'EngineOilTemperature', 'FuelLtd', 'FuelTemperature', 'IntakeManifoldTemperature', 'EngineCoolantTemperature', 'TurboBoostPressure', 'EngineLoad', 'CruiseControlSetSpeed', 'Throttle', 'LampStatus', 'EngineOilPressure', 'EngineRpm', 'EngineTimeLtd', 'Speed', 'spn_fmi', 'ParkingBrake', 'FuelRate', 'DistanceLtd', 'CruiseControlActive', 'SwitchedBatteryVoltage', 'IgnStatus']\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 27 features:\", top_27_features['Feature'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f8c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
